{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>\n",
    "COMP-6721 | 2021-Winter\n",
    "Project | Part-1\n",
    "\n",
    "Pravesh Gupta | 40152506\n",
    "Vikramjeet Singh | \n",
    "Manjot Kaur Dherdi | \n",
    "</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Installing required python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\installations\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: future in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (0.6)\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in d:\\installations\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.18.5)\n",
      "Requirement already satisfied: torch==1.7.0 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.7.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (7.2.0)\n",
      "Requirement already satisfied: future in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\installations\\anaconda3\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in d:\\installations\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\installations\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\installations\\anaconda3\\lib\\site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in d:\\installations\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in d:\\installations\\anaconda3\\lib\\site-packages (0.8.1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.18.5)\n",
      "Requirement already satisfied: torch==1.7.0 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.7.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (7.2.0)\n",
      "\n",
      "Requirement already satisfied: future in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.6)\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in d:\\installations\\anaconda3\\lib\\site-packages (0.16.2)\n",
      "Requirement already satisfied: networkx>=2.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: scipy>=0.19.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (1.5.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: pillow>=4.3.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (7.2.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (3.2.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\installations\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in d:\\installations\\anaconda3\\lib\\site-packages (from scipy>=0.19.0->scikit-image) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in d:\\installations\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in d:\\installations\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\installations\\anaconda3\\lib\\site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in d:\\installations\\anaconda3\\lib\\site-packages (7.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Required Dataset Folder Heirarchy:\n",
    "<pre>\n",
    "{dataset_folder}\n",
    "--images\n",
    "----mask\n",
    "-------{mask images}\n",
    "----no_mask\n",
    "-------{no mask images}\n",
    "----not_person\n",
    "-------{not person images}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Defining Pytorch dataset Representation and data transaformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VisionDataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io as sk_io, transform as sk_transform\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "    \n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size, debug=False, export_path=None):\n",
    "        assert isinstance(output_size, (int))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, img_data):\n",
    "        img_arr = np.array(img_data)\n",
    "        h, w, c = img_arr.shape\n",
    "        isAlreadyScaled = (h==self.output_size and w==self.output_size)\n",
    "        \n",
    "        if not isAlreadyScaled:\n",
    "            scale_factor = float(self.output_size)/img_arr.shape[0]\n",
    "            img_arr = (sk_transform.rescale(img_arr, (scale_factor, scale_factor, 1))*255).astype(np.uint8)\n",
    "\n",
    "            new_w = img_arr.shape[1]\n",
    "\n",
    "            # Clipping or filling\n",
    "            if new_w>self.output_size:\n",
    "                mid = new_w//2\n",
    "                new_w_start = mid-self.output_size//2\n",
    "                new_w_end = mid+self.output_size//2\n",
    "\n",
    "                if (new_w_end-new_w_start)<self.output_size:\n",
    "                    new_w_end += (self.output_size-(new_w_end-new_w_start))\n",
    "                elif (new_w_end-new_w_start)>self.output_size:\n",
    "                    new_w_end -= ((new_w_end-new_w_start)-self.output_size)\n",
    "                img_arr = img_arr[:, new_w_start:new_w_end]\n",
    "            elif new_w<self.output_size:\n",
    "                mid = new_w//2\n",
    "                new_w_start = self.output_size//2-mid\n",
    "                new_w_end = new_w_start+new_w\n",
    "                filled_img_arr = np.zeros((self.output_size, self.output_size, img_arr.shape[2]), dtype=np.uint8)\n",
    "                filled_img_arr[:, new_w_start:new_w_end] = img_arr[:, :]\n",
    "                img_arr = filled_img_arr\n",
    "        return Image.fromarray(img_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Creating dataset and data loaders for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_indices(dataset_targets):\n",
    "    test_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        test_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    train_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        train_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    targets = np.array(dataset.targets, dtype=np.int32)\n",
    "    target_indices = np.where(targets!=None)[0]\n",
    "    np.random.shuffle(target_indices)\n",
    "\n",
    "    for i in target_indices:\n",
    "        label = dataset.targets[i]\n",
    "        if test_indices_map[label]['count']<100:\n",
    "            test_indices_map[label]['indices'] = np.append(test_indices_map[label]['indices'], i)\n",
    "            test_indices_map[label]['count']+=1\n",
    "        elif train_indices_map[label]['count']<350:\n",
    "            train_indices_map[label]['indices'] = np.append(train_indices_map[label]['indices'], i)\n",
    "            train_indices_map[label]['count']+=1\n",
    "\n",
    "    test_indices = np.array([], dtype=np.int32)\n",
    "    train_indices = np.array([], dtype=np.int32)\n",
    "\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        label_test_indices = test_indices_map[label]['indices']\n",
    "        test_indices = np.append(test_indices, label_test_indices)\n",
    "\n",
    "        label_train_indices = train_indices_map[label]['indices']\n",
    "        train_indices = np.append(train_indices, label_train_indices)\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: size: 1344, class labels: {'mask': 0, 'no_mask': 1, 'not_person': 2}\n",
      "Selected dataset: size: 1344\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "rescaled_size=512\n",
    "\n",
    "data_transform = Compose([\n",
    "    Rescale(rescaled_size)\n",
    "    , ToTensor()\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    root='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/1/dataset/rescaled/'\n",
    "    ,transform=data_transform\n",
    ")\n",
    "print(f'Dataset: size: {len(dataset)}, class labels: {dataset.class_to_idx}')\n",
    "\n",
    "train_indices, test_indices = get_train_test_indices(dataset.targets)\n",
    "selected_indices = np.concatenate((train_indices, test_indices))\n",
    "\n",
    "selected_dataset = Subset(dataset, selected_indices)\n",
    "print(f'Selected dataset: size: {len(selected_dataset)}')\n",
    "selected_dataloader = DataLoader(selected_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "means = torch.tensor([])\n",
    "stds = torch.tensor([])\n",
    "for i, (data, labels) in enumerate(selected_dataloader):\n",
    "    batch_mean = torch.mean(data, axis=(0, 2, 3))\n",
    "    batch_std = torch.std(data, axis=(0, 2, 3))\n",
    "    means = torch.cat((means, batch_mean.unsqueeze(0)))\n",
    "    stds = torch.cat((stds, batch_std.unsqueeze(0)))\n",
    "mean = torch.mean(means, axis=0)\n",
    "std = torch.mean(stds, axis=0)\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: size: 1044\n",
      "Train X | y batch shapes : (torch.Size([8, 3, 512, 512]), torch.Size([8]))\n",
      "Test dataset: size: 300\n",
      "Test X | y batch shapes : (torch.Size([8, 3, 512, 512]), torch.Size([8]))\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "data_transform = Compose([\n",
    "    Rescale(rescaled_size)\n",
    "    , ToTensor()\n",
    "    , Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    root='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/1/dataset/rescaled/'\n",
    "    ,transform=data_transform\n",
    ")\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "print(f'Train dataset: size: {len(train_dataset)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "for data, labels in train_dataloader:\n",
    "    print(f'Train X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break\n",
    "\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "print(f'Test dataset: size: {len(test_dataset)}')\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "for data, labels in test_dataloader:\n",
    "    print(f'Test X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Conv2d, MaxPool2d, Linear, ReLU\n",
    "\n",
    "class ProjectModel(Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(ProjectModel, self).__init__()\n",
    "        self.module = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=2)\n",
    "            , torch.nn.BatchNorm2d(32)\n",
    "            , torch.nn.LeakyReLU(inplace=True)\n",
    "            \n",
    "            , torch.nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0)\n",
    "            , torch.nn.BatchNorm2d(32)\n",
    "            , torch.nn.LeakyReLU(inplace=True)\n",
    "            \n",
    "            , torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "            , torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "            , torch.nn.BatchNorm2d(64)\n",
    "            , torch.nn.LeakyReLU(inplace=True)\n",
    "            \n",
    "            , torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "            , torch.nn.BatchNorm2d(64)\n",
    "            , torch.nn.LeakyReLU(inplace=True)\n",
    "            \n",
    "            , torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "            , torch.nn.Flatten()\n",
    "            , torch.nn.Linear(64*126*126, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.module(X)\n",
    "\n",
    "net = ProjectModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Integrity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6154, -0.2912,  0.2695],\n",
      "        [ 0.3208,  0.4764,  0.0321],\n",
      "        [ 0.0822, -0.0940,  0.0862],\n",
      "        [ 0.6981, -0.9018,  0.0689],\n",
      "        [ 0.7143,  0.8044,  0.1841],\n",
      "        [ 0.3659, -0.2922,  0.0750],\n",
      "        [ 0.5144,  0.2931, -0.4612],\n",
      "        [ 0.0205, -0.1104, -0.3311]], grad_fn=<AddmmBackward>)\n",
      "tensor([0, 1, 2, 0, 1, 0, 0, 0])\n",
      "Accuracy: 12.5\n",
      "Model test passed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "net = ProjectModel()\n",
    "net = net.to(device)\n",
    "# Model Unit test\n",
    "total_labels = 0\n",
    "correct_labels = 0\n",
    "for data, labels in train_dataloader:\n",
    "#     torch.cuda.empty_cache()\n",
    "#     data, labels = data.to(device), labels.to(device)\n",
    "    outputs = net(data)\n",
    "    print(outputs)\n",
    "    y_pred = torch.argmax(outputs, dim=1)\n",
    "    print(y_pred)\n",
    "    total_labels+=labels.size(0)\n",
    "    correct_labels += (y_pred==labels).sum().item()\n",
    "    break\n",
    "\n",
    "print(f'Accuracy: {(correct_labels/total_labels)*100}')\n",
    "print('Model test passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "After 0 batches: [time:0.0m 6.936831474304199s, Accuracy: 12.5]\n",
      "After 5 batches: [time:0.0m 6.442779541015625s, Accuracy: 29.166666666666668]\n",
      "After 10 batches: [time:0.0m 6.527071475982666s, Accuracy: 37.5]\n",
      "After 15 batches: [time:0.0m 7.426187515258789s, Accuracy: 39.0625]\n",
      "After 20 batches: [time:0.0m 7.657751560211182s, Accuracy: 46.42857142857143]\n",
      "After 25 batches: [time:0.0m 7.203259468078613s, Accuracy: 46.63461538461539]\n",
      "After 30 batches: [time:0.0m 6.390387058258057s, Accuracy: 46.774193548387096]\n",
      "After 35 batches: [time:0.0m 6.605239391326904s, Accuracy: 48.61111111111111]\n",
      "After 40 batches: [time:0.0m 6.924021244049072s, Accuracy: 49.390243902439025]\n",
      "After 45 batches: [time:0.0m 7.337225437164307s, Accuracy: 48.91304347826087]\n",
      "After 50 batches: [time:0.0m 6.863690376281738s, Accuracy: 49.26470588235294]\n",
      "After 55 batches: [time:0.0m 6.7978363037109375s, Accuracy: 49.55357142857143]\n",
      "After 60 batches: [time:0.0m 6.977378606796265s, Accuracy: 49.59016393442623]\n",
      "After 65 batches: [time:0.0m 6.7692930698394775s, Accuracy: 49.053030303030305]\n",
      "After 70 batches: [time:0.0m 7.220240831375122s, Accuracy: 49.82394366197183]\n",
      "After 75 batches: [time:0.0m 7.410685777664185s, Accuracy: 49.83552631578947]\n",
      "After 80 batches: [time:0.0m 7.0228495597839355s, Accuracy: 49.53703703703704]\n",
      "After 85 batches: [time:0.0m 7.0254456996917725s, Accuracy: 49.127906976744185]\n",
      "After 90 batches: [time:0.0m 6.383491277694702s, Accuracy: 49.45054945054945]\n",
      "After 95 batches: [time:0.0m 7.660168170928955s, Accuracy: 49.08854166666667]\n",
      "After 100 batches: [time:0.0m 6.117607593536377s, Accuracy: 49.257425742574256]\n",
      "After 105 batches: [time:0.0m 6.980700731277466s, Accuracy: 48.82075471698113]\n",
      "After 110 batches: [time:0.0m 7.0707221031188965s, Accuracy: 48.986486486486484]\n",
      "After 115 batches: [time:0.0m 7.347413539886475s, Accuracy: 49.137931034482754]\n",
      "After 120 batches: [time:0.0m 7.178131818771362s, Accuracy: 48.760330578512395]\n",
      "After 125 batches: [time:0.0m 7.105680227279663s, Accuracy: 49.107142857142854]\n",
      "After 130 batches: [time:0.0m 4.309706449508667s, Accuracy: 49.137931034482754]\n",
      "Epoch 1: [time:15.0m 12.224884510040283s, Accuracy: 49.137931034482754]\n",
      "\n",
      "Epoch: 1\n",
      "After 0 batches: [time:0.0m 6.612289667129517s, Accuracy: 62.5]\n",
      "After 5 batches: [time:0.0m 6.923989295959473s, Accuracy: 56.25]\n",
      "After 10 batches: [time:0.0m 6.73298978805542s, Accuracy: 59.09090909090909]\n",
      "After 15 batches: [time:0.0m 6.613993883132935s, Accuracy: 60.15625]\n",
      "After 20 batches: [time:0.0m 6.6292901039123535s, Accuracy: 59.523809523809526]\n",
      "After 25 batches: [time:0.0m 6.457744121551514s, Accuracy: 61.53846153846154]\n",
      "After 30 batches: [time:0.0m 6.585400581359863s, Accuracy: 62.903225806451616]\n",
      "After 35 batches: [time:0.0m 6.351027965545654s, Accuracy: 64.58333333333334]\n",
      "After 40 batches: [time:0.0m 6.7744035720825195s, Accuracy: 64.9390243902439]\n",
      "After 45 batches: [time:0.0m 6.705063819885254s, Accuracy: 64.94565217391305]\n",
      "After 50 batches: [time:0.0m 6.965388774871826s, Accuracy: 65.19607843137256]\n",
      "After 55 batches: [time:0.0m 7.211726427078247s, Accuracy: 65.40178571428571]\n",
      "After 60 batches: [time:0.0m 6.42910623550415s, Accuracy: 64.95901639344262]\n",
      "After 65 batches: [time:0.0m 5.753799676895142s, Accuracy: 64.20454545454545]\n",
      "After 70 batches: [time:0.0m 6.6277806758880615s, Accuracy: 64.7887323943662]\n",
      "After 75 batches: [time:0.0m 7.370730638504028s, Accuracy: 63.651315789473685]\n",
      "After 80 batches: [time:0.0m 6.832723617553711s, Accuracy: 62.96296296296296]\n",
      "After 85 batches: [time:0.0m 6.295352458953857s, Accuracy: 63.80813953488372]\n",
      "After 90 batches: [time:0.0m 6.54703688621521s, Accuracy: 64.14835164835165]\n",
      "After 95 batches: [time:0.0m 6.609335422515869s, Accuracy: 64.58333333333334]\n",
      "After 100 batches: [time:0.0m 6.904024362564087s, Accuracy: 63.98514851485149]\n",
      "After 105 batches: [time:0.0m 6.184483528137207s, Accuracy: 63.561320754716974]\n",
      "After 110 batches: [time:0.0m 6.262183666229248s, Accuracy: 63.06306306306306]\n",
      "After 115 batches: [time:0.0m 6.159032821655273s, Accuracy: 63.03879310344828]\n",
      "After 120 batches: [time:0.0m 6.314270257949829s, Accuracy: 63.22314049586777]\n",
      "After 125 batches: [time:0.0m 6.522067546844482s, Accuracy: 62.99603174603175]\n",
      "After 130 batches: [time:0.0m 3.3340816497802734s, Accuracy: 63.31417624521073]\n",
      "Epoch 2: [time:14.0m 38.75895667076111s, Accuracy: 63.31417624521073]\n",
      "\n",
      "Epoch: 2\n",
      "After 0 batches: [time:0.0m 6.514204263687134s, Accuracy: 50.0]\n",
      "After 5 batches: [time:0.0m 6.508566856384277s, Accuracy: 58.333333333333336]\n",
      "After 10 batches: [time:0.0m 6.7165491580963135s, Accuracy: 67.04545454545455]\n",
      "After 15 batches: [time:0.0m 7.110018491744995s, Accuracy: 65.625]\n",
      "After 20 batches: [time:0.0m 7.07470703125s, Accuracy: 64.28571428571429]\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import time\n",
    "\n",
    "num_epoch = 5\n",
    "lr = 0.001\n",
    "momentum = 0.5\n",
    "net = ProjectModel()\n",
    "\n",
    "loss_evaluater = CrossEntropyLoss()\n",
    "optimizer = SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "net = net.to(device)\n",
    "\n",
    "net.train()\n",
    "\n",
    "t = time.time()\n",
    "for i in range(num_epoch):\n",
    "    print(f'Epoch: {i+1}')\n",
    "    t_epoch = time.time()\n",
    "    total_labels = 0\n",
    "    correctly_pred = 0\n",
    "    t_batch = time.time()\n",
    "    for j, (data, labels) in enumerate(train_dataloader):\n",
    "#         torch.cuda.empty_cache()\n",
    "#         data, labels = data.to(device), labels.to(device)\n",
    "        X, y = data, labels\n",
    "        optimizer.zero_grad()\n",
    "        output = net(X)\n",
    "        loss = loss_evaluater(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred = torch.argmax(output, dim=1)\n",
    "        total_labels += y.size(0)\n",
    "        correctly_pred += (y_pred==y).sum().item()\n",
    "        current_acc = (correctly_pred/total_labels)\n",
    "        if j%5==0:\n",
    "            seconds_passed = time.time()-t_batch\n",
    "            print(f'After {j} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "    epoch_acc = (correctly_pred/total_labels)\n",
    "    seconds_passed = time.time()-t_epoch\n",
    "    print(f'Epoch {i+1}: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {epoch_acc*100}]')\n",
    "    print()\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Training time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f484a5181c91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_labels = 0\n",
    "    correctly_pred = 0\n",
    "    t_batch = time.time()\n",
    "    for i, (data, labels) in train_dataloader:\n",
    "#         data,labels = data.to(device), labels.to(device)\n",
    "        X, y = data, labels\n",
    "        output = net(X)\n",
    "        y_pred = torch.argmax(output, dim=1)\n",
    "        total_labels += y.size(0)\n",
    "        correctly_pred += (y_pred==y).sum().item()\n",
    "        current_acc = (correctly_pred/total_labels)\n",
    "        if i%5==0:\n",
    "            seconds_passed = time.time()-t_batch\n",
    "            print(f'After {j} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "    train_acc = (correctly_pred/total_labels)\n",
    "    print(f'Training accuracy: {train_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "\n",
    "print(f'Trainig evaluation time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "t = time.time()\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "total_labels = 0\n",
    "correctly_pred = 0\n",
    "t_batch = time.time()\n",
    "for i, (data, labels) in enumerate(test_dataloader):\n",
    "#     torch.cuda.empty_cache()\n",
    "#     data, labels = data.to(device), labels.to(device)\n",
    "    X, y = data, labels\n",
    "    output = net(X)\n",
    "    y_pred = torch.argmax(output, dim=1)\n",
    "    total_labels += y.size(0)\n",
    "    correctly_pred += (y_pred==y).sum().item()\n",
    "    current_acc = (correctly_pred/total_labels)\n",
    "    if i%5==0:\n",
    "        seconds_passed = time.time()-t_batch\n",
    "        print(f'After {j} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "\n",
    "test_acc = (correctly_pred/total_labels)\n",
    "print(f'Test accuracy: {test_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Test time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Saving pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), './net.pt')\n",
    "\n",
    "state = {\n",
    "    'epoch': num_epoch,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'lr': lr,\n",
    "    'momentum': momentum\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Loading Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('./net.pt')\n",
    "\n",
    "net = ProjectModel()\n",
    "loss_evaluater = CrossEntropyLoss()\n",
    "optimizer = SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "num_epoch = state['epoch']\n",
    "lr = state['lr']\n",
    "momentum = state['momentum']\n",
    "net.load_state_dict(state['state_dict'])\n",
    "optimizer.load_state_dict(state['optimizer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6721project",
   "language": "python",
   "name": "6721project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
