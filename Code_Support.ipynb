{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2642\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "'''\n",
    "LABEL 0 : NON - MASKED PERSON\n",
    "LABEL 1: MASKED PERSON\n",
    "\n",
    "'''\n",
    "person_no_mask_labels = {'eyeglasses','face_no_mask','face_other_covering','hat','sunglasses','turban'}\n",
    "not_person = 'not_person'\n",
    "\n",
    "with open('Labels.csv','w',newline='') as file:\n",
    "    wr = csv.writer(file,delimiter=',')    \n",
    "    wr.writerow(['ImageNo','Label','Tags'])\n",
    "    \n",
    "\n",
    "path_to_dataset = 'D:\\pravesh\\\\Concordia\\\\2021-Winter\\\\COMP-6721-Intro_To_AI\\\\project\\\\1\\dataset\\\\'\n",
    "image_file_names= [i for i in os.listdir(path_to_dataset+'images')]\n",
    "\n",
    "rows = []\n",
    "for index, image_name  in enumerate(image_file_names):\n",
    "    path_to_json = path_to_dataset + 'annotations\\\\' + image_name + '.json'\n",
    "    data = json.load(open(path_to_json))\n",
    "    image_tags = set()\n",
    "    label = 0\n",
    "    for item in data['Annotations']:\n",
    "        image_tags.add(item['classname'])\n",
    "    rows.append((image_name, image_tags))\n",
    "\n",
    "print(len(rows))\n",
    "\n",
    "with open('Labels.csv','a',newline='') as file:\n",
    "    for image_name, image_tags in rows:\n",
    "        label = 0\n",
    "        if not_person in image_tags:\n",
    "            label = 2\n",
    "        elif len(image_tags & person_no_mask_labels)>0:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        wr = csv.writer(file,delimiter=',') \n",
    "        wr.writerow([image_name, label, ','.join(image_tags)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List down categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are 6435.jpg, 1, {'face_with_mask_incorrect', 'mask_surgical'}\n",
      "Processed 1700 lines.\n",
      "{'mask_surgical', 'face_with_mask_incorrect', 'goggles', 'hair_net', 'balaclava_ski_mask', 'eyeglasses', 'sunglasses', 'other', 'hijab_niqab', 'face_other_covering', 'hood', 'helmet', 'mask_colorful', 'face_shield', 'hat', 'turban', 'face_with_mask', 'face_no_mask', 'scarf_bandana', 'gas_mask'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "tags = set()\n",
    "\n",
    "with open('Labels.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for (name, label, image_tags) in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "#             print(f'{name}, {label}, {image_tags}')\n",
    "            tags = tags | set(image_tags.split(','))\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregate with categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are ImageNo, Label, Tags\n",
      "Processed 3649 lines.\n",
      "3648\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "tags = {'mask_surgical', 'face_with_mask_incorrect', 'goggles', 'hair_net'\n",
    "        , 'balaclava_ski_mask', 'eyeglasses', 'sunglasses', 'other'\n",
    "        , 'hijab_niqab', 'face_other_covering', 'hood', 'helmet'\n",
    "        , 'mask_colorful', 'face_shield', 'hat', 'turban', 'face_with_mask'\n",
    "        , 'face_no_mask', 'scarf_bandana', 'gas_mask'}\n",
    "\n",
    "rows = []\n",
    "\n",
    "path_to_dataset = 'D:\\pravesh\\\\Concordia\\\\2021-Winter\\\\COMP-6721-Intro_To_AI\\\\project\\\\1\\dataset\\\\'\n",
    "\n",
    "with open('Labels.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "#             print(f'{name}, {label}, {image_tags}')\n",
    "            rows.append(row)\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n",
    "\n",
    "print(len(rows))\n",
    "\n",
    "for tag in tags:\n",
    "    path_to_tag_directory = path_to_dataset + 'images\\\\' + tag\n",
    "    if not os.path.isdir(path_to_tag_directory):\n",
    "        os.mkdir(path_to_tag_directory)\n",
    "    for (name, _, image_tags) in rows:\n",
    "        path_to_file = path_to_dataset + 'images\\\\' + name\n",
    "#         print(path_to_file)\n",
    "#         print(os.path.isfile(path_to_file))\n",
    "        if os.path.isfile(path_to_file):\n",
    "            if tag in image_tags:\n",
    "                new_file_path = path_to_tag_directory+'\\\\'+ name\n",
    "#                 print(path_to_file, new_file_path)\n",
    "                os.rename(path_to_file, new_file_path)\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask 1749 3\n",
      "not_person 450 3\n",
      "no_mask 892 3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "'''\n",
    "LABEL 0 : NON - MASKED PERSON\n",
    "LABEL 1: MASKED PERSON\n",
    "\n",
    "'''\n",
    "person_no_mask_labels = {'eyeglasses','face_no_mask','face_other_covering','hat','sunglasses','turban'}\n",
    "label_map = {'mask': 0,\n",
    "            'no_mask': 1,\n",
    "            'not_person': 2}\n",
    "    \n",
    "\n",
    "path_to_dataset = 'D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/1/dataset/'\n",
    "\n",
    "images_dir = path_to_dataset+'images/'\n",
    "\n",
    "dir_names= [i for i in os.listdir(images_dir)]\n",
    "\n",
    "rows = {0: [], 1:[], 2:[]}\n",
    "for index, dir_name in enumerate(dir_names):\n",
    "    count=0\n",
    "    label = label_map[dir_name]\n",
    "    dir_path = images_dir + dir_name + '/'\n",
    "    image_names= [i for i in os.listdir(dir_path)]\n",
    "    for index, image_name  in enumerate(image_names):\n",
    "        path_to_json = path_to_dataset + 'annotations/' + image_name + '.json'\n",
    "        data = json.load(open(path_to_json))\n",
    "        image_tags = set()\n",
    "        for item in data['Annotations']:\n",
    "            image_tags.add(item['classname'])\n",
    "        rows[label].append((dir_name+'/'+image_name, label, image_tags))\n",
    "        count+=1\n",
    "    print(dir_name, count, len(rows))\n",
    "        \n",
    "print(len(rows))\n",
    "\n",
    "test_label_file = path_to_dataset+'test_label_info.csv'\n",
    "\n",
    "with open(test_label_file,'w',newline='') as file:\n",
    "    wr = csv.writer(file,delimiter=',')    \n",
    "    wr.writerow(['ImageNo','Label','Tags'])\n",
    "\n",
    "with open(test_label_file,'a',newline='') as file:\n",
    "    wr = csv.writer(file,delimiter=',')\n",
    "    for i in range(3):\n",
    "        label_rows = rows[i]\n",
    "        for j in range(100):\n",
    "            image, label, image_tags = label_rows[j]\n",
    "            wr.writerow([image, label])\n",
    "            \n",
    "train_label_file = path_to_dataset+'train_label_info.csv'\n",
    "\n",
    "with open(train_label_file,'w',newline='') as file:\n",
    "    wr = csv.writer(file,delimiter=',')    \n",
    "    wr.writerow(['ImageNo','Label','Tags'])      \n",
    "            \n",
    "with open(train_label_file,'a',newline='') as file:\n",
    "    wr = csv.writer(file,delimiter=',')\n",
    "    for i in range(3):\n",
    "        label_rows = rows[i]\n",
    "        for j in range(100, 100+350, 1):\n",
    "            image, label, image_tags = label_rows[j]\n",
    "            wr.writerow([image, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-b180bc99e072>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mProjectDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Face Landmarks dataset.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_info_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class ProjectDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, debug=False):\n",
    "        self.label_info_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.debug = debug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_info_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        label_img_name = self.label_info_frame.iloc[idx, 0]\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                label_img_name)\n",
    "        image = io.imread(img_name)\n",
    "        label = self.label_info_frame.iloc[idx, 1]\n",
    "        label = np.array([label])\n",
    "        landmarks = label.astype('float').reshape(-1, 1)\n",
    "        sample = {'image': image\n",
    "                  ,'label': label\n",
    "                  ,'name': label_img_name}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        if self.debug:\n",
    "            print(label_img_name)\n",
    "\n",
    "        return sample\n",
    "\n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int))\n",
    "        self.output_size = output_size\n",
    "        self.debug = False\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size, self.output_size * w / h\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "        \n",
    "        # Clipping or filling\n",
    "        if new_w>self.output_size:\n",
    "            mid = new_w//2\n",
    "            new_w_start = mid-self.output_size//2\n",
    "            new_w_end = mid+self.output_size//2\n",
    "            \n",
    "            if (new_w_end-new_w_start)<self.output_size:\n",
    "                new_w_end += (self.output_size-(new_w_end-new_w_start))\n",
    "            elif (new_w_end-new_w_start)>self.output_size:\n",
    "                new_w_end -= ((new_w_end-new_w_start)-self.output_size)\n",
    "            img = img[:, new_w_start:new_w_end]\n",
    "        elif new_w<self.output_size:\n",
    "            mid = new_w//2\n",
    "            new_w_start = self.output_size//2-mid\n",
    "            new_w_end = new_w_start+new_w\n",
    "            filled_img = np.zeros((self.output_size, self.output_size, img.shape[2]))\n",
    "            filled_img[:, new_w_start:new_w_end] = img[:, :]\n",
    "            img = filled_img\n",
    "        if self.debug:\n",
    "            root_dir = dataset.root_dir \n",
    "            copy_dir = root_dir+'rescaled/'\n",
    "            img_name = sample['name']\n",
    "            if not os.path.isdir(copy_dir):\n",
    "                os.mkdir(copy_dir)\n",
    "            label_dir_name = img_name.split('\\\\')[0]\n",
    "            label_dir_path = copy_dir + label_dir_name + '/'\n",
    "            if not os.path.isdir(label_dir_path):\n",
    "                os.mkdir(label_dir_path)\n",
    "            path_to_rescaled_img = copy_dir + img_name\n",
    "            io.imsave(path_to_rescaled_img, img, check_contrast=False)\n",
    "        \n",
    "        return {'image': img, 'label': label}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'label': torch.from_numpy(label)}\n",
    "    \n",
    "    \n",
    "class ConvertToType(object):\n",
    "    def __init__(self, conversion_type, debug=False):\n",
    "        self.conversion_type = conversion_type\n",
    "        self.debug = debug\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return img.type(self.conversion_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ProjectDataset(\n",
    "    csv_file='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/comp-6721-project/label_info.csv'\n",
    "    ,root_dir='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/1/dataset/images/')\n",
    "print(len(dataset))\n",
    "\n",
    "output_height = 512\n",
    "\n",
    "scale = Rescale(output_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "counts = np.zeros((100, ))\n",
    "label_counts = {0: np.zeros((100, ))\n",
    "                , 1: np.zeros((100, ))\n",
    "                , 2:np.zeros((100, ))}\n",
    "\n",
    "dataset.debug=False\n",
    "scale.debug=True\n",
    "t1 = time.time()\n",
    "max_w, max_h = 0, 0\n",
    "min_w, min_h = 1000000, 100000\n",
    "count = 0\n",
    "for k in range(5):\n",
    "    sample = dataset[k]\n",
    "    sample_image = sample['image']\n",
    "    label = sample['label'][0]\n",
    "    print(sample['name'], sample_image.shape)\n",
    "    \n",
    "    h, w, _ = sample_image.shape\n",
    "    if w>max_w:\n",
    "        max_w = w\n",
    "    if h>max_h:\n",
    "        max_h = h\n",
    "    if w<min_w:\n",
    "        min_w = w\n",
    "    if h<min_h:\n",
    "        min_h = h\n",
    "    index = w//100\n",
    "    counts[index]+=1\n",
    "    label_counts[label][index]+=1\n",
    "    \n",
    "    transformed_sample = scale(sample)\n",
    "    image = transformed_sample['image']\n",
    "    print(sample['name'], image.shape)\n",
    "    plt.figure()\n",
    "#     image = image.astype(np.uint8)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    count+=1\n",
    "    if count%100==0:\n",
    "        gc.collect()\n",
    "        print(count)\n",
    "        print((time.time()-t1))\n",
    "    \n",
    "print((time.time()-t1))\n",
    "print(max_w, max_h, min_w, min_h)\n",
    "print(counts)\n",
    "for key in label_counts:\n",
    "    print(key, label_counts[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = ProjectDataset(csv_file='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/comp-6721-project/label_info.csv'\n",
    "                                     ,root_dir='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/1/dataset/images/'\n",
    "                                     ,transform=transforms.Compose([\n",
    "                                         Rescale(512)\n",
    "                                         ,ToTensor()\n",
    "                                     ]))\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(dataset)\n",
    "X = np.zeros((dataset_size, output_height, output_height, 3), dtype=np.float32)\n",
    "y = np.zeros((dataset_size, 1), dtype=np.int32)\n",
    "for k in range(dataset_size):\n",
    "    sample = dataset[k]\n",
    "    sample_image, label = sample['image'], sample['label'][0]\n",
    "    \n",
    "    transformed_sample = scale(sample)\n",
    "    image = transformed_sample['image']\n",
    "    X[k] = image\n",
    "    y[k] = label\n",
    "np.savez_compressed('X.npz', X)\n",
    "np.savez_compressed('y.npz', y)\n",
    "print('Done converting to Numpy arrays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 29.644351959228516+(13*60)\n",
    "int(x//60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Conv2d, MaxPool2d, Linear, ReLU\n",
    "\n",
    "class ProjectModel(Module):\n",
    "    def __init__(self):\n",
    "        super(ProjectModel, self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=2)\n",
    "        self.pool1 = MaxPool2d(2)\n",
    "        self.conv2 = Conv2d(in_channels=16, out_channels = 32, kernel_size=3)\n",
    "        self.linear = Linear(in_features = 32*125*125, out_features=3)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        relu = ReLU(inplace=True)\n",
    "        X = self.conv1(X)\n",
    "        X = relu(X)\n",
    "        X = self.pool1(X)\n",
    "        X = self.conv2(X)\n",
    "        X = relu(X)\n",
    "        X = torch.flatten(X, 1)\n",
    "        X = self.linear(X)\n",
    "        return X\n",
    "\n",
    "net = ProjectModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=0)\n",
    "clf = SVC(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=clf.classes_, normalize='all')*100\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x15f31387438>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp.plot(cmap='') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x15f31387438>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=clf.classes_)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('Confusion Matrix(%)')\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:comp6721]",
   "language": "python",
   "name": "conda-env-comp6721-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
