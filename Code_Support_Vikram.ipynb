{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3091\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "'''\n",
    "LABEL 0 : NON - MASKED PERSON\n",
    "LABEL 1: MASKED PERSON\n",
    "\n",
    "'''\n",
    "person_no_mask_labels = {'eyeglasses','face_no_mask','face_other_covering','hat','sunglasses','turban'}\n",
    "not_person = 'not_person'\n",
    "\n",
    "with open('Labels.csv','w',newline='') as file:\n",
    "    wr = csv.writer(file,delimiter=',')    \n",
    "    wr.writerow(['ImageNo','Label','Tags'])\n",
    "    \n",
    "\n",
    "path_to_dataset = 'D:\\\\Courses\\\\COMP 6721 Applied AI\\\\Project\\\\Iteration1\\\\Dataset\\\\'\n",
    "image_file_names= [i for i in os.listdir(path_to_dataset+'images')]\n",
    "\n",
    "rows = []\n",
    "for index, image_name  in enumerate(image_file_names):\n",
    "    path_to_json = path_to_dataset + 'annotations\\\\' + image_name + '.json'\n",
    "    data = json.load(open(path_to_json))\n",
    "    image_tags = set()\n",
    "    label = 0\n",
    "    for item in data['Annotations']:\n",
    "        image_tags.add(item['classname'])\n",
    "    rows.append((image_name, image_tags))\n",
    "\n",
    "print(len(rows))\n",
    "\n",
    "with open('Labels.csv','a',newline='') as file:\n",
    "    for image_name, image_tags in rows:\n",
    "        label = 0\n",
    "        if not_person in image_tags:\n",
    "            label = 2\n",
    "        elif len(image_tags & person_no_mask_labels)>0:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        wr = csv.writer(file,delimiter=',') \n",
    "        wr.writerow([image_name, label, ','.join(image_tags)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List down categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are T, a, g, s\n",
      "Processed 3092 lines.\n",
      "{'helmet', 'sunglasses', 'mask_colorful', 'turban', 'face_with_mask', 'eyeglasses', 'hijab_niqab', 'face_with_mask_incorrect', 'face_shield', 'gas_mask', 'other', 'hood', 'hair_net', 'face_no_mask', 'hat', 'goggles', 'mask_surgical', 'face_other_covering', 'scarf_bandana', 'not_person'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "tags = set()\n",
    "\n",
    "with open('Labels.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for (name, label, image_tags) in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(image_tags)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "#             print(f'{name}, {label}, {image_tags}')\n",
    "            tags = tags | set(image_tags.split(','))\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregate with categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are ImageNo, Label, Tags\n",
      "Processed 1 lines.\n",
      "0\n",
      "mask_surgical\n",
      "face_with_mask\n",
      "mask_colorful\n",
      "helmet\n",
      "hair_net\n",
      "sunglasses\n",
      "face_no_mask\n",
      "balaclava_ski_mask\n",
      "turban\n",
      "hat\n",
      "eyeglasses\n",
      "face_with_mask_incorrect\n",
      "goggles\n",
      "hijab_niqab\n",
      "face_shield\n",
      "gas_mask\n",
      "face_other_covering\n",
      "other\n",
      "scarf_bandana\n",
      "hood\n",
      "not_person\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\"\"\"tags = {'mask_surgical', 'face_with_mask_incorrect', 'goggles', 'hair_net'\n",
    "        , 'balaclava_ski_mask', 'eyeglasses', 'sunglasses', 'other'\n",
    "        , 'hijab_niqab', 'face_other_covering', 'hood', 'helmet'\n",
    "        , 'mask_colorful', 'face_shield', 'hat', 'turban', 'face_with_mask'\n",
    "        , 'face_no_mask', 'scarf_bandana', 'gas_mask'}\n",
    "\"\"\"\n",
    "tags_mask={'face_with_mask', 'mask_surgical', 'mask_colorful'}\n",
    "tags_no_mask={'face_with_mask_incorrect', 'goggles', 'hair_net'\n",
    "        , 'balaclava_ski_mask', 'eyeglasses', 'sunglasses', 'other'\n",
    "        , 'hijab_niqab', 'face_other_covering', 'hood', 'helmet'\n",
    "        , 'face_shield', 'hat', 'turban'\n",
    "        , 'face_no_mask', 'scarf_bandana', 'gas_mask'}\n",
    "tags_not_person={'not_person'}\n",
    "rows = []\n",
    "\n",
    "path_to_dataset = 'D:\\\\Courses\\\\COMP 6721 Applied AI\\\\Project\\\\Iteration1\\\\Dataset\\\\'\n",
    "\n",
    "with open('Labels.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "#             print(f'{name}, {label}, {image_tags}')\n",
    "            rows.append(row)\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n",
    "\n",
    "print(len(rows))\n",
    "\n",
    "for tag in tags_mask:\n",
    "    print(tag)\n",
    "    path_to_tag_directory = path_to_dataset + 'images\\\\mask\\\\'\n",
    "    if not os.path.isdir(path_to_tag_directory):\n",
    "        os.mkdir(path_to_tag_directory)\n",
    "    for (name, _, image_tags) in rows:\n",
    "        path_to_file = path_to_dataset + 'images\\\\' + name\n",
    "#         print(path_to_file)\n",
    "#         print(os.path.isfile(path_to_file))\n",
    "        if os.path.isfile(path_to_file):\n",
    "            if tag in image_tags:\n",
    "                new_file_path = path_to_tag_directory+'\\\\'+ name\n",
    "#                 print(path_to_file, new_file_path)\n",
    "                os.rename(path_to_file, new_file_path)\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "for tag in tags_no_mask:\n",
    "    print(tag)\n",
    "    path_to_tag_directory = path_to_dataset + 'images\\\\no_mask\\\\'\n",
    "    if not os.path.isdir(path_to_tag_directory):\n",
    "        os.mkdir(path_to_tag_directory)\n",
    "    for (name, _, image_tags) in rows:\n",
    "        path_to_file = path_to_dataset + 'images\\\\' + name\n",
    "#         print(path_to_file)\n",
    "#         print(os.path.isfile(path_to_file))\n",
    "        if os.path.isfile(path_to_file):\n",
    "            if tag in image_tags:\n",
    "                new_file_path = path_to_tag_directory+'\\\\'+ name\n",
    "#                 print(path_to_file, new_file_path)\n",
    "                os.rename(path_to_file, new_file_path)\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "for tag in tags_not_person:\n",
    "    print(tag)\n",
    "    path_to_tag_directory = path_to_dataset + 'images\\\\not_person\\\\'\n",
    "    if not os.path.isdir(path_to_tag_directory):\n",
    "        os.mkdir(path_to_tag_directory)\n",
    "    for (name, _, image_tags) in rows:\n",
    "        path_to_file = path_to_dataset + 'images\\\\' + name\n",
    "#         print(path_to_file)\n",
    "#         print(os.path.isfile(path_to_file))\n",
    "        if os.path.isfile(path_to_file):\n",
    "            if tag in image_tags:\n",
    "                new_file_path = path_to_tag_directory+'\\\\'+ name\n",
    "#                 print(path_to_file, new_file_path)\n",
    "                os.rename(path_to_file, new_file_path)\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask 450 450\n",
      "not_person 450 450\n",
      "no_mask 445 445\n",
      "450\n",
      "445\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "'''\n",
    "LABEL 0 : NON - MASKED PERSON\n",
    "LABEL 1: MASKED PERSON\n",
    "LABEL 2: NOT PERSON\n",
    "'''\n",
    "#person_no_mask_labels = {'eyeglasses','face_no_mask','face_other_covering','hat','sunglasses','turban'}\n",
    "label_map = {'mask': 0,\n",
    "            'no_mask': 1,\n",
    "            'not_person': 2}\n",
    "\n",
    "\"\"\"with open('Labels.csv','w',newline='') as file:\n",
    "    wr = csv.writer(file,delimiter=',')    \n",
    "    wr.writerow(['ImageNo','Label','Tags'])\n",
    "\"\"\"    \n",
    "\n",
    "path_to_dataset = 'D:\\\\Courses\\\\COMP 6721 Applied AI\\\\Project\\\\Iteration1\\\\Dataset\\\\'\n",
    "\n",
    "images_dir = path_to_dataset+'images\\\\'\n",
    "\n",
    "dir_names= [i for i in os.listdir(images_dir) if os.path.isdir(images_dir)]\n",
    "rows_mask = []\n",
    "rows_not_mask = []\n",
    "rows_not_person = []\n",
    "row_map={'mask': rows_mask,\n",
    "        'no_mask': rows_not_mask,\n",
    "        'not_person': rows_not_person}\n",
    "for index, dir_name in enumerate(dir_names):\n",
    "    count=0\n",
    "    label = label_map[dir_name]\n",
    "    rows=row_map[dir_name]\n",
    "    dir_path = images_dir + dir_name + '\\\\'\n",
    "    image_names= [i for i in os.listdir(dir_path)]\n",
    "    for index, image_name  in enumerate(image_names):\n",
    "        if count >= 450:\n",
    "            break\n",
    "        img = Image.open(dir_path + image_name)\n",
    "        width, height=img.size\n",
    "        if height<512 or height>950 :\n",
    "            continue\n",
    "        path_to_json = path_to_dataset + 'annotations\\\\' + image_name + '.json'\n",
    "        data = json.load(open(path_to_json))\n",
    "        image_tags = set()\n",
    "        for item in data['Annotations']:\n",
    "            image_tags.add(item['classname'])\n",
    "        rows.append((dir_name+'\\\\'+image_name, label, image_tags))\n",
    "        count+=1\n",
    "    print(dir_name, count, len(rows))\n",
    "        \n",
    "print(len(rows_mask))\n",
    "print(len(rows_not_mask))\n",
    "print(len(rows_not_person))\n",
    "\n",
    "with open('train_label_info.csv','w',newline='') as train_file, open('test_label_info.csv','w',newline='') as test_file:\n",
    "    for directory, rows in row_map.items():\n",
    "        count=0\n",
    "        for image, label, image_tags in rows:\n",
    "            if count < 100:\n",
    "                wr = csv.writer(test_file,delimiter=',')\n",
    "            else:\n",
    "                wr = csv.writer(train_file,delimiter=',')\n",
    "            wr.writerow([image, label])\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
