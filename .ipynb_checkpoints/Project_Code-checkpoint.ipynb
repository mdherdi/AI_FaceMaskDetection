{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>\n",
    "COMP-6721 | 2021-Winter\n",
    "Project | Part-1\n",
    "\n",
    "Pravesh Gupta | 40152506\n",
    "Vikramjeet Singh | \n",
    "Manjot Kaur Dherdi | \n",
    "</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Installing required python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\installations\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: future in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (0.6)\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in d:\\installations\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.18.5)\n",
      "Requirement already satisfied: torch==1.7.0 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.7.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (7.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: future in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.6)\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\installations\\anaconda3\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\installations\\anaconda3\\lib\\site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in d:\\installations\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\installations\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\installations\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in d:\\installations\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.18.5)\n",
      "Requirement already satisfied: torch==1.7.0 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.7.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (7.2.0)\n",
      "Requirement already satisfied: future in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in d:\\installations\\anaconda3\\lib\\site-packages (0.16.2)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (7.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (3.2.2)\n",
      "Requirement already satisfied: scipy>=0.19.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (1.5.0)\n",
      "Requirement already satisfied: networkx>=2.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\installations\\anaconda3\\lib\\site-packages (from PyWavelets>=0.4.0->scikit-image) (1.18.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\installations\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: six in d:\\installations\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in d:\\installations\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\installations\\anaconda3\\lib\\site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in d:\\installations\\anaconda3\\lib\\site-packages (7.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Required Dataset Folder Heirarchy:\n",
    "<pre>\n",
    "{dataset_folder}\n",
    "--images\n",
    "----mask\n",
    "-------{mask images}\n",
    "----no_mask\n",
    "-------{no mask images}\n",
    "----not_person\n",
    "-------{not person images}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Defining Pytorch dataset Representation and data transaformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VisionDataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io as sk_io, transform as sk_transform\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "    \n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size, debug=False, export_path=None):\n",
    "        assert isinstance(output_size, (int))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, img_data):\n",
    "        img_arr = np.array(img_data)\n",
    "        h, w, c = img_arr.shape\n",
    "        isAlreadyScaled = (h==self.output_size and w==self.output_size)\n",
    "        \n",
    "        if not isAlreadyScaled:\n",
    "            scale_factor = float(self.output_size)/img_arr.shape[0]\n",
    "            img_arr = (sk_transform.rescale(img_arr, (scale_factor, scale_factor, 1))*255).astype(np.uint8)\n",
    "\n",
    "            new_w = img_arr.shape[1]\n",
    "\n",
    "            # Clipping or filling\n",
    "            if new_w>self.output_size:\n",
    "                mid = new_w//2\n",
    "                new_w_start = mid-self.output_size//2\n",
    "                new_w_end = mid+self.output_size//2\n",
    "\n",
    "                if (new_w_end-new_w_start)<self.output_size:\n",
    "                    new_w_end += (self.output_size-(new_w_end-new_w_start))\n",
    "                elif (new_w_end-new_w_start)>self.output_size:\n",
    "                    new_w_end -= ((new_w_end-new_w_start)-self.output_size)\n",
    "                img_arr = img_arr[:, new_w_start:new_w_end]\n",
    "            elif new_w<self.output_size:\n",
    "                mid = new_w//2\n",
    "                new_w_start = self.output_size//2-mid\n",
    "                new_w_end = new_w_start+new_w\n",
    "                filled_img_arr = np.zeros((self.output_size, self.output_size, img_arr.shape[2]), dtype=np.uint8)\n",
    "                filled_img_arr[:, new_w_start:new_w_end] = img_arr[:, :]\n",
    "                img_arr = filled_img_arr\n",
    "        return Image.fromarray(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: size: 2055, class labels: {'mask': 0, 'no_mask': 1, 'not_person': 2}\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "torch.manual_seed(6721)\n",
    "\n",
    "rescaled_size=512\n",
    "\n",
    "scaler = Rescale(rescaled_size)\n",
    "\n",
    "data_dir = './data/images_original/'\n",
    "copy_dir = './data/images_rescaled/'\n",
    "\n",
    "if not os.path.isdir(copy_dir):\n",
    "    os.mkdir(copy_dir)\n",
    "\n",
    "data_transform = Compose([\n",
    "    Rescale(rescaled_size)\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    root=data_dir\n",
    "    ,transform=data_transform\n",
    ")\n",
    "print(f'Dataset: size: {len(dataset)}, class labels: {dataset.class_to_idx}')\n",
    "\n",
    "label_to_class_dir = {}\n",
    "for class_name in dataset.class_to_idx:\n",
    "    label = dataset.class_to_idx[class_name]\n",
    "    class_dir = copy_dir + class_name + '/'\n",
    "    label_to_class_dir[label] = class_dir\n",
    "    if not os.path.isdir(class_dir):\n",
    "        os.mkdir(class_dir)\n",
    "\n",
    "for i in range(len(dataset.imgs)):\n",
    "    url, label = dataset.imgs[i]\n",
    "    img_name = url.split('\\\\')[1]\n",
    "    img_file_path = label_to_class_dir[label] + img_name\n",
    "    \n",
    "    if not os.path.isfile(img_file_path):\n",
    "        item = dataset.__getitem__(i)\n",
    "        rescaled_img = item[0]\n",
    "        rescaled_img.save(img_file_path, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Creating dataset and data loaders for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_per_class = 600\n",
    "test_images_per_class = 100\n",
    "\n",
    "def get_train_test_indices(dataset_targets):\n",
    "    test_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        test_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    train_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        train_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    targets = np.array(dataset.targets, dtype=np.int32)\n",
    "    target_indices = np.where(targets!=None)[0]\n",
    "    np.random.shuffle(target_indices)\n",
    "\n",
    "    for i in target_indices:\n",
    "        label = dataset.targets[i]\n",
    "        if test_indices_map[label]['count']<test_images_per_class:\n",
    "            test_indices_map[label]['indices'] = np.append(test_indices_map[label]['indices'], i)\n",
    "            test_indices_map[label]['count']+=1\n",
    "        elif train_indices_map[label]['count']<train_images_per_class:\n",
    "            train_indices_map[label]['indices'] = np.append(train_indices_map[label]['indices'], i)\n",
    "            train_indices_map[label]['count']+=1\n",
    "\n",
    "    test_indices = np.array([], dtype=np.int32)\n",
    "    train_indices = np.array([], dtype=np.int32)\n",
    "\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        label_test_indices = test_indices_map[label]['indices']\n",
    "        test_indices = np.append(test_indices, label_test_indices)\n",
    "\n",
    "        label_train_indices = train_indices_map[label]['indices']\n",
    "        train_indices = np.append(train_indices, label_train_indices)\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: size: 2055, class labels: {'mask': 0, 'no_mask': 1, 'not_person': 2}\n",
      "Selected dataset: size: 1850\n",
      "Mean: tensor([0.4273, 0.3934, 0.3734])\n",
      "Std: tensor([0.2897, 0.2778, 0.2854])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import gc\n",
    "\n",
    "torch.manual_seed(6721)\n",
    "\n",
    "rescaled_size=512\n",
    "data_dir = './data/images/'\n",
    "\n",
    "data_transform = Compose([\n",
    "    Rescale(rescaled_size)\n",
    "    , ToTensor()\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    root=data_dir\n",
    "    ,transform=data_transform\n",
    ")\n",
    "print(f'Dataset: size: {len(dataset)}, class labels: {dataset.class_to_idx}')\n",
    "\n",
    "train_indices, test_indices = get_train_test_indices(dataset.targets)\n",
    "selected_indices = np.concatenate((train_indices, test_indices))\n",
    "\n",
    "selected_dataset = Subset(dataset, selected_indices)\n",
    "print(f'Selected dataset: size: {len(selected_dataset)}')\n",
    "selected_dataloader = DataLoader(selected_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "means = torch.tensor([])\n",
    "stds = torch.tensor([])\n",
    "for i, (data, labels) in enumerate(selected_dataloader):\n",
    "    gc.collect()\n",
    "    batch_mean = torch.mean(data, axis=(0, 2, 3))\n",
    "    batch_std = torch.std(data, axis=(0, 2, 3))\n",
    "    means = torch.cat((means, batch_mean.unsqueeze(0)))\n",
    "    stds = torch.cat((stds, batch_std.unsqueeze(0)))\n",
    "mean = torch.mean(means, axis=0)\n",
    "std = torch.mean(stds, axis=0)\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: size: 1550\n",
      "Train X | y batch shapes : (torch.Size([8, 3, 512, 512]), torch.Size([8]))\n",
      "Test dataset: size: 300\n",
      "Test X | y batch shapes : (torch.Size([8, 3, 512, 512]), torch.Size([8]))\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "data_transform = Compose([\n",
    "    Rescale(rescaled_size)\n",
    "    , ToTensor()\n",
    "    , Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    root=data_dir\n",
    "    ,transform=data_transform\n",
    ")\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "print(f'Train dataset: size: {len(train_dataset)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "for data, labels in train_dataloader:\n",
    "    print(f'Train X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break\n",
    "\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "print(f'Test dataset: size: {len(test_dataset)}')\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "for data, labels in test_dataloader:\n",
    "    print(f'Test X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Module, Conv2d, MaxPool2d, Linear, ReLU, Dropout, BatchNorm2d, LeakyReLU, AdaptiveAvgPool2d, Flatten\n",
    "\n",
    "class ProjectModel(Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(ProjectModel, self).__init__()\n",
    "        self.module = Sequential(\n",
    "            Conv2d(3, 32, kernel_size=3, stride=1, padding=2)\n",
    "            , BatchNorm2d(32)\n",
    "            , LeakyReLU(inplace=True)\n",
    "            \n",
    "            , Conv2d(32, 32, kernel_size=3, stride=1, padding=0)\n",
    "            , BatchNorm2d(32)\n",
    "            , LeakyReLU(inplace=True)\n",
    "            \n",
    "            , MaxPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "            , Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "            , BatchNorm2d(64)\n",
    "            , LeakyReLU(inplace=True)\n",
    "            \n",
    "            , Conv2d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "            , BatchNorm2d(64)\n",
    "            , LeakyReLU(inplace=True)\n",
    "            \n",
    "            , MaxPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "            , AdaptiveAvgPool2d(output_size=(12, 12))\n",
    "            \n",
    "            , Flatten()\n",
    "            , Dropout(p=0.2, inplace=False)\n",
    "            , Linear(in_features=64*12*12, out_features=4096, bias=True)\n",
    "            , Dropout(p=0.2, inplace=False)\n",
    "            , Linear(in_features=4096, out_features=512, bias=True)\n",
    "            , Dropout(p=0.2, inplace=False)\n",
    "            , Linear(in_features=512, out_features=num_classes, bias=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.module(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Integrity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2116,  0.4294,  0.1612],\n",
      "        [-0.0947,  0.0015, -0.2038],\n",
      "        [-0.0615,  0.0540,  0.2987],\n",
      "        [-0.0271,  0.3452, -0.0270],\n",
      "        [-0.0680,  0.0351, -0.1456],\n",
      "        [ 0.3672,  0.3775,  0.2946],\n",
      "        [ 0.2208,  0.0455, -0.1692],\n",
      "        [ 0.0310, -0.0212, -0.0259]], grad_fn=<AddmmBackward>)\n",
      "tensor([1, 1, 2, 1, 1, 1, 0, 0])\n",
      "Accuracy: 25.0\n",
      "Model test passed.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = ProjectModel()\n",
    "\n",
    "# net = net.to(device)\n",
    "\n",
    "# Model Unit test\n",
    "total_labels = 0\n",
    "correct_labels = 0\n",
    "for data, labels in train_dataloader:\n",
    "#     torch.cuda.empty_cache()\n",
    "#     data, labels = data.to(device), labels.to(device)\n",
    "    outputs = net(data)\n",
    "    print(outputs)\n",
    "    y_pred = torch.argmax(outputs, dim=1)\n",
    "    print(y_pred)\n",
    "    total_labels+=labels.size(0)\n",
    "    correct_labels += (y_pred==labels).sum().item()\n",
    "    break\n",
    "\n",
    "print(f'Accuracy: {(correct_labels/total_labels)*100}')\n",
    "print('Model test passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProjectModel(\n",
       "  (module): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): AdaptiveAvgPool2d(output_size=(12, 12))\n",
       "    (15): Flatten(start_dim=1, end_dim=-1)\n",
       "    (16): Dropout(p=0.2, inplace=False)\n",
       "    (17): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (18): Dropout(p=0.2, inplace=False)\n",
       "    (19): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (20): Dropout(p=0.2, inplace=False)\n",
       "    (21): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_linear_layer_weights(layer):\n",
    "    torch.nn.init.xavier_uniform_(layer.weight)\n",
    "    torch.nn.init.zeros_(layer.bias)\n",
    "        \n",
    "def initialize_conv2d_layer_weights(layer):\n",
    "    torch.nn.init.xavier_uniform_(layer.weight)\n",
    "    \n",
    "def initialize_model_weights(module):\n",
    "    if isinstance(module, ProjectModel):\n",
    "        return\n",
    "    elif isinstance(module, Sequential):\n",
    "        return\n",
    "    if isinstance(module, Conv2d):\n",
    "        initialize_conv2d_layer_weights(module)\n",
    "    if isinstance(module, Linear):\n",
    "        initialize_linear_layer_weights(module)\n",
    "\n",
    "\n",
    "net = ProjectModel()\n",
    "net.apply(initialize_model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import time\n",
    "\n",
    "num_epoch = 10\n",
    "lr = 1e-3\n",
    "momentum = 0.5\n",
    "\n",
    "loss_evaluater = CrossEntropyLoss()\n",
    "optimizer = Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "# net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "After 0 batches: [time:0.0m 23.70935320854187s, Accuracy: 87.5]\n",
      "After 5 batches: [time:0.0m 58.73638677597046s, Accuracy: 77.08333333333334]\n",
      "After 10 batches: [time:1.0m 29.50020980834961s, Accuracy: 77.27272727272727]\n",
      "After 15 batches: [time:1.0m 59.84116268157959s, Accuracy: 78.90625]\n",
      "After 20 batches: [time:2.0m 29.653037309646606s, Accuracy: 77.97619047619048]\n",
      "After 25 batches: [time:3.0m 0.2602522373199463s, Accuracy: 75.48076923076923]\n",
      "After 30 batches: [time:3.0m 31.693413257598877s, Accuracy: 75.80645161290323]\n",
      "After 35 batches: [time:4.0m 4.4760966300964355s, Accuracy: 76.38888888888889]\n",
      "After 40 batches: [time:4.0m 37.52189016342163s, Accuracy: 74.39024390243902]\n",
      "After 45 batches: [time:5.0m 12.3137686252594s, Accuracy: 74.72826086956522]\n",
      "After 50 batches: [time:5.0m 47.33159923553467s, Accuracy: 74.01960784313727]\n",
      "After 55 batches: [time:6.0m 22.17854928970337s, Accuracy: 72.99107142857143]\n",
      "After 60 batches: [time:6.0m 53.0940842628479s, Accuracy: 72.1311475409836]\n",
      "After 65 batches: [time:7.0m 23.562376260757446s, Accuracy: 71.96969696969697]\n",
      "After 70 batches: [time:7.0m 53.526845932006836s, Accuracy: 71.12676056338029]\n",
      "After 75 batches: [time:8.0m 22.72919487953186s, Accuracy: 71.38157894736842]\n",
      "After 80 batches: [time:8.0m 53.04079723358154s, Accuracy: 71.60493827160494]\n",
      "After 85 batches: [time:9.0m 22.6885404586792s, Accuracy: 71.22093023255815]\n",
      "After 90 batches: [time:9.0m 52.42957162857056s, Accuracy: 72.25274725274726]\n",
      "After 95 batches: [time:10.0m 22.27184748649597s, Accuracy: 72.39583333333334]\n",
      "After 100 batches: [time:10.0m 52.909071922302246s, Accuracy: 72.52475247524752]\n",
      "After 105 batches: [time:11.0m 22.465060710906982s, Accuracy: 72.64150943396226]\n",
      "After 110 batches: [time:11.0m 52.89258527755737s, Accuracy: 73.3108108108108]\n",
      "After 115 batches: [time:12.0m 23.345383644104004s, Accuracy: 73.16810344827587]\n",
      "After 120 batches: [time:12.0m 52.93977880477905s, Accuracy: 73.4504132231405]\n",
      "After 125 batches: [time:13.0m 22.33945059776306s, Accuracy: 73.90873015873017]\n",
      "After 130 batches: [time:13.0m 52.02845358848572s, Accuracy: 74.14122137404581]\n",
      "After 135 batches: [time:14.0m 22.59718132019043s, Accuracy: 74.26470588235294]\n",
      "After 140 batches: [time:14.0m 53.323474168777466s, Accuracy: 74.46808510638297]\n",
      "After 145 batches: [time:15.0m 24.09590172767639s, Accuracy: 74.91438356164383]\n",
      "After 150 batches: [time:15.0m 55.46287989616394s, Accuracy: 74.91721854304636]\n",
      "After 155 batches: [time:16.0m 27.064244985580444s, Accuracy: 75.32051282051282]\n",
      "After 160 batches: [time:16.0m 58.3636691570282s, Accuracy: 75.62111801242236]\n",
      "After 165 batches: [time:17.0m 28.527640104293823s, Accuracy: 75.82831325301204]\n",
      "After 170 batches: [time:17.0m 59.123109579086304s, Accuracy: 75.80409356725146]\n",
      "After 175 batches: [time:18.0m 32.658905029296875s, Accuracy: 75.78125]\n",
      "After 180 batches: [time:19.0m 5.358789920806885s, Accuracy: 76.17403314917127]\n",
      "After 185 batches: [time:19.0m 35.97152876853943s, Accuracy: 76.00806451612904]\n",
      "After 190 batches: [time:20.0m 6.49595308303833s, Accuracy: 76.11256544502618]\n",
      "Epoch 1: [time:20.0m 24.680406093597412s, Accuracy: 75.87096774193547]\n",
      "\n",
      "Epoch: 2\n",
      "After 0 batches: [time:0.0m 5.983014106750488s, Accuracy: 75.0]\n",
      "After 5 batches: [time:0.0m 35.445799589157104s, Accuracy: 87.5]\n",
      "After 10 batches: [time:1.0m 5.755419969558716s, Accuracy: 82.95454545454545]\n",
      "After 15 batches: [time:1.0m 36.859840393066406s, Accuracy: 81.25]\n",
      "After 20 batches: [time:2.0m 7.781783103942871s, Accuracy: 80.95238095238095]\n",
      "After 25 batches: [time:2.0m 38.971359968185425s, Accuracy: 81.25]\n",
      "After 30 batches: [time:3.0m 10.78758692741394s, Accuracy: 78.62903225806451]\n",
      "After 35 batches: [time:3.0m 42.098042726516724s, Accuracy: 80.90277777777779]\n",
      "After 40 batches: [time:4.0m 12.372872591018677s, Accuracy: 79.8780487804878]\n",
      "After 45 batches: [time:4.0m 42.07512354850769s, Accuracy: 81.25]\n",
      "After 50 batches: [time:5.0m 11.302497386932373s, Accuracy: 82.35294117647058]\n",
      "After 55 batches: [time:5.0m 41.59814810752869s, Accuracy: 83.03571428571429]\n",
      "After 60 batches: [time:6.0m 12.74702501296997s, Accuracy: 82.99180327868852]\n",
      "After 65 batches: [time:6.0m 42.34098958969116s, Accuracy: 82.76515151515152]\n",
      "After 70 batches: [time:7.0m 12.1752188205719s, Accuracy: 81.51408450704226]\n",
      "After 75 batches: [time:7.0m 46.74808359146118s, Accuracy: 80.09868421052632]\n",
      "After 80 batches: [time:8.0m 21.539642333984375s, Accuracy: 78.85802469135803]\n",
      "After 85 batches: [time:8.0m 55.08251690864563s, Accuracy: 78.63372093023256]\n",
      "After 90 batches: [time:9.0m 27.86227536201477s, Accuracy: 77.88461538461539]\n",
      "After 95 batches: [time:10.0m 1.396803379058838s, Accuracy: 77.60416666666666]\n",
      "After 100 batches: [time:10.0m 36.1792938709259s, Accuracy: 77.47524752475248]\n",
      "After 105 batches: [time:11.0m 10.050596952438354s, Accuracy: 77.35849056603774]\n",
      "After 110 batches: [time:11.0m 42.683597564697266s, Accuracy: 77.13963963963964]\n",
      "After 115 batches: [time:12.0m 19.18108367919922s, Accuracy: 76.29310344827587]\n",
      "After 120 batches: [time:12.0m 59.00079846382141s, Accuracy: 76.96280991735537]\n",
      "After 125 batches: [time:13.0m 34.37928819656372s, Accuracy: 76.28968253968253]\n",
      "After 130 batches: [time:14.0m 9.046603918075562s, Accuracy: 76.90839694656488]\n",
      "After 135 batches: [time:14.0m 42.899006366729736s, Accuracy: 76.5625]\n",
      "After 140 batches: [time:15.0m 16.703933715820312s, Accuracy: 76.59574468085107]\n",
      "After 145 batches: [time:15.0m 55.261470556259155s, Accuracy: 76.79794520547945]\n",
      "After 150 batches: [time:16.0m 32.81110739707947s, Accuracy: 76.5728476821192]\n",
      "After 155 batches: [time:17.0m 7.574171304702759s, Accuracy: 76.36217948717949]\n",
      "After 160 batches: [time:17.0m 44.469146490097046s, Accuracy: 76.63043478260869]\n",
      "After 165 batches: [time:18.0m 24.937692403793335s, Accuracy: 76.80722891566265]\n",
      "After 170 batches: [time:19.0m 5.106003999710083s, Accuracy: 76.68128654970761]\n",
      "After 175 batches: [time:19.0m 45.22581124305725s, Accuracy: 76.63352272727273]\n",
      "After 180 batches: [time:20.0m 26.585647106170654s, Accuracy: 76.58839779005525]\n",
      "After 185 batches: [time:21.0m 6.502318620681763s, Accuracy: 76.14247311827957]\n",
      "After 190 batches: [time:21.0m 46.3925883769989s, Accuracy: 76.30890052356021]\n",
      "Epoch 2: [time:22.0m 10.132619857788086s, Accuracy: 76.32258064516128]\n",
      "\n",
      "Epoch: 3\n",
      "After 0 batches: [time:0.0m 9.155059576034546s, Accuracy: 75.0]\n",
      "After 5 batches: [time:0.0m 50.62136745452881s, Accuracy: 81.25]\n",
      "After 10 batches: [time:1.0m 26.412014484405518s, Accuracy: 79.54545454545455]\n",
      "After 15 batches: [time:1.0m 59.38474631309509s, Accuracy: 78.90625]\n",
      "After 20 batches: [time:2.0m 32.23869800567627s, Accuracy: 79.16666666666666]\n",
      "After 25 batches: [time:3.0m 5.405545473098755s, Accuracy: 78.36538461538461]\n",
      "After 30 batches: [time:3.0m 39.04627990722656s, Accuracy: 78.2258064516129]\n",
      "After 35 batches: [time:4.0m 13.36638331413269s, Accuracy: 77.77777777777779]\n",
      "After 40 batches: [time:4.0m 48.11301946640015s, Accuracy: 77.4390243902439]\n",
      "After 45 batches: [time:5.0m 25.77015709877014s, Accuracy: 77.17391304347827]\n",
      "After 50 batches: [time:6.0m 1.3959071636199951s, Accuracy: 76.9607843137255]\n",
      "After 55 batches: [time:6.0m 38.54371762275696s, Accuracy: 75.44642857142857]\n",
      "After 60 batches: [time:7.0m 13.904494047164917s, Accuracy: 76.02459016393442]\n",
      "After 65 batches: [time:7.0m 46.93787741661072s, Accuracy: 76.70454545454545]\n",
      "After 70 batches: [time:8.0m 20.55033040046692s, Accuracy: 76.93661971830986]\n",
      "After 75 batches: [time:8.0m 55.98988103866577s, Accuracy: 76.80921052631578]\n",
      "After 80 batches: [time:9.0m 33.551273345947266s, Accuracy: 76.85185185185185]\n",
      "After 85 batches: [time:10.0m 8.628241062164307s, Accuracy: 76.30813953488372]\n",
      "After 90 batches: [time:10.0m 42.02301788330078s, Accuracy: 75.96153846153845]\n",
      "After 95 batches: [time:11.0m 17.499534368515015s, Accuracy: 76.43229166666666]\n",
      "After 100 batches: [time:11.0m 55.287917137145996s, Accuracy: 76.36138613861387]\n",
      "After 105 batches: [time:12.0m 31.14990782737732s, Accuracy: 76.41509433962264]\n",
      "After 110 batches: [time:13.0m 6.869061708450317s, Accuracy: 76.91441441441441]\n",
      "After 115 batches: [time:13.0m 41.322675704956055s, Accuracy: 77.26293103448276]\n",
      "After 120 batches: [time:14.0m 14.556873559951782s, Accuracy: 77.1694214876033]\n",
      "After 125 batches: [time:14.0m 48.93395972251892s, Accuracy: 76.98412698412699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 130 batches: [time:15.0m 23.447776317596436s, Accuracy: 77.29007633587787]\n",
      "After 135 batches: [time:15.0m 58.23106050491333s, Accuracy: 77.38970588235294]\n",
      "After 140 batches: [time:16.0m 33.97181844711304s, Accuracy: 77.5709219858156]\n",
      "After 145 batches: [time:17.0m 8.083204746246338s, Accuracy: 77.48287671232876]\n",
      "After 150 batches: [time:17.0m 43.183367013931274s, Accuracy: 77.73178807947019]\n",
      "After 155 batches: [time:18.0m 18.05455994606018s, Accuracy: 77.80448717948718]\n",
      "After 160 batches: [time:18.0m 55.9086229801178s, Accuracy: 78.1832298136646]\n",
      "After 165 batches: [time:19.0m 36.53520750999451s, Accuracy: 77.9367469879518]\n",
      "After 170 batches: [time:20.0m 20.385863304138184s, Accuracy: 77.7046783625731]\n",
      "After 175 batches: [time:21.0m 0.47502851486206055s, Accuracy: 77.8409090909091]\n",
      "After 180 batches: [time:21.0m 42.374263763427734s, Accuracy: 77.69337016574586]\n",
      "After 185 batches: [time:22.0m 24.888774394989014s, Accuracy: 77.95698924731182]\n",
      "After 190 batches: [time:23.0m 6.855179309844971s, Accuracy: 77.87958115183245]\n",
      "Epoch 3: [time:23.0m 28.02930974960327s, Accuracy: 77.93548387096774]\n",
      "\n",
      "Epoch: 4\n",
      "After 0 batches: [time:0.0m 7.251220941543579s, Accuracy: 75.0]\n",
      "After 5 batches: [time:0.0m 44.376638412475586s, Accuracy: 87.5]\n",
      "After 10 batches: [time:1.0m 21.809298992156982s, Accuracy: 80.68181818181817]\n",
      "After 15 batches: [time:2.0m 3.914595603942871s, Accuracy: 80.46875]\n",
      "After 20 batches: [time:2.0m 48.51365542411804s, Accuracy: 79.76190476190477]\n",
      "After 25 batches: [time:3.0m 32.69817137718201s, Accuracy: 80.28846153846155]\n",
      "After 30 batches: [time:4.0m 14.532347679138184s, Accuracy: 78.2258064516129]\n",
      "After 35 batches: [time:4.0m 56.20988702774048s, Accuracy: 78.81944444444444]\n",
      "After 40 batches: [time:5.0m 33.838144302368164s, Accuracy: 78.96341463414635]\n",
      "After 45 batches: [time:6.0m 14.73709225654602s, Accuracy: 79.61956521739131]\n",
      "After 50 batches: [time:6.0m 53.18079900741577s, Accuracy: 79.90196078431373]\n",
      "After 55 batches: [time:7.0m 31.16705012321472s, Accuracy: 79.46428571428571]\n",
      "After 60 batches: [time:8.0m 10.931133270263672s, Accuracy: 79.30327868852459]\n",
      "After 65 batches: [time:8.0m 51.45580816268921s, Accuracy: 78.97727272727273]\n",
      "After 70 batches: [time:9.0m 32.38703680038452s, Accuracy: 78.52112676056338]\n",
      "After 75 batches: [time:10.0m 13.299934148788452s, Accuracy: 78.61842105263158]\n",
      "After 80 batches: [time:10.0m 54.92875385284424s, Accuracy: 78.39506172839506]\n",
      "After 85 batches: [time:11.0m 34.61589980125427s, Accuracy: 78.48837209302324]\n",
      "After 90 batches: [time:12.0m 15.00973391532898s, Accuracy: 78.02197802197803]\n",
      "After 95 batches: [time:12.0m 55.552191495895386s, Accuracy: 77.34375]\n",
      "After 100 batches: [time:13.0m 37.60259556770325s, Accuracy: 77.5990099009901]\n",
      "After 105 batches: [time:14.0m 16.513962745666504s, Accuracy: 77.24056603773585]\n",
      "After 110 batches: [time:15.0m 27.939842462539673s, Accuracy: 77.36486486486487]\n",
      "After 115 batches: [time:16.0m 17.849287748336792s, Accuracy: 77.26293103448276]\n",
      "After 120 batches: [time:17.0m 3.8342292308807373s, Accuracy: 77.1694214876033]\n",
      "After 125 batches: [time:17.0m 49.714014291763306s, Accuracy: 76.68650793650794]\n",
      "After 130 batches: [time:18.0m 33.83204007148743s, Accuracy: 76.43129770992367]\n",
      "After 135 batches: [time:19.0m 20.783764839172363s, Accuracy: 76.83823529411765]\n",
      "After 140 batches: [time:20.0m 6.782188415527344s, Accuracy: 77.21631205673759]\n",
      "After 145 batches: [time:20.0m 55.85782980918884s, Accuracy: 76.79794520547945]\n",
      "After 150 batches: [time:21.0m 46.19719648361206s, Accuracy: 76.40728476821192]\n",
      "After 155 batches: [time:22.0m 35.893977880477905s, Accuracy: 75.96153846153845]\n",
      "After 160 batches: [time:23.0m 26.2612087726593s, Accuracy: 76.00931677018633]\n",
      "After 165 batches: [time:24.0m 17.250771045684814s, Accuracy: 75.9789156626506]\n",
      "After 170 batches: [time:25.0m 5.856421947479248s, Accuracy: 75.95029239766082]\n",
      "After 175 batches: [time:25.0m 55.00214099884033s, Accuracy: 76.42045454545455]\n",
      "After 180 batches: [time:26.0m 46.42534375190735s, Accuracy: 76.51933701657458]\n",
      "After 185 batches: [time:27.0m 32.081562519073486s, Accuracy: 76.47849462365592]\n",
      "After 190 batches: [time:28.0m 19.94834542274475s, Accuracy: 76.57068062827224]\n",
      "Epoch 4: [time:28.0m 47.865150451660156s, Accuracy: 76.64516129032258]\n",
      "\n",
      "Epoch: 5\n",
      "After 0 batches: [time:0.0m 9.846286058425903s, Accuracy: 87.5]\n",
      "After 5 batches: [time:0.0m 58.994340896606445s, Accuracy: 83.33333333333334]\n",
      "After 10 batches: [time:1.0m 49.0293231010437s, Accuracy: 77.27272727272727]\n",
      "After 15 batches: [time:2.0m 38.36707663536072s, Accuracy: 75.78125]\n",
      "After 20 batches: [time:3.0m 27.040099620819092s, Accuracy: 73.80952380952381]\n",
      "After 25 batches: [time:4.0m 10.748764038085938s, Accuracy: 75.48076923076923]\n",
      "After 30 batches: [time:4.0m 58.741559982299805s, Accuracy: 75.0]\n",
      "After 35 batches: [time:5.0m 48.460469007492065s, Accuracy: 72.91666666666666]\n",
      "After 40 batches: [time:6.0m 38.62861251831055s, Accuracy: 73.47560975609755]\n",
      "After 45 batches: [time:7.0m 29.336771726608276s, Accuracy: 73.91304347826086]\n",
      "After 50 batches: [time:8.0m 18.53724193572998s, Accuracy: 74.01960784313727]\n",
      "After 55 batches: [time:9.0m 4.52540397644043s, Accuracy: 74.10714285714286]\n",
      "After 60 batches: [time:9.0m 50.90356802940369s, Accuracy: 74.18032786885246]\n",
      "After 65 batches: [time:10.0m 41.05679941177368s, Accuracy: 75.0]\n",
      "After 70 batches: [time:11.0m 29.98490619659424s, Accuracy: 75.35211267605634]\n",
      "After 75 batches: [time:12.0m 19.94546675682068s, Accuracy: 75.32894736842105]\n",
      "After 80 batches: [time:13.0m 10.131072282791138s, Accuracy: 76.08024691358025]\n",
      "After 85 batches: [time:14.0m 0.12316393852233887s, Accuracy: 76.30813953488372]\n",
      "After 90 batches: [time:14.0m 49.580995321273804s, Accuracy: 76.0989010989011]\n",
      "After 95 batches: [time:15.0m 39.032150983810425s, Accuracy: 76.82291666666666]\n",
      "After 100 batches: [time:16.0m 27.89710831642151s, Accuracy: 76.60891089108911]\n",
      "After 105 batches: [time:17.0m 17.706428050994873s, Accuracy: 76.41509433962264]\n",
      "After 110 batches: [time:18.0m 1.358293056488037s, Accuracy: 76.57657657657657]\n",
      "After 115 batches: [time:18.0m 46.2732937335968s, Accuracy: 76.83189655172413]\n",
      "After 120 batches: [time:19.0m 30.923227787017822s, Accuracy: 76.75619834710744]\n",
      "After 125 batches: [time:20.0m 12.94347858428955s, Accuracy: 77.18253968253968]\n",
      "After 130 batches: [time:20.0m 52.06124234199524s, Accuracy: 77.09923664122137]\n",
      "After 135 batches: [time:21.0m 33.205219745635986s, Accuracy: 77.29779411764706]\n",
      "After 140 batches: [time:22.0m 13.418081283569336s, Accuracy: 77.48226950354609]\n",
      "After 145 batches: [time:22.0m 55.57049918174744s, Accuracy: 77.48287671232876]\n",
      "After 150 batches: [time:23.0m 37.2614209651947s, Accuracy: 77.48344370860927]\n",
      "After 155 batches: [time:24.0m 20.015755653381348s, Accuracy: 77.32371794871796]\n",
      "After 160 batches: [time:25.0m 0.6154158115386963s, Accuracy: 77.63975155279503]\n",
      "After 165 batches: [time:25.0m 39.93652129173279s, Accuracy: 78.08734939759037]\n",
      "After 170 batches: [time:26.0m 24.05852961540222s, Accuracy: 78.28947368421053]\n",
      "After 175 batches: [time:27.0m 8.543457269668579s, Accuracy: 77.8409090909091]\n",
      "After 180 batches: [time:27.0m 48.59045958518982s, Accuracy: 77.62430939226519]\n",
      "After 185 batches: [time:28.0m 33.436665058135986s, Accuracy: 77.62096774193549]\n",
      "After 190 batches: [time:29.0m 18.576091051101685s, Accuracy: 77.5523560209424]\n",
      "Epoch 5: [time:29.0m 42.99194025993347s, Accuracy: 77.54838709677419]\n",
      "\n",
      "Training time: 124.0m 33.80122208595276s\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "t = time.time()\n",
    "for i in range(num_epoch):\n",
    "    print(f'Epoch: {i+1}')\n",
    "    t_epoch = time.time()\n",
    "    total_labels = 0\n",
    "    correctly_pred = 0\n",
    "    t_batch = time.time()\n",
    "    for j, (data, labels) in enumerate(train_dataloader):\n",
    "#         torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "#         data, labels = data.to(device), labels.to(device)\n",
    "        X, y = data, labels\n",
    "        optimizer.zero_grad()\n",
    "        output = net(X)\n",
    "        loss = loss_evaluater(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred = torch.argmax(output, dim=1)\n",
    "        total_labels += y.size(0)\n",
    "        correctly_pred += (y_pred==y).sum().item()\n",
    "        current_acc = (correctly_pred/total_labels)\n",
    "        if j%5==0:\n",
    "            seconds_passed = time.time()-t_batch\n",
    "            print(f'After {j} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "    epoch_acc = (correctly_pred/total_labels)\n",
    "    seconds_passed = time.time()-t_epoch\n",
    "    print(f'Epoch {i+1}: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {epoch_acc*100}]')\n",
    "    print()\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Training time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 batches: [time:0.0m 3.3356618881225586s, Accuracy: 100.0]\n",
      "After 5 batches: [time:0.0m 18.053566694259644s, Accuracy: 83.33333333333334]\n",
      "After 10 batches: [time:0.0m 33.65128540992737s, Accuracy: 82.95454545454545]\n",
      "After 15 batches: [time:0.0m 50.005255460739136s, Accuracy: 83.59375]\n",
      "After 20 batches: [time:1.0m 7.13040828704834s, Accuracy: 82.73809523809523]\n",
      "After 25 batches: [time:1.0m 23.544406414031982s, Accuracy: 83.17307692307693]\n",
      "After 30 batches: [time:1.0m 40.080196142196655s, Accuracy: 81.45161290322581]\n",
      "After 35 batches: [time:1.0m 57.712846755981445s, Accuracy: 81.94444444444444]\n",
      "After 40 batches: [time:2.0m 14.771364212036133s, Accuracy: 82.6219512195122]\n",
      "After 45 batches: [time:2.0m 31.99657654762268s, Accuracy: 82.33695652173914]\n",
      "After 50 batches: [time:2.0m 49.20467662811279s, Accuracy: 81.61764705882352]\n",
      "After 55 batches: [time:3.0m 6.0036303997039795s, Accuracy: 80.35714285714286]\n",
      "After 60 batches: [time:3.0m 21.27405309677124s, Accuracy: 78.48360655737704]\n",
      "After 65 batches: [time:3.0m 37.87223172187805s, Accuracy: 78.21969696969697]\n",
      "After 70 batches: [time:3.0m 54.969146966934204s, Accuracy: 78.87323943661971]\n",
      "After 75 batches: [time:4.0m 11.498555660247803s, Accuracy: 79.27631578947368]\n",
      "After 80 batches: [time:4.0m 28.237923860549927s, Accuracy: 78.85802469135803]\n",
      "After 85 batches: [time:4.0m 45.52359104156494s, Accuracy: 79.21511627906976]\n",
      "After 90 batches: [time:5.0m 2.9486162662506104s, Accuracy: 79.67032967032966]\n",
      "After 95 batches: [time:5.0m 19.882969617843628s, Accuracy: 79.55729166666666]\n",
      "After 100 batches: [time:5.0m 36.39998769760132s, Accuracy: 79.33168316831683]\n",
      "After 105 batches: [time:5.0m 53.0203857421875s, Accuracy: 79.12735849056604]\n",
      "After 110 batches: [time:6.0m 9.506227493286133s, Accuracy: 79.27927927927928]\n",
      "After 115 batches: [time:6.0m 26.533411741256714s, Accuracy: 79.3103448275862]\n",
      "After 120 batches: [time:6.0m 43.77591037750244s, Accuracy: 79.23553719008265]\n",
      "After 125 batches: [time:7.0m 0.5691916942596436s, Accuracy: 79.26587301587301]\n",
      "After 130 batches: [time:7.0m 17.33233666419983s, Accuracy: 79.1030534351145]\n",
      "After 135 batches: [time:7.0m 34.070141077041626s, Accuracy: 79.22794117647058]\n",
      "After 140 batches: [time:7.0m 50.75395488739014s, Accuracy: 79.07801418439716]\n",
      "After 145 batches: [time:8.0m 7.953128099441528s, Accuracy: 79.45205479452055]\n",
      "After 150 batches: [time:8.0m 25.418269634246826s, Accuracy: 79.63576158940397]\n",
      "After 155 batches: [time:8.0m 42.968403339385986s, Accuracy: 79.7275641025641]\n",
      "After 160 batches: [time:8.0m 59.920493364334106s, Accuracy: 79.8136645962733]\n",
      "After 165 batches: [time:9.0m 17.03219723701477s, Accuracy: 79.81927710843374]\n",
      "After 170 batches: [time:9.0m 33.957173347473145s, Accuracy: 79.60526315789474]\n",
      "After 175 batches: [time:9.0m 51.337926149368286s, Accuracy: 79.82954545454545]\n",
      "After 180 batches: [time:10.0m 8.947852373123169s, Accuracy: 79.97237569060773]\n",
      "After 185 batches: [time:10.0m 26.115593194961548s, Accuracy: 79.83870967741935]\n",
      "After 190 batches: [time:10.0m 43.02615165710449s, Accuracy: 79.97382198952879]\n",
      "Training accuracy: 80.06451612903226\n",
      "Trainig evaluation time: 10.0m 52.250762701034546s\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "t = time.time()\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_labels = 0\n",
    "    correctly_pred = 0\n",
    "    t_batch = time.time()\n",
    "    for i, (data, labels) in enumerate(train_dataloader):\n",
    "#         data,labels = data.to(device), labels.to(device)\n",
    "        gc.collect()\n",
    "        X, y = data, labels\n",
    "        output = net(X)\n",
    "        y_pred = torch.argmax(output, dim=1)\n",
    "        total_labels += y.size(0)\n",
    "        correctly_pred += (y_pred==y).sum().item()\n",
    "        current_acc = (correctly_pred/total_labels)\n",
    "        if i%5==0:\n",
    "            seconds_passed = time.time()-t_batch\n",
    "            print(f'After {i} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "    train_acc = (correctly_pred/total_labels)\n",
    "    print(f'Training accuracy: {train_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "\n",
    "print(f'Trainig evaluation time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 batches: [time:0.0m 3.2525296211242676s, Accuracy: 100.0]\n",
      "After 5 batches: [time:6.0m 56.673192262649536s, Accuracy: 77.08333333333334]\n",
      "After 10 batches: [time:10.0m 43.78805637359619s, Accuracy: 77.27272727272727]\n",
      "After 15 batches: [time:11.0m 8.210622310638428s, Accuracy: 77.34375]\n",
      "After 20 batches: [time:11.0m 29.31381869316101s, Accuracy: 74.40476190476191]\n",
      "After 25 batches: [time:11.0m 46.50768709182739s, Accuracy: 73.5576923076923]\n",
      "After 30 batches: [time:11.0m 59.85336470603943s, Accuracy: 74.59677419354838]\n",
      "After 35 batches: [time:12.0m 12.875742435455322s, Accuracy: 74.30555555555556]\n",
      "Test accuracy: 73.33333333333333\n",
      "Test time: 12.0m 17.54648995399475s\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "net.eval()\n",
    "\n",
    "t = time.time()\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "total_labels = 0\n",
    "correctly_pred = 0\n",
    "t_batch = time.time()\n",
    "for i, (data, labels) in enumerate(test_dataloader):\n",
    "#     torch.cuda.empty_cache()\n",
    "#     data, labels = data.to(device), labels.to(device)\n",
    "    gc.collect()\n",
    "    X, y = data, labels\n",
    "    output = net(X)\n",
    "    y_pred = torch.argmax(output, dim=1)\n",
    "    total_labels += y.size(0)\n",
    "    correctly_pred += (y_pred==y).sum().item()\n",
    "    current_acc = (correctly_pred/total_labels)\n",
    "    if i%5==0:\n",
    "        seconds_passed = time.time()-t_batch\n",
    "        print(f'After {i} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "\n",
    "test_acc = (correctly_pred/total_labels)\n",
    "print(f'Test accuracy: {test_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Test time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Saving pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "file_path = './temp/net_6.pt'\n",
    "\n",
    "state = {\n",
    "    'epoch': num_epoch,\n",
    "    'state_dict': net.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'lr': lr,\n",
    "    'momentum': momentum\n",
    "}\n",
    "\n",
    "torch.save(state, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Loading Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "state = torch.load(file_path)\n",
    "\n",
    "loaded_net = ProjectModel()\n",
    "loaded_loss_evaluater = CrossEntropyLoss()\n",
    "loaded_optimizer = SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "loaded_num_epoch = state['epoch']\n",
    "loaded_lr = state['lr']\n",
    "loaded_momentum = state['momentum']\n",
    "loaded_net.load_state_dict(state['state_dict'])\n",
    "loaded_optimizer.load_state_dict(state['optimizer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing loaded pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 batches: [time:0.0m 5.167317628860474s, Accuracy: 100.0]\n",
      "After 5 batches: [time:0.0m 22.566511392593384s, Accuracy: 77.08333333333334]\n",
      "After 10 batches: [time:0.0m 35.97054624557495s, Accuracy: 77.27272727272727]\n",
      "After 15 batches: [time:0.0m 50.326696157455444s, Accuracy: 77.34375]\n",
      "After 20 batches: [time:1.0m 2.638129472732544s, Accuracy: 74.40476190476191]\n",
      "After 25 batches: [time:1.0m 15.515797853469849s, Accuracy: 73.5576923076923]\n",
      "After 30 batches: [time:1.0m 28.419474363327026s, Accuracy: 74.59677419354838]\n",
      "After 35 batches: [time:1.0m 42.75859594345093s, Accuracy: 74.30555555555556]\n",
      "Test accuracy: 73.33333333333333\n",
      "Test time: 1.0m 47.81209325790405s\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "loaded_net.eval()\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "total_labels = 0\n",
    "correctly_pred = 0\n",
    "t_batch = time.time()\n",
    "for i, (data, labels) in enumerate(test_dataloader):\n",
    "#     torch.cuda.empty_cache()\n",
    "#     data, labels = data.to(device), labels.to(device)\n",
    "    gc.collect()\n",
    "    X, y = data, labels\n",
    "    output = loaded_net(X)\n",
    "    y_pred = torch.argmax(output, dim=1)\n",
    "    total_labels += y.size(0)\n",
    "    correctly_pred += (y_pred==y).sum().item()\n",
    "    current_acc = (correctly_pred/total_labels)\n",
    "    if i%5==0:\n",
    "        seconds_passed = time.time()-t_batch\n",
    "        print(f'After {i} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "\n",
    "test_acc = (correctly_pred/total_labels)\n",
    "print(f'Test accuracy: {test_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Test time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy for the model is {test_acc*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision for the model is {test_precision*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Recall for the model is {test_recall*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'F1 score for the model is {test_f1*100} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
