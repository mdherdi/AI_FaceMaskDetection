{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2642\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "'''\n",
    "LABEL 0 : NON - MASKED PERSON\n",
    "LABEL 1: MASKED PERSON\n",
    "\n",
    "'''\n",
    "person_no_mask_labels = {'eyeglasses','face_no_mask','face_other_covering','hat','sunglasses','turban'}\n",
    "not_person = 'not_person'\n",
    "\n",
    "with open('Labels.csv','w',newline='') as file:\n",
    "    wr = csv.writer(file,delimiter=',')    \n",
    "    wr.writerow(['ImageNo','Label','Tags'])\n",
    "    \n",
    "\n",
    "path_to_dataset = 'D:\\pravesh\\\\Concordia\\\\2021-Winter\\\\COMP-6721-Intro_To_AI\\\\project\\\\1\\dataset\\\\'\n",
    "image_file_names= [i for i in os.listdir(path_to_dataset+'images')]\n",
    "\n",
    "rows = []\n",
    "for index, image_name  in enumerate(image_file_names):\n",
    "    path_to_json = path_to_dataset + 'annotations\\\\' + image_name + '.json'\n",
    "    data = json.load(open(path_to_json))\n",
    "    image_tags = set()\n",
    "    label = 0\n",
    "    for item in data['Annotations']:\n",
    "        image_tags.add(item['classname'])\n",
    "    rows.append((image_name, image_tags))\n",
    "\n",
    "print(len(rows))\n",
    "\n",
    "with open('Labels.csv','a',newline='') as file:\n",
    "    for image_name, image_tags in rows:\n",
    "        label = 0\n",
    "        if not_person in image_tags:\n",
    "            label = 2\n",
    "        elif len(image_tags & person_no_mask_labels)>0:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        wr = csv.writer(file,delimiter=',') \n",
    "        wr.writerow([image_name, label, ','.join(image_tags)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List down categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are 6435.jpg, 1, {'face_with_mask_incorrect', 'mask_surgical'}\n",
      "Processed 1700 lines.\n",
      "{'mask_surgical', 'face_with_mask_incorrect', 'goggles', 'hair_net', 'balaclava_ski_mask', 'eyeglasses', 'sunglasses', 'other', 'hijab_niqab', 'face_other_covering', 'hood', 'helmet', 'mask_colorful', 'face_shield', 'hat', 'turban', 'face_with_mask', 'face_no_mask', 'scarf_bandana', 'gas_mask'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "tags = set()\n",
    "\n",
    "with open('Labels.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for (name, label, image_tags) in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "#             print(f'{name}, {label}, {image_tags}')\n",
    "            tags = tags | set(image_tags.split(','))\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregate with categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are ImageNo, Label, Tags\n",
      "Processed 3649 lines.\n",
      "3648\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "tags = {'mask_surgical', 'face_with_mask_incorrect', 'goggles', 'hair_net'\n",
    "        , 'balaclava_ski_mask', 'eyeglasses', 'sunglasses', 'other'\n",
    "        , 'hijab_niqab', 'face_other_covering', 'hood', 'helmet'\n",
    "        , 'mask_colorful', 'face_shield', 'hat', 'turban', 'face_with_mask'\n",
    "        , 'face_no_mask', 'scarf_bandana', 'gas_mask'}\n",
    "\n",
    "rows = []\n",
    "\n",
    "path_to_dataset = 'D:\\pravesh\\\\Concordia\\\\2021-Winter\\\\COMP-6721-Intro_To_AI\\\\project\\\\1\\dataset\\\\'\n",
    "\n",
    "with open('Labels.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "#             print(f'{name}, {label}, {image_tags}')\n",
    "            rows.append(row)\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n",
    "\n",
    "print(len(rows))\n",
    "\n",
    "for tag in tags:\n",
    "    path_to_tag_directory = path_to_dataset + 'images\\\\' + tag\n",
    "    if not os.path.isdir(path_to_tag_directory):\n",
    "        os.mkdir(path_to_tag_directory)\n",
    "    for (name, _, image_tags) in rows:\n",
    "        path_to_file = path_to_dataset + 'images\\\\' + name\n",
    "#         print(path_to_file)\n",
    "#         print(os.path.isfile(path_to_file))\n",
    "        if os.path.isfile(path_to_file):\n",
    "            if tag in image_tags:\n",
    "                new_file_path = path_to_tag_directory+'\\\\'+ name\n",
    "#                 print(path_to_file, new_file_path)\n",
    "                os.rename(path_to_file, new_file_path)\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask 1749 3\n",
      "not_person 450 3\n",
      "no_mask 892 3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "'''\n",
    "LABEL 0 : NON - MASKED PERSON\n",
    "LABEL 1: MASKED PERSON\n",
    "\n",
    "'''\n",
    "person_no_mask_labels = {'eyeglasses','face_no_mask','face_other_covering','hat','sunglasses','turban'}\n",
    "label_map = {'mask': 0,\n",
    "            'no_mask': 1,\n",
    "            'not_person': 2}\n",
    "    \n",
    "\n",
    "path_to_dataset = 'D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/1/dataset/'\n",
    "\n",
    "images_dir = path_to_dataset+'images/'\n",
    "\n",
    "dir_names= [i for i in os.listdir(images_dir)]\n",
    "\n",
    "rows = {0: [], 1:[], 2:[]}\n",
    "for index, dir_name in enumerate(dir_names):\n",
    "    count=0\n",
    "    label = label_map[dir_name]\n",
    "    dir_path = images_dir + dir_name + '/'\n",
    "    image_names= [i for i in os.listdir(dir_path)]\n",
    "    for index, image_name  in enumerate(image_names):\n",
    "        path_to_json = path_to_dataset + 'annotations/' + image_name + '.json'\n",
    "        data = json.load(open(path_to_json))\n",
    "        image_tags = set()\n",
    "        for item in data['Annotations']:\n",
    "            image_tags.add(item['classname'])\n",
    "        rows[label].append((dir_name+'/'+image_name, label, image_tags))\n",
    "        count+=1\n",
    "    print(dir_name, count, len(rows))\n",
    "        \n",
    "print(len(rows))\n",
    "\n",
    "test_label_file = path_to_dataset+'test_label_info.csv'\n",
    "\n",
    "with open(test_label_file,'w',newline='') as file:\n",
    "    wr = csv.writer(file,delimiter=',')    \n",
    "    wr.writerow(['ImageNo','Label','Tags'])\n",
    "\n",
    "with open(test_label_file,'a',newline='') as file:\n",
    "    wr = csv.writer(file,delimiter=',')\n",
    "    for i in range(3):\n",
    "        label_rows = rows[i]\n",
    "        for j in range(100):\n",
    "            image, label, image_tags = label_rows[j]\n",
    "            wr.writerow([image, label])\n",
    "            \n",
    "train_label_file = path_to_dataset+'train_label_info.csv'\n",
    "\n",
    "with open(train_label_file,'w',newline='') as file:\n",
    "    wr = csv.writer(file,delimiter=',')    \n",
    "    wr.writerow(['ImageNo','Label','Tags'])      \n",
    "            \n",
    "with open(train_label_file,'a',newline='') as file:\n",
    "    wr = csv.writer(file,delimiter=',')\n",
    "    for i in range(3):\n",
    "        label_rows = rows[i]\n",
    "        for j in range(100, 100+350, 1):\n",
    "            image, label, image_tags = label_rows[j]\n",
    "            wr.writerow([image, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-b180bc99e072>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mProjectDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Face Landmarks dataset.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_info_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class ProjectDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, debug=False):\n",
    "        self.label_info_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.debug = debug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_info_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        label_img_name = self.label_info_frame.iloc[idx, 0]\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                label_img_name)\n",
    "        image = io.imread(img_name)\n",
    "        label = self.label_info_frame.iloc[idx, 1]\n",
    "        label = np.array([label])\n",
    "        landmarks = label.astype('float').reshape(-1, 1)\n",
    "        sample = {'image': image\n",
    "                  ,'label': label\n",
    "                  ,'name': label_img_name}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        if self.debug:\n",
    "            print(label_img_name)\n",
    "\n",
    "        return sample\n",
    "\n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int))\n",
    "        self.output_size = output_size\n",
    "        self.debug = False\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size, self.output_size * w / h\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "        \n",
    "        # Clipping or filling\n",
    "        if new_w>self.output_size:\n",
    "            mid = new_w//2\n",
    "            new_w_start = mid-self.output_size//2\n",
    "            new_w_end = mid+self.output_size//2\n",
    "            \n",
    "            if (new_w_end-new_w_start)<self.output_size:\n",
    "                new_w_end += (self.output_size-(new_w_end-new_w_start))\n",
    "            elif (new_w_end-new_w_start)>self.output_size:\n",
    "                new_w_end -= ((new_w_end-new_w_start)-self.output_size)\n",
    "            img = img[:, new_w_start:new_w_end]\n",
    "        elif new_w<self.output_size:\n",
    "            mid = new_w//2\n",
    "            new_w_start = self.output_size//2-mid\n",
    "            new_w_end = new_w_start+new_w\n",
    "            filled_img = np.zeros((self.output_size, self.output_size, img.shape[2]))\n",
    "            filled_img[:, new_w_start:new_w_end] = img[:, :]\n",
    "            img = filled_img\n",
    "        if self.debug:\n",
    "            root_dir = dataset.root_dir \n",
    "            copy_dir = root_dir+'rescaled/'\n",
    "            img_name = sample['name']\n",
    "            if not os.path.isdir(copy_dir):\n",
    "                os.mkdir(copy_dir)\n",
    "            label_dir_name = img_name.split('\\\\')[0]\n",
    "            label_dir_path = copy_dir + label_dir_name + '/'\n",
    "            if not os.path.isdir(label_dir_path):\n",
    "                os.mkdir(label_dir_path)\n",
    "            path_to_rescaled_img = copy_dir + img_name\n",
    "            io.imsave(path_to_rescaled_img, img, check_contrast=False)\n",
    "        \n",
    "        return {'image': img, 'label': label}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'label': torch.from_numpy(label)}\n",
    "    \n",
    "    \n",
    "class ConvertToType(object):\n",
    "    def __init__(self, conversion_type, debug=False):\n",
    "        self.conversion_type = conversion_type\n",
    "        self.debug = debug\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return img.type(self.conversion_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ProjectDataset(\n",
    "    csv_file='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/comp-6721-project/label_info.csv'\n",
    "    ,root_dir='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/1/dataset/images/')\n",
    "print(len(dataset))\n",
    "\n",
    "output_height = 512\n",
    "\n",
    "scale = Rescale(output_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "counts = np.zeros((100, ))\n",
    "label_counts = {0: np.zeros((100, ))\n",
    "                , 1: np.zeros((100, ))\n",
    "                , 2:np.zeros((100, ))}\n",
    "\n",
    "dataset.debug=False\n",
    "scale.debug=True\n",
    "t1 = time.time()\n",
    "max_w, max_h = 0, 0\n",
    "min_w, min_h = 1000000, 100000\n",
    "count = 0\n",
    "for k in range(5):\n",
    "    sample = dataset[k]\n",
    "    sample_image = sample['image']\n",
    "    label = sample['label'][0]\n",
    "    print(sample['name'], sample_image.shape)\n",
    "    \n",
    "    h, w, _ = sample_image.shape\n",
    "    if w>max_w:\n",
    "        max_w = w\n",
    "    if h>max_h:\n",
    "        max_h = h\n",
    "    if w<min_w:\n",
    "        min_w = w\n",
    "    if h<min_h:\n",
    "        min_h = h\n",
    "    index = w//100\n",
    "    counts[index]+=1\n",
    "    label_counts[label][index]+=1\n",
    "    \n",
    "    transformed_sample = scale(sample)\n",
    "    image = transformed_sample['image']\n",
    "    print(sample['name'], image.shape)\n",
    "    plt.figure()\n",
    "#     image = image.astype(np.uint8)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    count+=1\n",
    "    if count%100==0:\n",
    "        gc.collect()\n",
    "        print(count)\n",
    "        print((time.time()-t1))\n",
    "    \n",
    "print((time.time()-t1))\n",
    "print(max_w, max_h, min_w, min_h)\n",
    "print(counts)\n",
    "for key in label_counts:\n",
    "    print(key, label_counts[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = ProjectDataset(csv_file='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/comp-6721-project/label_info.csv'\n",
    "                                     ,root_dir='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/1/dataset/images/'\n",
    "                                     ,transform=transforms.Compose([\n",
    "                                         Rescale(512)\n",
    "                                         ,ToTensor()\n",
    "                                     ]))\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(dataset)\n",
    "X = np.zeros((dataset_size, output_height, output_height, 3), dtype=np.float32)\n",
    "y = np.zeros((dataset_size, 1), dtype=np.int32)\n",
    "for k in range(dataset_size):\n",
    "    sample = dataset[k]\n",
    "    sample_image, label = sample['image'], sample['label'][0]\n",
    "    \n",
    "    transformed_sample = scale(sample)\n",
    "    image = transformed_sample['image']\n",
    "    X[k] = image\n",
    "    y[k] = label\n",
    "np.savez_compressed('X.npz', X)\n",
    "np.savez_compressed('y.npz', y)\n",
    "print('Done converting to Numpy arrays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 29.644351959228516+(13*60)\n",
    "int(x//60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Conv2d, MaxPool2d, Linear, ReLU\n",
    "\n",
    "class ProjectModel(Module):\n",
    "    def __init__(self):\n",
    "        super(ProjectModel, self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=2)\n",
    "        self.pool1 = MaxPool2d(2)\n",
    "        self.conv2 = Conv2d(in_channels=16, out_channels = 32, kernel_size=3)\n",
    "        self.linear = Linear(in_features = 32*125*125, out_features=3)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        relu = ReLU(inplace=True)\n",
    "        X = self.conv1(X)\n",
    "        X = relu(X)\n",
    "        X = self.pool1(X)\n",
    "        X = self.conv2(X)\n",
    "        X = relu(X)\n",
    "        X = torch.flatten(X, 1)\n",
    "        X = self.linear(X)\n",
    "        return X\n",
    "\n",
    "net = ProjectModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x15f31387400>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=0)\n",
    "clf = SVC(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:comp6721]",
   "language": "python",
   "name": "conda-env-comp6721-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
