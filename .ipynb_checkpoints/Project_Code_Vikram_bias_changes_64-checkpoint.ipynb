{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>\n",
    "COMP-6721 | 2021-Winter\n",
    "Project | Part-1\n",
    "\n",
    "Pravesh Gupta | 40152506\n",
    "Vikramjeet Singh | 40134477\n",
    "Manjot Kaur Dherdi | 40107905\n",
    "</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Installing required python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torch) (1.19.2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: torch==1.8.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torchvision) (1.8.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torch==1.8.0->torchvision) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (1.1.3)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from pandas) (1.19.2)\n",
      "\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vkrmj\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: torch==1.8.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torchvision) (1.8.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torch==1.8.0->torchvision) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.15.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (1.5.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (3.3.2)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (8.0.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (2020.10.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2020.6.20)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vkrmj\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (1.19.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Required Dataset Folder Heirarchy:\n",
    "<pre>\n",
    "{dataset_folder}\n",
    "--images\n",
    "----mask\n",
    "-------{mask images}\n",
    "----no_mask\n",
    "-------{no mask images}\n",
    "----not_person\n",
    "-------{not person images}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Defining Pytorch dataset Representation and data transaformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VisionDataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io as sk_io, transform as sk_transform\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "    \n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size, debug=False, export_path=None):\n",
    "        assert isinstance(output_size, (int))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, img_data):\n",
    "        img_arr = np.array(img_data)\n",
    "        h, w, c = img_arr.shape\n",
    "        isAlreadyScaled = (h==self.output_size and w==self.output_size)\n",
    "        \n",
    "        if not isAlreadyScaled:\n",
    "            scale_factor = float(self.output_size)/img_arr.shape[0]\n",
    "            img_arr = (sk_transform.rescale(img_arr, (scale_factor, scale_factor, 1))*255).astype(np.uint8)\n",
    "\n",
    "            new_w = img_arr.shape[1]\n",
    "\n",
    "            # Clipping or filling\n",
    "            if new_w>self.output_size:\n",
    "                mid = new_w//2\n",
    "                new_w_start = mid-self.output_size//2\n",
    "                new_w_end = mid+self.output_size//2\n",
    "\n",
    "                if (new_w_end-new_w_start)<self.output_size:\n",
    "                    new_w_end += (self.output_size-(new_w_end-new_w_start))\n",
    "                elif (new_w_end-new_w_start)>self.output_size:\n",
    "                    new_w_end -= ((new_w_end-new_w_start)-self.output_size)\n",
    "                img_arr = img_arr[:, new_w_start:new_w_end]\n",
    "            elif new_w<self.output_size:\n",
    "                mid = new_w//2\n",
    "                new_w_start = self.output_size//2-mid\n",
    "                new_w_end = new_w_start+new_w\n",
    "                filled_img_arr = np.zeros((self.output_size, self.output_size, img_arr.shape[2]), dtype=np.uint8)\n",
    "                filled_img_arr[:, new_w_start:new_w_end] = img_arr[:, :]\n",
    "                img_arr = filled_img_arr\n",
    "        return Image.fromarray(img_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. (Optional) Prior conversion of image to speed up training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: size: 150, class labels: {'mask': 0, 'no_mask': 1, 'not_person': 2}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "rescaled_size=64\n",
    "\n",
    "scaler = Rescale(rescaled_size)\n",
    "\n",
    "data_dir = 'D:/Courses/COMP 6721 Applied AI/Project/GitRepo/dataset_p_2_64/test_female/'\n",
    "copy_dir = 'D:/Courses/COMP 6721 Applied AI/Project/GitRepo/dataset_p_2_64/rescaled/test_female/'\n",
    "\n",
    "if not os.path.isdir(copy_dir):\n",
    "    os.mkdir(copy_dir)\n",
    "\n",
    "data_transform = Compose([\n",
    "    Rescale(rescaled_size)\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    root=data_dir\n",
    "    ,transform=data_transform\n",
    ")\n",
    "print(f'Dataset: size: {len(dataset)}, class labels: {dataset.class_to_idx}')\n",
    "\n",
    "label_to_class_dir = {}\n",
    "for class_name in dataset.class_to_idx:\n",
    "    label = dataset.class_to_idx[class_name]\n",
    "    class_dir = copy_dir + class_name + '/'\n",
    "    label_to_class_dir[label] = class_dir\n",
    "    if not os.path.isdir(class_dir):\n",
    "        os.mkdir(class_dir)\n",
    "\n",
    "for i in range(len(dataset.imgs)):\n",
    "    url, label = dataset.imgs[i]\n",
    "    img_name = url.split('\\\\')[1]\n",
    "    img_file_path = label_to_class_dir[label] + img_name\n",
    "    \n",
    "    if not os.path.isfile(img_file_path):\n",
    "        item = dataset.__getitem__(i)\n",
    "        rescaled_img = item[0]\n",
    "        rescaled_img.save(img_file_path, check_contrast=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Creating dataset and data loaders for train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From whole dataset, split and find train/test dataset data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_per_class = 600\n",
    "test_images_per_class = 100\n",
    "\n",
    "def get_train_test_indices(dataset_targets):\n",
    "    test_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        test_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    train_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        train_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    targets = np.array(dataset.targets, dtype=np.int32)\n",
    "    target_indices = np.where(targets!=None)[0]\n",
    "    np.random.shuffle(target_indices)\n",
    "\n",
    "    for i in target_indices:\n",
    "        label = dataset.targets[i]\n",
    "        if test_indices_map[label]['count']<test_images_per_class:\n",
    "            test_indices_map[label]['indices'] = np.append(test_indices_map[label]['indices'], i)\n",
    "            test_indices_map[label]['count']+=1\n",
    "        elif train_indices_map[label]['count']<train_images_per_class:\n",
    "            train_indices_map[label]['indices'] = np.append(train_indices_map[label]['indices'], i)\n",
    "            train_indices_map[label]['count']+=1\n",
    "\n",
    "    test_indices = np.array([], dtype=np.int32)\n",
    "    train_indices = np.array([], dtype=np.int32)\n",
    "\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        label_test_indices = test_indices_map[label]['indices']\n",
    "        test_indices = np.append(test_indices, label_test_indices)\n",
    "\n",
    "        label_train_indices = train_indices_map[label]['indices']\n",
    "        train_indices = np.append(train_indices, label_train_indices)\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Bias Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_per_class = 260\n",
    "test_images_per_class = 50\n",
    "\n",
    "def get_train_test_indices(dataset_targets):\n",
    "    test_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        test_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    train_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        train_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    targets = np.array(dataset.targets, dtype=np.int32)\n",
    "    target_indices = np.where(targets!=None)[0]\n",
    "    np.random.shuffle(target_indices)\n",
    "\n",
    "    for i in target_indices:\n",
    "        label = dataset.targets[i]\n",
    "        if test_indices_map[label]['count']<test_images_per_class:\n",
    "            test_indices_map[label]['indices'] = np.append(test_indices_map[label]['indices'], i)\n",
    "            test_indices_map[label]['count']+=1\n",
    "        elif train_indices_map[label]['count']<train_images_per_class:\n",
    "            train_indices_map[label]['indices'] = np.append(train_indices_map[label]['indices'], i)\n",
    "            train_indices_map[label]['count']+=1\n",
    "\n",
    "    test_indices = np.array([], dtype=np.int32)\n",
    "    train_indices = np.array([], dtype=np.int32)\n",
    "\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        label_test_indices = test_indices_map[label]['indices']\n",
    "        test_indices = np.append(test_indices, label_test_indices)\n",
    "\n",
    "        label_train_indices = train_indices_map[label]['indices']\n",
    "        train_indices = np.append(train_indices, label_train_indices)\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating mean and std for Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: size: 1560, class labels: {'mask': 0, 'no_mask': 1, 'not_person': 2}\n",
      "Mean: tensor([0.4248, 0.3925, 0.3736])\n",
      "Std: tensor([0.2651, 0.2566, 0.2677])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import gc\n",
    "\n",
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "rescaled_size=64\n",
    "train_data_dir = 'D:/Courses/COMP 6721 Applied AI/Project/GitRepo/dataset_p_2_64/rescaled/train/'\n",
    "\n",
    "data_transform = Compose([\n",
    "    Rescale(rescaled_size)\n",
    "    , ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(\n",
    "    root=train_data_dir\n",
    "    ,transform=data_transform\n",
    ")\n",
    "print(f'Dataset: size: {len(train_dataset)}, class labels: {train_dataset.class_to_idx}')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "means = torch.tensor([])\n",
    "stds = torch.tensor([])\n",
    "for i, (data, labels) in enumerate(train_dataloader):\n",
    "    gc.collect()\n",
    "    batch_mean = torch.mean(data, axis=(0, 2, 3))\n",
    "    batch_std = torch.std(data, axis=(0, 2, 3))\n",
    "    means = torch.cat((means, batch_mean.unsqueeze(0)))\n",
    "    stds = torch.cat((stds, batch_std.unsqueeze(0)))\n",
    "mean = torch.mean(means, axis=0)\n",
    "std = torch.mean(stds, axis=0)\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Std: {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating train and test dataset and data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: size: 1560\n",
      "Train X | y batch shapes : (torch.Size([8, 3, 64, 64]), torch.Size([8]))\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "data_transform = Compose([\n",
    "    Rescale(rescaled_size)\n",
    "    , ToTensor()\n",
    "    , Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(\n",
    "    root=train_data_dir\n",
    "    ,transform=data_transform\n",
    ")\n",
    "print(f'Train dataset: size: {len(train_dataset)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "for data, labels in train_dataloader:\n",
    "    print(f'Train X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset: size: 300\n",
      "Test X | y batch shapes : (torch.Size([8, 3, 64, 64]), torch.Size([8]))\n"
     ]
    }
   ],
   "source": [
    "data_dir_test = 'D:/Courses/COMP 6721 Applied AI/Project/GitRepo/dataset_p_2_64/rescaled/test_combined/'\n",
    "\n",
    "test_dataset = ImageFolder(\n",
    "    root=data_dir_test\n",
    "    ,transform=data_transform\n",
    ")\n",
    "print(f'Test dataset: size: {len(test_dataset)}')\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "for data, labels in test_dataloader:\n",
    "    print(f'Test X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Module, Conv2d, MaxPool2d, Linear, ReLU, Dropout, BatchNorm2d, LeakyReLU, AdaptiveAvgPool2d, Flatten\n",
    "\n",
    "class ProjectModel(Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(ProjectModel, self).__init__()\n",
    "        self.module = Sequential(\n",
    "            Conv2d(3, 32, kernel_size=3, stride=1, padding=2)\n",
    "            , BatchNorm2d(32)\n",
    "            , LeakyReLU(inplace=True)\n",
    "            \n",
    "            , Conv2d(32, 32, kernel_size=3, stride=1, padding=0)\n",
    "            , BatchNorm2d(32)\n",
    "            , LeakyReLU(inplace=True)\n",
    "            \n",
    "            , MaxPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "            , Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "            , BatchNorm2d(64)\n",
    "            , LeakyReLU(inplace=True)\n",
    "            \n",
    "            , Conv2d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "            , BatchNorm2d(64)\n",
    "            , LeakyReLU(inplace=True)\n",
    "            \n",
    "            , MaxPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "            , AdaptiveAvgPool2d(output_size=(12, 12))\n",
    "            \n",
    "            , Flatten()\n",
    "            , Dropout(p=0.2, inplace=False)\n",
    "            , Linear(in_features=64*12*12, out_features=4096, bias=True)\n",
    "            , Dropout(p=0.2, inplace=False)\n",
    "            , Linear(in_features=4096, out_features=512, bias=True)\n",
    "            , Dropout(p=0.2, inplace=False)\n",
    "            , Linear(in_features=512, out_features=num_classes, bias=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.module(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Integrity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0359,  0.1828,  0.0756],\n",
      "        [ 0.0868,  0.1339,  0.0272],\n",
      "        [-0.2157, -0.0058, -0.2916],\n",
      "        [-0.0160,  0.1240,  0.0946],\n",
      "        [-0.2344, -0.1851, -0.1339],\n",
      "        [-0.0269,  0.2558, -0.3571],\n",
      "        [-0.0501,  0.3133, -0.0734],\n",
      "        [-0.0320, -0.1245,  0.2324]], grad_fn=<AddmmBackward>)\n",
      "tensor([1, 1, 1, 1, 2, 1, 1, 2])\n",
      "Accuracy: 37.5\n",
      "Model test passed.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "net = ProjectModel()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = net.to(device)\n",
    "\n",
    "# Model Unit test\n",
    "total_labels = 0\n",
    "correct_labels = 0\n",
    "for data, labels in train_dataloader:\n",
    "    torch.cuda.empty_cache()\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "    outputs = net(data)\n",
    "    print(outputs)\n",
    "    y_pred = torch.argmax(outputs, dim=1)\n",
    "    print(y_pred)\n",
    "    total_labels+=labels.size(0)\n",
    "    correct_labels += (y_pred==labels).sum().item()\n",
    "    break\n",
    "\n",
    "print(f'Accuracy: {(correct_labels/total_labels)*100}')\n",
    "print('Model test passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Model Parameter Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProjectModel(\n",
       "  (module): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): AdaptiveAvgPool2d(output_size=(12, 12))\n",
       "    (15): Flatten(start_dim=1, end_dim=-1)\n",
       "    (16): Dropout(p=0.2, inplace=False)\n",
       "    (17): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (18): Dropout(p=0.2, inplace=False)\n",
       "    (19): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (20): Dropout(p=0.2, inplace=False)\n",
       "    (21): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "def initialize_linear_layer_weights(layer):\n",
    "    torch.nn.init.xavier_uniform_(layer.weight)\n",
    "    torch.nn.init.zeros_(layer.bias)\n",
    "        \n",
    "def initialize_conv2d_layer_weights(layer):\n",
    "    torch.nn.init.xavier_uniform_(layer.weight)\n",
    "    \n",
    "def initialize_model_weights(module):\n",
    "    if isinstance(module, ProjectModel):\n",
    "        return\n",
    "    elif isinstance(module, Sequential):\n",
    "        return\n",
    "    if isinstance(module, Conv2d):\n",
    "        initialize_conv2d_layer_weights(module)\n",
    "    if isinstance(module, Linear):\n",
    "        initialize_linear_layer_weights(module)\n",
    "\n",
    "\n",
    "net = ProjectModel()\n",
    "net.apply(initialize_model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Parameter Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import time\n",
    "\n",
    "num_epoch = 10\n",
    "lr = 1e-3\n",
    "momentum = 0.5\n",
    "\n",
    "loss_evaluater = CrossEntropyLoss()\n",
    "optimizer = Adam(net.parameters(), lr=lr)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "After 0 batches: [time:0.0m 0.9701638221740723s, Accuracy: 75.0]\n",
      "After 5 batches: [time:0.0m 4.647967576980591s, Accuracy: 45.83333333333333]\n",
      "After 10 batches: [time:0.0m 8.555250644683838s, Accuracy: 44.31818181818182]\n",
      "After 15 batches: [time:0.0m 11.924469470977783s, Accuracy: 46.09375]\n",
      "After 20 batches: [time:0.0m 15.754701137542725s, Accuracy: 46.42857142857143]\n",
      "After 25 batches: [time:0.0m 19.51285672187805s, Accuracy: 45.67307692307692]\n",
      "After 30 batches: [time:0.0m 23.096119165420532s, Accuracy: 45.16129032258064]\n",
      "After 35 batches: [time:0.0m 26.778414964675903s, Accuracy: 43.05555555555556]\n",
      "After 40 batches: [time:0.0m 30.863971948623657s, Accuracy: 42.073170731707314]\n",
      "After 45 batches: [time:0.0m 34.932095527648926s, Accuracy: 41.57608695652174]\n",
      "After 50 batches: [time:0.0m 38.95473289489746s, Accuracy: 41.911764705882355]\n",
      "After 55 batches: [time:0.0m 43.12747526168823s, Accuracy: 41.74107142857143]\n",
      "After 60 batches: [time:0.0m 48.2558228969574s, Accuracy: 40.16393442622951]\n",
      "After 65 batches: [time:0.0m 53.95942997932434s, Accuracy: 40.71969696969697]\n",
      "After 70 batches: [time:0.0m 58.245525598526s, Accuracy: 40.66901408450704]\n",
      "After 75 batches: [time:1.0m 1.9446589946746826s, Accuracy: 40.46052631578947]\n",
      "After 80 batches: [time:1.0m 5.930852651596069s, Accuracy: 40.89506172839506]\n",
      "After 85 batches: [time:1.0m 9.622941255569458s, Accuracy: 40.406976744186046]\n",
      "After 90 batches: [time:1.0m 13.910472631454468s, Accuracy: 41.07142857142857]\n",
      "After 95 batches: [time:1.0m 18.507469177246094s, Accuracy: 41.27604166666667]\n",
      "After 100 batches: [time:1.0m 22.778390645980835s, Accuracy: 41.336633663366335]\n",
      "After 105 batches: [time:1.0m 26.559094429016113s, Accuracy: 41.62735849056604]\n",
      "After 110 batches: [time:1.0m 30.267598867416382s, Accuracy: 41.77927927927928]\n",
      "After 115 batches: [time:1.0m 34.156418800354004s, Accuracy: 42.133620689655174]\n",
      "After 120 batches: [time:1.0m 37.92774939537048s, Accuracy: 42.25206611570248]\n",
      "After 125 batches: [time:1.0m 41.70486569404602s, Accuracy: 42.26190476190476]\n",
      "After 130 batches: [time:1.0m 45.610875368118286s, Accuracy: 41.79389312977099]\n",
      "After 135 batches: [time:1.0m 49.39889645576477s, Accuracy: 42.279411764705884]\n",
      "After 140 batches: [time:1.0m 54.828999280929565s, Accuracy: 42.641843971631204]\n",
      "After 145 batches: [time:1.0m 58.942652225494385s, Accuracy: 43.15068493150685]\n",
      "After 150 batches: [time:2.0m 2.88401198387146s, Accuracy: 43.62582781456953]\n",
      "After 155 batches: [time:2.0m 6.561161041259766s, Accuracy: 43.669871794871796]\n",
      "After 160 batches: [time:2.0m 10.4446542263031s, Accuracy: 43.7111801242236]\n",
      "After 165 batches: [time:2.0m 14.207205057144165s, Accuracy: 43.97590361445783]\n",
      "After 170 batches: [time:2.0m 18.07033371925354s, Accuracy: 44.005847953216374]\n",
      "After 175 batches: [time:2.0m 23.30233407020569s, Accuracy: 44.53125]\n",
      "After 180 batches: [time:2.0m 28.54034686088562s, Accuracy: 44.9585635359116]\n",
      "After 185 batches: [time:2.0m 32.6873414516449s, Accuracy: 45.094086021505376]\n",
      "After 190 batches: [time:2.0m 36.97915196418762s, Accuracy: 45.746073298429316]\n",
      "Epoch 1: [time:2.0m 40.05538582801819s, Accuracy: 46.15384615384615]\n",
      "\n",
      "Epoch: 2\n",
      "After 0 batches: [time:0.0m 0.7435741424560547s, Accuracy: 62.5]\n",
      "After 5 batches: [time:0.0m 4.339523077011108s, Accuracy: 52.083333333333336]\n",
      "After 10 batches: [time:0.0m 8.131353855133057s, Accuracy: 50.0]\n",
      "After 15 batches: [time:0.0m 12.039546728134155s, Accuracy: 41.40625]\n",
      "After 20 batches: [time:0.0m 15.899847507476807s, Accuracy: 45.83333333333333]\n",
      "After 25 batches: [time:0.0m 20.285313844680786s, Accuracy: 50.0]\n",
      "After 30 batches: [time:0.0m 24.857300281524658s, Accuracy: 52.016129032258064]\n",
      "After 35 batches: [time:0.0m 30.292181730270386s, Accuracy: 52.43055555555556]\n",
      "After 40 batches: [time:0.0m 35.68750190734863s, Accuracy: 50.609756097560975]\n",
      "After 45 batches: [time:0.0m 40.60335350036621s, Accuracy: 50.815217391304344]\n",
      "After 50 batches: [time:0.0m 45.66061472892761s, Accuracy: 50.98039215686274]\n",
      "After 55 batches: [time:0.0m 50.03067088127136s, Accuracy: 52.23214285714286]\n",
      "After 60 batches: [time:0.0m 54.55892515182495s, Accuracy: 52.86885245901639]\n",
      "After 65 batches: [time:0.0m 58.966821908950806s, Accuracy: 52.27272727272727]\n",
      "After 70 batches: [time:1.0m 3.1074464321136475s, Accuracy: 51.76056338028169]\n",
      "After 75 batches: [time:1.0m 7.168120861053467s, Accuracy: 51.80921052631579]\n",
      "After 80 batches: [time:1.0m 11.546272039413452s, Accuracy: 51.54320987654321]\n",
      "After 85 batches: [time:1.0m 15.557970523834229s, Accuracy: 52.18023255813954]\n",
      "After 90 batches: [time:1.0m 19.343790292739868s, Accuracy: 52.60989010989011]\n",
      "After 95 batches: [time:1.0m 23.99629235267639s, Accuracy: 52.473958333333336]\n",
      "After 100 batches: [time:1.0m 28.921467304229736s, Accuracy: 52.351485148514854]\n",
      "After 105 batches: [time:1.0m 33.90761041641235s, Accuracy: 51.65094339622641]\n",
      "After 110 batches: [time:1.0m 38.852773666381836s, Accuracy: 51.57657657657657]\n",
      "After 115 batches: [time:1.0m 44.152199029922485s, Accuracy: 51.616379310344826]\n",
      "After 120 batches: [time:1.0m 49.93516755104065s, Accuracy: 51.962809917355365]\n",
      "After 125 batches: [time:1.0m 55.42601823806763s, Accuracy: 51.88492063492064]\n",
      "After 130 batches: [time:2.0m 0.46712756156921387s, Accuracy: 51.526717557251914]\n",
      "After 135 batches: [time:2.0m 5.89001989364624s, Accuracy: 50.91911764705882]\n",
      "After 140 batches: [time:2.0m 11.419848918914795s, Accuracy: 51.329787234042556]\n",
      "After 145 batches: [time:2.0m 17.074607133865356s, Accuracy: 50.9417808219178]\n",
      "After 150 batches: [time:2.0m 22.306607723236084s, Accuracy: 51.076158940397356]\n",
      "After 155 batches: [time:2.0m 27.327726125717163s, Accuracy: 50.96153846153846]\n",
      "After 160 batches: [time:2.0m 32.544734716415405s, Accuracy: 50.931677018633536]\n",
      "After 165 batches: [time:2.0m 37.77573585510254s, Accuracy: 50.602409638554214]\n",
      "After 170 batches: [time:2.0m 43.662275552749634s, Accuracy: 50.36549707602339]\n",
      "After 175 batches: [time:2.0m 48.84323334693909s, Accuracy: 50.42613636363637]\n",
      "After 180 batches: [time:2.0m 53.963299036026s, Accuracy: 50.069060773480665]\n",
      "After 185 batches: [time:2.0m 59.48013496398926s, Accuracy: 49.79838709677419]\n",
      "After 190 batches: [time:3.0m 4.607197046279907s, Accuracy: 49.803664921465966]\n",
      "Epoch 2: [time:3.0m 7.907305002212524s, Accuracy: 49.61538461538461]\n",
      "\n",
      "Epoch: 3\n",
      "After 0 batches: [time:0.0m 0.8944845199584961s, Accuracy: 50.0]\n",
      "After 5 batches: [time:0.0m 5.1275575160980225s, Accuracy: 60.416666666666664]\n",
      "After 10 batches: [time:0.0m 9.121270179748535s, Accuracy: 52.27272727272727]\n",
      "After 15 batches: [time:0.0m 12.824145078659058s, Accuracy: 53.125]\n",
      "After 20 batches: [time:0.0m 17.081374168395996s, Accuracy: 51.78571428571429]\n",
      "After 25 batches: [time:0.0m 20.74431037902832s, Accuracy: 52.40384615384615]\n",
      "After 30 batches: [time:0.0m 24.726030349731445s, Accuracy: 49.596774193548384]\n",
      "After 35 batches: [time:0.0m 28.325563669204712s, Accuracy: 49.30555555555556]\n",
      "After 40 batches: [time:0.0m 31.9875431060791s, Accuracy: 48.170731707317074]\n",
      "After 45 batches: [time:0.0m 35.65210223197937s, Accuracy: 49.184782608695656]\n",
      "After 50 batches: [time:0.0m 39.581852436065674s, Accuracy: 50.245098039215684]\n",
      "After 55 batches: [time:0.0m 45.04293346405029s, Accuracy: 50.0]\n",
      "After 60 batches: [time:0.0m 49.28752303123474s, Accuracy: 50.204918032786885]\n",
      "After 65 batches: [time:0.0m 53.34219765663147s, Accuracy: 50.0]\n",
      "After 70 batches: [time:0.0m 57.54678559303284s, Accuracy: 50.176056338028175]\n",
      "After 75 batches: [time:1.0m 1.2946369647979736s, Accuracy: 50.164473684210535]\n",
      "After 80 batches: [time:1.0m 7.708959341049194s, Accuracy: 50.308641975308646]\n",
      "After 85 batches: [time:1.0m 11.860579013824463s, Accuracy: 50.43604651162791]\n",
      "After 90 batches: [time:1.0m 16.311200380325317s, Accuracy: 51.098901098901095]\n",
      "After 95 batches: [time:1.0m 20.29241132736206s, Accuracy: 51.5625]\n",
      "After 100 batches: [time:1.0m 24.144198894500732s, Accuracy: 52.351485148514854]\n",
      "After 105 batches: [time:1.0m 28.092508554458618s, Accuracy: 53.06603773584906]\n",
      "After 110 batches: [time:1.0m 32.001065731048584s, Accuracy: 53.6036036036036]\n",
      "After 115 batches: [time:1.0m 36.089147329330444s, Accuracy: 53.23275862068966]\n",
      "After 120 batches: [time:1.0m 40.37647271156311s, Accuracy: 53.20247933884298]\n",
      "After 125 batches: [time:1.0m 44.46800184249878s, Accuracy: 53.273809523809526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 130 batches: [time:1.0m 50.486644983291626s, Accuracy: 53.05343511450382]\n",
      "After 135 batches: [time:1.0m 54.849462032318115s, Accuracy: 53.033088235294116]\n",
      "After 140 batches: [time:1.0m 58.418415784835815s, Accuracy: 52.74822695035461]\n",
      "After 145 batches: [time:2.0m 2.1417601108551025s, Accuracy: 53.082191780821915]\n",
      "After 150 batches: [time:2.0m 5.675729751586914s, Accuracy: 53.31125827814569]\n",
      "After 155 batches: [time:2.0m 9.246700763702393s, Accuracy: 53.68589743589743]\n",
      "After 160 batches: [time:2.0m 12.8226318359375s, Accuracy: 53.95962732919255]\n",
      "After 165 batches: [time:2.0m 16.41408634185791s, Accuracy: 53.915662650602414]\n",
      "After 170 batches: [time:2.0m 19.98335337638855s, Accuracy: 53.94736842105263]\n",
      "After 175 batches: [time:2.0m 23.474323749542236s, Accuracy: 54.11931818181818]\n",
      "After 180 batches: [time:2.0m 27.037708044052124s, Accuracy: 54.350828729281766]\n",
      "After 185 batches: [time:2.0m 30.546838521957397s, Accuracy: 54.56989247311827]\n",
      "After 190 batches: [time:2.0m 34.19373059272766s, Accuracy: 54.581151832460726]\n",
      "Epoch 3: [time:2.0m 37.08509039878845s, Accuracy: 54.35897435897436]\n",
      "\n",
      "Epoch: 4\n",
      "After 0 batches: [time:0.0m 0.7265834808349609s, Accuracy: 62.5]\n",
      "After 5 batches: [time:0.0m 4.245273113250732s, Accuracy: 56.25]\n",
      "After 10 batches: [time:0.0m 7.841334342956543s, Accuracy: 64.77272727272727]\n",
      "After 15 batches: [time:0.0m 11.401308536529541s, Accuracy: 59.375]\n",
      "After 20 batches: [time:0.0m 15.030582904815674s, Accuracy: 61.30952380952381]\n",
      "After 25 batches: [time:0.0m 18.59135603904724s, Accuracy: 62.019230769230774]\n",
      "After 30 batches: [time:0.0m 22.14383292198181s, Accuracy: 59.2741935483871]\n",
      "After 35 batches: [time:0.0m 25.933393955230713s, Accuracy: 60.416666666666664]\n",
      "After 40 batches: [time:0.0m 29.52134108543396s, Accuracy: 58.536585365853654]\n",
      "After 45 batches: [time:0.0m 33.08329939842224s, Accuracy: 58.152173913043484]\n",
      "After 50 batches: [time:0.0m 36.651265382766724s, Accuracy: 57.59803921568627]\n",
      "After 55 batches: [time:0.0m 40.22220492362976s, Accuracy: 57.14285714285714]\n",
      "After 60 batches: [time:0.0m 43.76761817932129s, Accuracy: 57.58196721311475]\n",
      "After 65 batches: [time:0.0m 47.32758092880249s, Accuracy: 57.1969696969697]\n",
      "After 70 batches: [time:0.0m 50.97989058494568s, Accuracy: 57.21830985915493]\n",
      "After 75 batches: [time:0.0m 54.533947706222534s, Accuracy: 57.89473684210527]\n",
      "After 80 batches: [time:0.0m 58.12458372116089s, Accuracy: 57.098765432098766]\n",
      "After 85 batches: [time:1.0m 1.8816773891448975s, Accuracy: 56.97674418604651]\n",
      "After 90 batches: [time:1.0m 5.421115398406982s, Accuracy: 56.456043956043956]\n",
      "After 95 batches: [time:1.0m 9.047022104263306s, Accuracy: 57.03125]\n",
      "After 100 batches: [time:1.0m 12.571015119552612s, Accuracy: 56.806930693069305]\n",
      "After 105 batches: [time:1.0m 16.130961179733276s, Accuracy: 57.07547169811321]\n",
      "After 110 batches: [time:1.0m 19.724895238876343s, Accuracy: 56.981981981981974]\n",
      "After 115 batches: [time:1.0m 23.288856029510498s, Accuracy: 57.11206896551724]\n",
      "After 120 batches: [time:1.0m 26.877796173095703s, Accuracy: 56.921487603305785]\n",
      "After 125 batches: [time:1.0m 30.398775815963745s, Accuracy: 57.24206349206349]\n",
      "After 130 batches: [time:1.0m 34.356507539749146s, Accuracy: 57.347328244274806]\n",
      "After 135 batches: [time:1.0m 38.201319217681885s, Accuracy: 57.35294117647059]\n",
      "After 140 batches: [time:1.0m 41.833492040634155s, Accuracy: 57.446808510638306]\n",
      "After 145 batches: [time:1.0m 45.368961334228516s, Accuracy: 57.02054794520548]\n",
      "After 150 batches: [time:1.0m 48.98990201950073s, Accuracy: 56.95364238410596]\n",
      "After 155 batches: [time:1.0m 52.55470681190491s, Accuracy: 57.61217948717948]\n",
      "After 160 batches: [time:1.0m 56.15387988090515s, Accuracy: 57.919254658385086]\n",
      "After 165 batches: [time:1.0m 59.73305606842041s, Accuracy: 58.20783132530121]\n",
      "After 170 batches: [time:2.0m 3.301011562347412s, Accuracy: 58.333333333333336]\n",
      "After 175 batches: [time:2.0m 6.893699884414673s, Accuracy: 58.59375]\n",
      "After 180 batches: [time:2.0m 10.473645687103271s, Accuracy: 58.70165745856354]\n",
      "After 185 batches: [time:2.0m 14.095573902130127s, Accuracy: 59.13978494623656]\n",
      "After 190 batches: [time:2.0m 17.655527114868164s, Accuracy: 59.620418848167546]\n",
      "Epoch 4: [time:2.0m 20.53589177131653s, Accuracy: 59.80769230769231]\n",
      "\n",
      "Epoch: 5\n",
      "After 0 batches: [time:0.0m 0.7235851287841797s, Accuracy: 87.5]\n",
      "After 5 batches: [time:0.0m 4.398480176925659s, Accuracy: 58.333333333333336]\n",
      "After 10 batches: [time:0.0m 8.204297542572021s, Accuracy: 57.95454545454546]\n",
      "After 15 batches: [time:0.0m 11.752261638641357s, Accuracy: 57.03125]\n",
      "After 20 batches: [time:0.0m 15.339205741882324s, Accuracy: 56.547619047619044]\n",
      "After 25 batches: [time:0.0m 18.893183708190918s, Accuracy: 57.692307692307686]\n",
      "After 30 batches: [time:0.0m 22.477813720703125s, Accuracy: 59.2741935483871]\n",
      "After 35 batches: [time:0.0m 26.011467695236206s, Accuracy: 60.416666666666664]\n",
      "After 40 batches: [time:0.0m 29.569429874420166s, Accuracy: 60.0609756097561]\n",
      "After 45 batches: [time:0.0m 33.09916830062866s, Accuracy: 61.41304347826087]\n",
      "After 50 batches: [time:0.0m 36.6821346282959s, Accuracy: 61.029411764705884]\n",
      "After 55 batches: [time:0.0m 40.24808621406555s, Accuracy: 60.71428571428571]\n",
      "After 60 batches: [time:0.0m 43.785637617111206s, Accuracy: 60.86065573770492]\n",
      "After 65 batches: [time:0.0m 47.37766933441162s, Accuracy: 60.79545454545454]\n",
      "After 70 batches: [time:0.0m 50.930617809295654s, Accuracy: 60.56338028169014]\n",
      "After 75 batches: [time:0.0m 54.498584508895874s, Accuracy: 59.539473684210535]\n",
      "After 80 batches: [time:0.0m 58.0335419178009s, Accuracy: 60.95679012345679]\n",
      "After 85 batches: [time:1.0m 1.6874639987945557s, Accuracy: 61.77325581395349]\n",
      "After 90 batches: [time:1.0m 5.293382883071899s, Accuracy: 62.362637362637365]\n",
      "After 95 batches: [time:1.0m 8.85534143447876s, Accuracy: 62.5]\n",
      "After 100 batches: [time:1.0m 12.447277069091797s, Accuracy: 62.995049504950494]\n",
      "After 105 batches: [time:1.0m 15.99824070930481s, Accuracy: 62.617924528301884]\n",
      "After 110 batches: [time:1.0m 19.5911865234375s, Accuracy: 63.17567567567568]\n",
      "After 115 batches: [time:1.0m 23.19817304611206s, Accuracy: 63.36206896551724]\n",
      "After 120 batches: [time:1.0m 26.694903135299683s, Accuracy: 63.63636363636363]\n",
      "After 125 batches: [time:1.0m 30.316826581954956s, Accuracy: 63.591269841269835]\n",
      "After 130 batches: [time:1.0m 33.86150527000427s, Accuracy: 64.02671755725191]\n",
      "After 135 batches: [time:1.0m 37.461119174957275s, Accuracy: 64.24632352941177]\n",
      "After 140 batches: [time:1.0m 41.062320947647095s, Accuracy: 64.62765957446808]\n",
      "After 145 batches: [time:1.0m 44.6095917224884s, Accuracy: 64.6404109589041]\n",
      "After 150 batches: [time:1.0m 48.211520195007324s, Accuracy: 64.90066225165563]\n",
      "After 155 batches: [time:1.0m 51.76449775695801s, Accuracy: 65.14423076923077]\n",
      "After 160 batches: [time:1.0m 55.41915965080261s, Accuracy: 64.90683229813664]\n",
      "After 165 batches: [time:1.0m 58.949434995651245s, Accuracy: 64.83433734939759]\n",
      "After 170 batches: [time:2.0m 2.5186305046081543s, Accuracy: 65.13157894736842]\n",
      "After 175 batches: [time:2.0m 6.285624027252197s, Accuracy: 64.84375]\n",
      "After 180 batches: [time:2.0m 10.621001720428467s, Accuracy: 64.84806629834254]\n",
      "After 185 batches: [time:2.0m 14.726577520370483s, Accuracy: 64.85215053763442]\n",
      "After 190 batches: [time:2.0m 18.322707414627075s, Accuracy: 64.9869109947644]\n",
      "Epoch 5: [time:2.0m 21.198156595230103s, Accuracy: 64.87179487179488]\n",
      "\n",
      "Epoch: 6\n",
      "After 0 batches: [time:0.0m 0.7330210208892822s, Accuracy: 37.5]\n",
      "After 5 batches: [time:0.0m 4.2765748500823975s, Accuracy: 56.25]\n",
      "After 10 batches: [time:0.0m 7.862303733825684s, Accuracy: 59.09090909090909]\n",
      "After 15 batches: [time:0.0m 11.443248271942139s, Accuracy: 54.6875]\n",
      "After 20 batches: [time:0.0m 15.014538526535034s, Accuracy: 58.92857142857143]\n",
      "After 25 batches: [time:0.0m 18.560632705688477s, Accuracy: 58.65384615384615]\n",
      "After 30 batches: [time:0.0m 22.112616300582886s, Accuracy: 57.66129032258065]\n",
      "After 35 batches: [time:0.0m 25.659889698028564s, Accuracy: 58.68055555555556]\n",
      "After 40 batches: [time:0.0m 29.314992427825928s, Accuracy: 59.45121951219512]\n",
      "After 45 batches: [time:0.0m 32.84519147872925s, Accuracy: 61.141304347826086]\n",
      "After 50 batches: [time:0.0m 36.41329073905945s, Accuracy: 60.5392156862745]\n",
      "After 55 batches: [time:0.0m 39.922502756118774s, Accuracy: 61.60714285714286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 60 batches: [time:0.0m 43.47049522399902s, Accuracy: 62.704918032786885]\n",
      "After 65 batches: [time:0.0m 47.05970525741577s, Accuracy: 62.5]\n",
      "After 70 batches: [time:0.0m 50.65784811973572s, Accuracy: 63.38028169014085]\n",
      "After 75 batches: [time:0.0m 54.26399779319763s, Accuracy: 63.1578947368421]\n",
      "After 80 batches: [time:0.0m 57.80334973335266s, Accuracy: 63.888888888888886]\n",
      "After 85 batches: [time:1.0m 1.4198477268218994s, Accuracy: 63.662790697674424]\n",
      "After 90 batches: [time:1.0m 4.959424257278442s, Accuracy: 63.873626373626365]\n",
      "After 95 batches: [time:1.0m 8.486525058746338s, Accuracy: 64.97395833333334]\n",
      "After 100 batches: [time:1.0m 12.055652379989624s, Accuracy: 64.97524752475248]\n",
      "After 105 batches: [time:1.0m 15.597622871398926s, Accuracy: 64.74056603773585]\n",
      "After 110 batches: [time:1.0m 19.14451766014099s, Accuracy: 64.86486486486487]\n",
      "After 115 batches: [time:1.0m 22.67803692817688s, Accuracy: 65.19396551724138]\n",
      "After 120 batches: [time:1.0m 26.26822781562805s, Accuracy: 65.599173553719]\n",
      "After 125 batches: [time:1.0m 29.800365924835205s, Accuracy: 65.07936507936508]\n",
      "After 130 batches: [time:1.0m 33.39141488075256s, Accuracy: 65.17175572519083]\n",
      "After 135 batches: [time:1.0m 36.97059869766235s, Accuracy: 64.98161764705883]\n",
      "After 140 batches: [time:1.0m 40.49385333061218s, Accuracy: 65.1595744680851]\n",
      "After 145 batches: [time:1.0m 44.22683620452881s, Accuracy: 64.98287671232876]\n",
      "After 150 batches: [time:1.0m 47.960338830947876s, Accuracy: 64.90066225165563]\n",
      "After 155 batches: [time:1.0m 51.5961799621582s, Accuracy: 64.98397435897436]\n",
      "After 160 batches: [time:1.0m 55.15618133544922s, Accuracy: 65.21739130434783]\n",
      "After 165 batches: [time:1.0m 58.67932152748108s, Accuracy: 65.4367469879518]\n",
      "After 170 batches: [time:2.0m 2.2484161853790283s, Accuracy: 66.00877192982456]\n",
      "After 175 batches: [time:2.0m 5.8416712284088135s, Accuracy: 66.19318181818183]\n",
      "After 180 batches: [time:2.0m 9.416743278503418s, Accuracy: 66.09116022099447]\n",
      "After 185 batches: [time:2.0m 13.014769554138184s, Accuracy: 65.7258064516129]\n",
      "After 190 batches: [time:2.0m 16.54693865776062s, Accuracy: 65.96858638743456]\n",
      "Epoch 6: [time:2.0m 19.4103262424469s, Accuracy: 66.02564102564102]\n",
      "\n",
      "Epoch: 7\n",
      "After 0 batches: [time:0.0m 0.7506020069122314s, Accuracy: 87.5]\n",
      "After 5 batches: [time:0.0m 4.314958095550537s, Accuracy: 77.08333333333334]\n",
      "After 10 batches: [time:0.0m 7.949145317077637s, Accuracy: 72.72727272727273]\n",
      "After 15 batches: [time:0.0m 11.530387878417969s, Accuracy: 67.1875]\n",
      "After 20 batches: [time:0.0m 15.088312864303589s, Accuracy: 67.26190476190477]\n",
      "After 25 batches: [time:0.0m 18.71540904045105s, Accuracy: 68.26923076923077]\n",
      "After 30 batches: [time:0.0m 22.29957365989685s, Accuracy: 68.95161290322581]\n",
      "After 35 batches: [time:0.0m 25.89268159866333s, Accuracy: 69.09722222222221]\n",
      "After 40 batches: [time:0.0m 29.469830989837646s, Accuracy: 68.59756097560977]\n",
      "After 45 batches: [time:0.0m 33.03054618835449s, Accuracy: 68.47826086956522]\n",
      "After 50 batches: [time:0.0m 36.558154582977295s, Accuracy: 67.64705882352942]\n",
      "After 55 batches: [time:0.0m 40.15022039413452s, Accuracy: 67.41071428571429]\n",
      "After 60 batches: [time:0.0m 43.720271587371826s, Accuracy: 66.18852459016394]\n",
      "After 65 batches: [time:0.0m 47.22072958946228s, Accuracy: 65.3409090909091]\n",
      "After 70 batches: [time:0.0m 50.836599588394165s, Accuracy: 66.37323943661971]\n",
      "After 75 batches: [time:0.0m 54.3776581287384s, Accuracy: 66.44736842105263]\n",
      "After 80 batches: [time:0.0m 57.950950384140015s, Accuracy: 66.9753086419753]\n",
      "After 85 batches: [time:1.0m 1.523195505142212s, Accuracy: 67.58720930232558]\n",
      "After 90 batches: [time:1.0m 5.0551207065582275s, Accuracy: 67.58241758241759]\n",
      "After 95 batches: [time:1.0m 8.632489204406738s, Accuracy: 67.70833333333334]\n",
      "After 100 batches: [time:1.0m 12.190528392791748s, Accuracy: 67.82178217821783]\n",
      "After 105 batches: [time:1.0m 15.80461597442627s, Accuracy: 67.57075471698113]\n",
      "After 110 batches: [time:1.0m 19.372559785842896s, Accuracy: 67.68018018018019]\n",
      "After 115 batches: [time:1.0m 22.984827995300293s, Accuracy: 67.45689655172413]\n",
      "After 120 batches: [time:1.0m 26.74495005607605s, Accuracy: 67.56198347107438]\n",
      "After 125 batches: [time:1.0m 30.297993659973145s, Accuracy: 67.95634920634922]\n",
      "After 130 batches: [time:1.0m 33.86220932006836s, Accuracy: 67.6526717557252]\n",
      "After 135 batches: [time:1.0m 37.407246828079224s, Accuracy: 67.73897058823529]\n",
      "After 140 batches: [time:1.0m 40.98161435127258s, Accuracy: 67.4645390070922]\n",
      "After 145 batches: [time:1.0m 44.519503116607666s, Accuracy: 67.20890410958904]\n",
      "After 150 batches: [time:1.0m 48.123753786087036s, Accuracy: 67.30132450331125]\n",
      "After 155 batches: [time:1.0m 53.73758554458618s, Accuracy: 67.38782051282051]\n",
      "After 160 batches: [time:1.0m 58.83366346359253s, Accuracy: 67.54658385093167]\n",
      "After 165 batches: [time:2.0m 3.380056858062744s, Accuracy: 67.7710843373494]\n",
      "After 170 batches: [time:2.0m 7.119912385940552s, Accuracy: 67.54385964912281]\n",
      "After 175 batches: [time:2.0m 10.742836236953735s, Accuracy: 67.54261363636364]\n",
      "After 180 batches: [time:2.0m 15.093340158462524s, Accuracy: 67.67955801104972]\n",
      "After 185 batches: [time:2.0m 21.335752248764038s, Accuracy: 67.27150537634408]\n",
      "After 190 batches: [time:2.0m 26.457855701446533s, Accuracy: 67.08115183246073]\n",
      "Epoch 7: [time:2.0m 30.180155515670776s, Accuracy: 66.92307692307692]\n",
      "\n",
      "Epoch: 8\n",
      "After 0 batches: [time:0.0m 0.8101902008056641s, Accuracy: 62.5]\n",
      "After 5 batches: [time:0.0m 4.820453643798828s, Accuracy: 68.75]\n",
      "After 10 batches: [time:0.0m 8.851130485534668s, Accuracy: 62.5]\n",
      "After 15 batches: [time:0.0m 13.021817922592163s, Accuracy: 63.28125]\n",
      "After 20 batches: [time:0.0m 17.08399510383606s, Accuracy: 65.47619047619048]\n",
      "After 25 batches: [time:0.0m 21.161600828170776s, Accuracy: 65.86538461538461]\n",
      "After 30 batches: [time:0.0m 25.16712260246277s, Accuracy: 66.93548387096774]\n",
      "After 35 batches: [time:0.0m 29.276885986328125s, Accuracy: 68.75]\n",
      "After 40 batches: [time:0.0m 33.85815620422363s, Accuracy: 70.1219512195122]\n",
      "After 45 batches: [time:0.0m 38.30985498428345s, Accuracy: 72.01086956521739]\n",
      "After 50 batches: [time:0.0m 42.474294662475586s, Accuracy: 72.30392156862744]\n",
      "After 55 batches: [time:0.0m 46.86737370491028s, Accuracy: 72.32142857142857]\n",
      "After 60 batches: [time:0.0m 51.14225459098816s, Accuracy: 72.95081967213115]\n",
      "After 65 batches: [time:0.0m 55.45588946342468s, Accuracy: 72.53787878787878]\n",
      "After 70 batches: [time:0.0m 59.56946301460266s, Accuracy: 72.88732394366197]\n",
      "After 75 batches: [time:1.0m 4.9288365840911865s, Accuracy: 73.19078947368422]\n",
      "After 80 batches: [time:1.0m 8.917728900909424s, Accuracy: 73.76543209876543]\n",
      "After 85 batches: [time:1.0m 12.833348035812378s, Accuracy: 73.83720930232558]\n",
      "After 90 batches: [time:1.0m 16.70762038230896s, Accuracy: 72.93956043956044]\n",
      "After 95 batches: [time:1.0m 20.72950768470764s, Accuracy: 73.4375]\n",
      "After 100 batches: [time:1.0m 24.635074377059937s, Accuracy: 72.27722772277228]\n",
      "After 105 batches: [time:1.0m 28.637937545776367s, Accuracy: 71.34433962264151]\n",
      "After 110 batches: [time:1.0m 32.604156494140625s, Accuracy: 70.83333333333334]\n",
      "After 115 batches: [time:1.0m 36.47827196121216s, Accuracy: 70.6896551724138]\n",
      "After 120 batches: [time:1.0m 40.42035150527954s, Accuracy: 70.24793388429752]\n",
      "After 125 batches: [time:1.0m 44.32839107513428s, Accuracy: 70.23809523809523]\n",
      "After 130 batches: [time:1.0m 48.32493543624878s, Accuracy: 70.32442748091603]\n",
      "After 135 batches: [time:1.0m 52.31784009933472s, Accuracy: 70.68014705882352]\n",
      "After 140 batches: [time:1.0m 56.22668981552124s, Accuracy: 70.65602836879432]\n",
      "After 145 batches: [time:2.0m 0.1684436798095703s, Accuracy: 70.54794520547945]\n",
      "After 150 batches: [time:2.0m 4.127415180206299s, Accuracy: 70.61258278145695]\n",
      "After 155 batches: [time:2.0m 8.088792324066162s, Accuracy: 70.51282051282051]\n",
      "After 160 batches: [time:2.0m 11.98093843460083s, Accuracy: 70.65217391304348]\n",
      "After 165 batches: [time:2.0m 15.875103950500488s, Accuracy: 70.70783132530121]\n",
      "After 170 batches: [time:2.0m 19.846092224121094s, Accuracy: 70.68713450292398]\n",
      "After 175 batches: [time:2.0m 23.766836404800415s, Accuracy: 70.73863636363636]\n",
      "After 180 batches: [time:2.0m 27.68894910812378s, Accuracy: 70.58011049723757]\n",
      "After 185 batches: [time:2.0m 31.62105965614319s, Accuracy: 70.76612903225806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 190 batches: [time:2.0m 35.51297402381897s, Accuracy: 70.74607329842932]\n",
      "Epoch 8: [time:2.0m 38.694133043289185s, Accuracy: 70.76923076923077]\n",
      "\n",
      "Epoch: 9\n",
      "After 0 batches: [time:0.0m 0.809535026550293s, Accuracy: 75.0]\n",
      "After 5 batches: [time:0.0m 4.619708061218262s, Accuracy: 79.16666666666666]\n",
      "After 10 batches: [time:0.0m 8.291634798049927s, Accuracy: 75.0]\n",
      "After 15 batches: [time:0.0m 11.924668073654175s, Accuracy: 71.09375]\n",
      "After 20 batches: [time:0.0m 15.500329732894897s, Accuracy: 72.02380952380952]\n",
      "After 25 batches: [time:0.0m 19.351122856140137s, Accuracy: 74.03846153846155]\n",
      "After 30 batches: [time:0.0m 22.923058032989502s, Accuracy: 76.20967741935483]\n",
      "After 35 batches: [time:0.0m 26.476019620895386s, Accuracy: 75.69444444444444]\n",
      "After 40 batches: [time:0.0m 30.048988342285156s, Accuracy: 75.0]\n",
      "After 45 batches: [time:0.0m 33.613930463790894s, Accuracy: 74.18478260869566]\n",
      "After 50 batches: [time:0.0m 37.19187545776367s, Accuracy: 74.75490196078431]\n",
      "After 55 batches: [time:0.0m 40.76282787322998s, Accuracy: 73.4375]\n",
      "After 60 batches: [time:0.0m 44.31380891799927s, Accuracy: 73.15573770491804]\n",
      "After 65 batches: [time:0.0m 47.85576033592224s, Accuracy: 73.86363636363636]\n",
      "After 70 batches: [time:0.0m 51.46469283103943s, Accuracy: 73.41549295774648]\n",
      "After 75 batches: [time:0.0m 55.06962609291077s, Accuracy: 73.84868421052632]\n",
      "After 80 batches: [time:0.0m 58.65357184410095s, Accuracy: 74.22839506172839]\n",
      "After 85 batches: [time:1.0m 2.232522964477539s, Accuracy: 73.98255813953489]\n",
      "After 90 batches: [time:1.0m 5.79649019241333s, Accuracy: 73.76373626373626]\n",
      "After 95 batches: [time:1.0m 9.324455976486206s, Accuracy: 73.17708333333334]\n",
      "After 100 batches: [time:1.0m 12.897419452667236s, Accuracy: 73.14356435643565]\n",
      "After 105 batches: [time:1.0m 16.494344472885132s, Accuracy: 73.70283018867924]\n",
      "After 110 batches: [time:1.0m 20.059300899505615s, Accuracy: 73.53603603603604]\n",
      "After 115 batches: [time:1.0m 23.628265380859375s, Accuracy: 73.49137931034483]\n",
      "After 120 batches: [time:1.0m 27.23718023300171s, Accuracy: 73.65702479338843]\n",
      "After 125 batches: [time:1.0m 30.80715036392212s, Accuracy: 73.61111111111111]\n",
      "After 130 batches: [time:1.0m 34.436068534851074s, Accuracy: 73.37786259541986]\n",
      "After 135 batches: [time:1.0m 38.05597758293152s, Accuracy: 73.4375]\n",
      "After 140 batches: [time:1.0m 41.64991593360901s, Accuracy: 73.40425531914893]\n",
      "After 145 batches: [time:1.0m 45.203895568847656s, Accuracy: 73.28767123287672]\n",
      "After 150 batches: [time:1.0m 48.85578656196594s, Accuracy: 73.4271523178808]\n",
      "After 155 batches: [time:1.0m 52.43573260307312s, Accuracy: 73.15705128205127]\n",
      "After 160 batches: [time:1.0m 56.0536572933197s, Accuracy: 72.90372670807453]\n",
      "After 165 batches: [time:1.0m 59.64060091972351s, Accuracy: 72.7409638554217]\n",
      "After 170 batches: [time:2.0m 3.131598949432373s, Accuracy: 72.00292397660819]\n",
      "After 175 batches: [time:2.0m 6.696556568145752s, Accuracy: 71.875]\n",
      "After 180 batches: [time:2.0m 10.26252818107605s, Accuracy: 71.54696132596685]\n",
      "After 185 batches: [time:2.0m 13.832467794418335s, Accuracy: 71.43817204301075]\n",
      "After 190 batches: [time:2.0m 17.355448961257935s, Accuracy: 71.40052356020942]\n",
      "Epoch 9: [time:2.0m 20.215803146362305s, Accuracy: 71.53846153846153]\n",
      "\n",
      "Epoch: 10\n",
      "After 0 batches: [time:0.0m 0.7405762672424316s, Accuracy: 75.0]\n",
      "After 5 batches: [time:0.0m 4.40548038482666s, Accuracy: 79.16666666666666]\n",
      "After 10 batches: [time:0.0m 7.95345664024353s, Accuracy: 81.81818181818183]\n",
      "After 15 batches: [time:0.0m 11.525407552719116s, Accuracy: 79.6875]\n",
      "After 20 batches: [time:0.0m 15.060381889343262s, Accuracy: 77.97619047619048]\n",
      "After 25 batches: [time:0.0m 18.61034607887268s, Accuracy: 75.0]\n",
      "After 30 batches: [time:0.0m 22.18128252029419s, Accuracy: 72.98387096774194]\n",
      "After 35 batches: [time:0.0m 25.784223556518555s, Accuracy: 73.95833333333334]\n",
      "After 40 batches: [time:0.0m 29.413135051727295s, Accuracy: 73.47560975609755]\n",
      "After 45 batches: [time:0.0m 32.940118074417114s, Accuracy: 75.0]\n",
      "After 50 batches: [time:0.0m 36.53307127952576s, Accuracy: 75.49019607843137]\n",
      "After 55 batches: [time:0.0m 40.06302881240845s, Accuracy: 75.89285714285714]\n",
      "After 60 batches: [time:0.0m 43.62098813056946s, Accuracy: 75.61475409836066]\n",
      "After 65 batches: [time:0.0m 47.174957513809204s, Accuracy: 75.37878787878788]\n",
      "After 70 batches: [time:0.0m 50.804869174957275s, Accuracy: 75.0]\n",
      "After 75 batches: [time:0.0m 54.40780782699585s, Accuracy: 74.17763157894737]\n",
      "After 80 batches: [time:0.0m 58.012741565704346s, Accuracy: 73.76543209876543]\n",
      "After 85 batches: [time:1.0m 1.6326615810394287s, Accuracy: 73.69186046511628]\n",
      "After 90 batches: [time:1.0m 5.166651964187622s, Accuracy: 73.48901098901099]\n",
      "After 95 batches: [time:1.0m 8.729595422744751s, Accuracy: 73.56770833333334]\n",
      "After 100 batches: [time:1.0m 12.281559705734253s, Accuracy: 73.63861386138613]\n",
      "After 105 batches: [time:1.0m 15.836517572402954s, Accuracy: 73.46698113207547]\n",
      "After 110 batches: [time:1.0m 19.4054753780365s, Accuracy: 73.53603603603604]\n",
      "After 115 batches: [time:1.0m 22.975425720214844s, Accuracy: 73.16810344827587]\n",
      "After 120 batches: [time:1.0m 26.53738522529602s, Accuracy: 72.62396694214877]\n",
      "After 125 batches: [time:1.0m 30.075355052947998s, Accuracy: 73.11507936507937]\n",
      "After 130 batches: [time:1.0m 33.6972758769989s, Accuracy: 73.37786259541986]\n",
      "After 135 batches: [time:1.0m 37.246257305145264s, Accuracy: 73.25367647058823]\n",
      "After 140 batches: [time:1.0m 40.78121852874756s, Accuracy: 73.31560283687944]\n",
      "After 145 batches: [time:1.0m 44.79991006851196s, Accuracy: 73.5445205479452]\n",
      "After 150 batches: [time:1.0m 48.90956950187683s, Accuracy: 74.00662251655629]\n",
      "After 155 batches: [time:1.0m 52.49050259590149s, Accuracy: 74.03846153846155]\n",
      "After 160 batches: [time:1.0m 56.23935604095459s, Accuracy: 73.99068322981367]\n",
      "After 165 batches: [time:1.0m 59.799309730529785s, Accuracy: 73.49397590361446]\n",
      "After 170 batches: [time:2.0m 6.218650817871094s, Accuracy: 73.46491228070175]\n",
      "After 175 batches: [time:2.0m 11.072556018829346s, Accuracy: 73.08238636363636]\n",
      "After 180 batches: [time:2.0m 15.084471702575684s, Accuracy: 73.34254143646409]\n",
      "After 185 batches: [time:2.0m 19.030969381332397s, Accuracy: 73.0510752688172]\n",
      "After 190 batches: [time:2.0m 23.028780221939087s, Accuracy: 73.03664921465969]\n",
      "Epoch 10: [time:2.0m 26.157522439956665s, Accuracy: 73.2051282051282]\n",
      "\n",
      "Training time: 25.0m 21.45647692680359s\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "net.train()\n",
    "\n",
    "t = time.time()\n",
    "for i in range(num_epoch):\n",
    "    print(f'Epoch: {i+1}')\n",
    "    t_epoch = time.time()\n",
    "    total_labels = 0\n",
    "    correctly_pred = 0\n",
    "    t_batch = time.time()\n",
    "    for j, (data, labels) in enumerate(train_dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        X, y = data, labels\n",
    "        optimizer.zero_grad()\n",
    "        output = net(X)\n",
    "        loss = loss_evaluater(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred = torch.argmax(output, dim=1)\n",
    "        total_labels += y.size(0)\n",
    "        correctly_pred += (y_pred==y).sum().item()\n",
    "        current_acc = (correctly_pred/total_labels)\n",
    "        if j%5==0:\n",
    "            seconds_passed = time.time()-t_batch\n",
    "            print(f'After {j} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "    epoch_acc = (correctly_pred/total_labels)\n",
    "    seconds_passed = time.time()-t_epoch\n",
    "    print(f'Epoch {i+1}: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {epoch_acc*100}]')\n",
    "    print()\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Training time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 batches: [time:0.0m 0.17090630531311035s, Accuracy: 62.5]\n",
      "After 5 batches: [time:0.0m 1.036407232284546s, Accuracy: 79.16666666666666]\n",
      "After 10 batches: [time:0.0m 1.9938583374023438s, Accuracy: 82.95454545454545]\n",
      "After 15 batches: [time:0.0m 2.890345811843872s, Accuracy: 80.46875]\n",
      "After 20 batches: [time:0.0m 3.796823024749756s, Accuracy: 78.57142857142857]\n",
      "After 25 batches: [time:0.0m 4.697310924530029s, Accuracy: 79.32692307692307]\n",
      "After 30 batches: [time:0.0m 5.598789930343628s, Accuracy: 77.82258064516128]\n",
      "After 35 batches: [time:0.0m 6.424317121505737s, Accuracy: 77.77777777777779]\n",
      "After 40 batches: [time:0.0m 7.298826217651367s, Accuracy: 78.04878048780488]\n",
      "After 45 batches: [time:0.0m 8.103365898132324s, Accuracy: 77.71739130434783]\n",
      "After 50 batches: [time:0.0m 8.901904344558716s, Accuracy: 76.9607843137255]\n",
      "After 55 batches: [time:0.0m 9.7174391746521s, Accuracy: 76.78571428571429]\n",
      "After 60 batches: [time:0.0m 10.535969972610474s, Accuracy: 76.4344262295082]\n",
      "After 65 batches: [time:0.0m 11.35062575340271s, Accuracy: 77.08333333333334]\n",
      "After 70 batches: [time:0.0m 12.228241205215454s, Accuracy: 77.46478873239437]\n",
      "After 75 batches: [time:0.0m 13.319923639297485s, Accuracy: 77.79605263157895]\n",
      "After 80 batches: [time:0.0m 14.303316116333008s, Accuracy: 77.1604938271605]\n",
      "After 85 batches: [time:0.0m 15.327532768249512s, Accuracy: 77.03488372093024]\n",
      "After 90 batches: [time:0.0m 16.412917852401733s, Accuracy: 76.92307692307693]\n",
      "After 95 batches: [time:0.0m 17.531710863113403s, Accuracy: 76.43229166666666]\n",
      "After 100 batches: [time:0.0m 18.63034725189209s, Accuracy: 76.60891089108911]\n",
      "After 105 batches: [time:0.0m 19.77369499206543s, Accuracy: 76.65094339622641]\n",
      "After 110 batches: [time:0.0m 20.88359022140503s, Accuracy: 76.91441441441441]\n",
      "After 115 batches: [time:0.0m 22.013189554214478s, Accuracy: 77.47844827586206]\n",
      "After 120 batches: [time:0.0m 23.105241060256958s, Accuracy: 77.47933884297521]\n",
      "After 125 batches: [time:0.0m 24.262352228164673s, Accuracy: 77.28174603174604]\n",
      "After 130 batches: [time:0.0m 25.258392333984375s, Accuracy: 77.3854961832061]\n",
      "After 135 batches: [time:0.0m 26.424927473068237s, Accuracy: 77.38970588235294]\n",
      "After 140 batches: [time:0.0m 27.533299446105957s, Accuracy: 77.5709219858156]\n",
      "After 145 batches: [time:0.0m 28.757638454437256s, Accuracy: 77.3972602739726]\n",
      "After 150 batches: [time:0.0m 29.919525384902954s, Accuracy: 77.56622516556291]\n",
      "After 155 batches: [time:0.0m 30.988381147384644s, Accuracy: 77.56410256410257]\n",
      "After 160 batches: [time:0.0m 31.861894607543945s, Accuracy: 77.56211180124224]\n",
      "After 165 batches: [time:0.0m 33.13769793510437s, Accuracy: 77.56024096385542]\n",
      "After 170 batches: [time:0.0m 34.49291253089905s, Accuracy: 77.55847953216374]\n",
      "After 175 batches: [time:0.0m 35.53931140899658s, Accuracy: 77.91193181818183]\n",
      "After 180 batches: [time:0.0m 36.49476385116577s, Accuracy: 78.24585635359117]\n",
      "After 185 batches: [time:0.0m 37.602131843566895s, Accuracy: 78.36021505376344]\n",
      "After 190 batches: [time:0.0m 38.499629497528076s, Accuracy: 78.66492146596859]\n",
      "Training accuracy: 78.65384615384615\n",
      "Trainig evaluation time: 0.0m 39.24520254135132s\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "t = time.time()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_labels = 0\n",
    "    correctly_pred = 0\n",
    "    t_batch = time.time()\n",
    "    for i, (data, labels) in enumerate(train_dataloader):\n",
    "        data,labels = data.to(device), labels.to(device)\n",
    "        gc.collect()\n",
    "        X, y = data, labels\n",
    "        output = net(X)\n",
    "        y_pred = torch.argmax(output, dim=1)\n",
    "        total_labels += y.size(0)\n",
    "        correctly_pred += (y_pred==y).sum().item()\n",
    "        current_acc = (correctly_pred/total_labels)\n",
    "        if i%5==0:\n",
    "            seconds_passed = time.time()-t_batch\n",
    "            print(f'After {i} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "    train_acc = (correctly_pred/total_labels)\n",
    "    print(f'Training accuracy: {train_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "\n",
    "print(f'Trainig evaluation time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Testing Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 batches: [time:0.0m 0.1739063262939453s, Accuracy: 75.0]\n",
      "After 5 batches: [time:0.0m 1.0214130878448486s, Accuracy: 66.66666666666666]\n",
      "After 10 batches: [time:0.0m 1.9179024696350098s, Accuracy: 63.63636363636363]\n",
      "After 15 batches: [time:0.0m 2.749424695968628s, Accuracy: 63.28125]\n",
      "After 20 batches: [time:0.0m 3.5809478759765625s, Accuracy: 67.85714285714286]\n",
      "After 25 batches: [time:0.0m 4.4174675941467285s, Accuracy: 69.23076923076923]\n",
      "After 30 batches: [time:0.0m 5.199018955230713s, Accuracy: 69.75806451612904]\n",
      "After 35 batches: [time:0.0m 6.088508129119873s, Accuracy: 70.13888888888889]\n",
      "Test accuracy: 70.66666666666667\n",
      "Test time: 0.0m 6.398329973220825s\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "net.eval()\n",
    "\n",
    "t = time.time()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "total_labels = 0\n",
    "correctly_pred = 0\n",
    "t_batch = time.time()\n",
    "test_batch=[]\n",
    "pred_batch=[]\n",
    "\n",
    "for i, (data, labels) in enumerate(test_dataloader):\n",
    "    torch.cuda.empty_cache()\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "    gc.collect()\n",
    "    X, y = data, labels\n",
    "    test_batch.extend(y.tolist())\n",
    "    output = net(X)\n",
    "    y_pred = torch.argmax(output, dim=1)\n",
    "    pred_batch.extend(y_pred.tolist())\n",
    "    total_labels += y.size(0)\n",
    "    correctly_pred += (y_pred==y).sum().item()\n",
    "    current_acc = (correctly_pred/total_labels)\n",
    "    if i%5==0:\n",
    "        seconds_passed = time.time()-t_batch\n",
    "        print(f'After {i} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "\n",
    "test_acc = (correctly_pred/total_labels)\n",
    "print(f'Test accuracy: {test_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Test time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7. Saving pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "file_path = 'C:/Users/vkrmj/model_64_1.pt'\n",
    "\n",
    "state = {\n",
    "    'epoch': num_epoch,\n",
    "    'state_dict': net.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'lr': lr\n",
    "}\n",
    "\n",
    "torch.save(state, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8. Loading Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded Successfully\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from torch.nn import Sequential, Module, Conv2d, MaxPool2d, Linear, ReLU, Dropout, BatchNorm2d, LeakyReLU, AdaptiveAvgPool2d, Flatten\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import gc\n",
    "from PIL import Image\n",
    "from torchvision.datasets import VisionDataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io as sk_io, transform as sk_transform\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "\n",
    "file_path = 'C:/Users/vkrmj/model_64_1.pt'\n",
    "\n",
    "state = torch.load(file_path)\n",
    "\n",
    "loaded_net = ProjectModel()\n",
    "loaded_net.load_state_dict(state['state_dict'])\n",
    "\n",
    "loaded_lr = state['lr']\n",
    "loaded_loss_evaluater = CrossEntropyLoss()\n",
    "loaded_optimizer = Adam(loaded_net.parameters(), lr=loaded_lr)\n",
    "loaded_optimizer.load_state_dict(state['optimizer'])\n",
    "\n",
    "loaded_num_epoch = state['epoch']\n",
    "print('Model Loaded Successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing loaded pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset: size: 150\n",
      "Test X | y batch shapes : (torch.Size([8, 3, 64, 64]), torch.Size([8]))\n"
     ]
    }
   ],
   "source": [
    "data_dir_test_male = 'D:/Courses/COMP 6721 Applied AI/Project/GitRepo/dataset_p_2_64/rescaled/test_male/'\n",
    "\n",
    "test_dataset_male = ImageFolder(\n",
    "    root=data_dir_test_male\n",
    "    ,transform=data_transform\n",
    ")\n",
    "print(f'Test dataset: size: {len(test_dataset_male)}')\n",
    "\n",
    "test_dataloader_male = DataLoader(test_dataset_male, batch_size=8, shuffle=True)\n",
    "for data, labels in test_dataloader:\n",
    "    print(f'Test X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 batches: [time:0.0m 0.16484785079956055s, Accuracy: 62.5]\n",
      "After 5 batches: [time:0.0m 0.961421012878418s, Accuracy: 68.75]\n",
      "After 10 batches: [time:0.0m 1.813323974609375s, Accuracy: 71.5909090909091]\n",
      "After 15 batches: [time:0.0m 2.604869842529297s, Accuracy: 74.21875]\n",
      "Test accuracy: 72.66666666666667\n",
      "Test time: 0.0m 3.0710079669952393s\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "loaded_net.eval()\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "total_labels = 0\n",
    "correctly_pred = 0\n",
    "t_batch = time.time()\n",
    "test_batch=[]\n",
    "pred_batch=[]\n",
    "\n",
    "for i, (data, labels) in enumerate(test_dataloader_male):\n",
    "    torch.cuda.empty_cache()\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "    gc.collect()\n",
    "    X, y = data, labels\n",
    "    test_batch.extend(y.tolist())\n",
    "    output = loaded_net(X)\n",
    "    y_pred = torch.argmax(output, dim=1)\n",
    "    pred_batch.extend(y_pred.tolist())\n",
    "    total_labels += y.size(0)\n",
    "    correctly_pred += (y_pred==y).sum().item()\n",
    "    current_acc = (correctly_pred/total_labels)\n",
    "    if i%5==0:\n",
    "        seconds_passed = time.time()-t_batch\n",
    "        print(f'After {i} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "\n",
    "test_acc = (correctly_pred/total_labels)\n",
    "print(f'Test accuracy: {test_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Test time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "mask_index=test_dataset.class_to_idx['mask']\n",
    "no_mask_index=test_dataset.class_to_idx['no_mask']\n",
    "not_person_index=test_dataset.class_to_idx['not_person']\n",
    "\n",
    "confusion_metrics_final=metrics.confusion_matrix(test_batch,pred_batch)\n",
    "precision_final=metrics.precision_score(test_batch, pred_batch, average=None)\n",
    "recall_final=metrics.recall_score(test_batch, pred_batch, average=None)\n",
    "f1_final=metrics.f1_score(test_batch, pred_batch, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the model is 72.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for the model is {test_acc*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for the class mask is 65.38461538461539 %\n",
      "Precision for the class no_mask is 73.68421052631578 %\n",
      "Precision for the class not_person is 78.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision for the class mask is {precision_final[mask_index]*100} %')\n",
    "print(f'Precision for the class no_mask is {precision_final[no_mask_index]*100} %')\n",
    "print(f'Precision for the class not_person is {precision_final[not_person_index]*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for the class mask is 68.0 %\n",
      "Recall for the class no_mask is 56.00000000000001 %\n",
      "Recall for the class not_person is 94.0 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Recall for the class mask is {recall_final[mask_index]*100} %')\n",
    "print(f'Recall for the class no_mask is {recall_final[no_mask_index]*100} %')\n",
    "print(f'Recall for the class not_person is {recall_final[not_person_index]*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for the class mask is 66.66666666666666 %\n",
      "F1 Score for the class no_mask is 63.63636363636363 %\n",
      "F1 Score for the class not_person is 85.45454545454547 %\n"
     ]
    }
   ],
   "source": [
    "print(f'F1 Score for the class mask is {f1_final[mask_index]*100} %')\n",
    "print(f'F1 Score for the class no_mask is {f1_final[no_mask_index]*100} %')\n",
    "print(f'F1 Score for the class not_person is {f1_final[not_person_index]*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2118b364190>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "torch.manual_seed(6721)\n",
    "np.random.seed(6721)\n",
    "\n",
    "cm = confusion_matrix(test_batch, pred_batch, normalize='all')*100\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['mask', 'no_mask', 'not_person'])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('Confusion Matrix(%)')\n",
    "cmd.plot(ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# == End =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
