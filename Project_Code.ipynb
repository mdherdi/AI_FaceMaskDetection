{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, debug=False):\n",
    "        self.label_info_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.debug = debug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_info_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        label_img_name = self.label_info_frame.iloc[idx, 0]\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                label_img_name)\n",
    "        image = io.imread(img_name)\n",
    "        label = self.label_info_frame.iloc[idx, 1]\n",
    "        label = np.array([label])\n",
    "        landmarks = label.astype('float').reshape(-1, 1)\n",
    "        sample = {'image': image\n",
    "                  ,'label': label\n",
    "                  ,'name': label_img_name }\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        if self.debug:\n",
    "            print(label_img_name)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3091\n",
      "mask\\0003.jpg\n",
      "mask\\0003.jpg (2002, 3000, 3)\n"
     ]
    }
   ],
   "source": [
    "face_dataset = ProjectDataset(\n",
    "    csv_file='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/comp-6721-project/label_info.csv'\n",
    "    ,root_dir='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/1/dataset/images/')\n",
    "print(len(face_dataset))\n",
    "face_dataset.debug = True\n",
    "sample = face_dataset[0]\n",
    "print(sample['name'], sample['image'].shape)\n",
    "face_dataset.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "#             if h > w:\n",
    "#                 new_h, new_w = self.output_size * h / w, self.output_size\n",
    "#             else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        return {'image': img, 'label': label}\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        return {'image': image, 'label': label}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'label': torch.from_numpy(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = Rescale(512)\n",
    "crop = RandomCrop(128)\n",
    "composed = transforms.Compose([Rescale(256),\n",
    "                               RandomCrop(224)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "35.84386610984802\n",
      "200\n",
      "63.015703439712524\n",
      "300\n",
      "86.83172297477722\n",
      "400\n",
      "123.0325517654419\n",
      "500\n",
      "154.57428193092346\n",
      "600\n",
      "232.01140642166138\n",
      "700\n",
      "267.16561794281006\n",
      "800\n",
      "286.43241357803345\n",
      "900\n",
      "307.0557301044464\n",
      "1000\n",
      "322.20960879325867\n",
      "1100\n",
      "334.43564343452454\n",
      "1200\n",
      "351.1432144641876\n",
      "1300\n",
      "370.3830246925354\n",
      "1400\n",
      "387.9676263332367\n",
      "1500\n",
      "407.743775844574\n",
      "1600\n",
      "430.16234827041626\n",
      "1700\n",
      "533.25239777565\n",
      "1800\n",
      "770.5090777873993\n",
      "1900\n",
      "1055.697925567627\n",
      "2000\n",
      "1241.8436603546143\n",
      "2100\n",
      "1392.105262517929\n",
      "2200\n",
      "1562.8205502033234\n",
      "2300\n",
      "1577.3249225616455\n",
      "2400\n",
      "1599.721957206726\n",
      "2500\n",
      "1638.8086278438568\n",
      "2600\n",
      "1647.3492488861084\n",
      "2700\n",
      "1681.4737355709076\n",
      "2800\n",
      "1696.5142893791199\n",
      "2900\n",
      "1712.857860326767\n",
      "3000\n",
      "1737.6331858634949\n",
      "1753.2574436664581\n",
      "6720 8192 352 320\n",
      "[  0.   0.   0.   8. 158. 338. 596. 463. 202. 162. 322.  41. 115.  10.\n",
      "  30.  15.  18.   4.   9.  29.  21.   6.   2.   2.  11.   8.   1.   0.\n",
      "   4.   4.  15.  31.  38.   2.   2.   2.   0.   2.   3.   1.  87.   1.\n",
      " 300.   1.   0.   1.   1.   1.   0.   2.   1.   0.   1.   2.   2.   0.\n",
      "   1.   2.   0.   2.   7.   1.   1.   0.   0.   0.   0.   2.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "{0: array([  0.,   0.,   0.,   3.,  96., 276., 392., 351., 132.,  97., 178.,\n",
      "        30.,  71.,   6.,  19.,   9.,  12.,   1.,   6.,   7.,   9.,   5.,\n",
      "         1.,   1.,   1.,   3.,   1.,   0.,   3.,   1.,   3.,   2.,   0.,\n",
      "         0.,   0.,   2.,   0.,   2.,   1.,   0.,   6.,   1.,   2.,   1.,\n",
      "         0.,   1.,   0.,   1.,   0.,   1.,   1.,   0.,   0.,   1.,   1.,\n",
      "         0.,   1.,   0.,   0.,   2.,   6.,   1.,   1.,   0.,   0.,   0.,\n",
      "         0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.]), 1: array([  0.,   0.,   0.,   5.,  62.,  62., 204., 112.,  70.,  65., 144.,\n",
      "        11.,  44.,   4.,  11.,   6.,   6.,   3.,   3.,  22.,  12.,   1.,\n",
      "         1.,   1.,   7.,   5.,   0.,   0.,   1.,   3.,   5.,   1.,   2.,\n",
      "         2.,   2.,   0.,   0.,   0.,   2.,   1.,   3.,   0.,   1.,   0.,\n",
      "         0.,   0.,   1.,   0.,   0.,   1.,   0.,   0.,   1.,   0.,   1.,\n",
      "         0.,   0.,   2.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.]), 2: array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.,   0.,   3.,   0.,   0.,   0.,   0.,   0.,   7.,  28.,  36.,\n",
      "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  78.,   0., 297.,   0.,\n",
      "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
      "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.])}\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "counts = np.zeros((100, ))\n",
    "label_counts = {0: np.zeros((100, ))\n",
    "                , 1: np.zeros((100, ))\n",
    "                , 2:np.zeros((100, ))}\n",
    "\n",
    "face_dataset.debug=False\n",
    "t1 = time.time()\n",
    "max_w, max_h = 0, 0\n",
    "min_w, min_h = 1000000, 100000\n",
    "count = 0\n",
    "for k in range(len(face_dataset)):\n",
    "    sample = face_dataset[k]\n",
    "    sample_image = sample['image']\n",
    "    label = sample['label'][0]\n",
    "#     print(sample['name'], sample_image.shape)\n",
    "    \n",
    "    h, w, _ = sample_image.shape\n",
    "    if w>max_w:\n",
    "        max_w = w\n",
    "    if h>max_h:\n",
    "        max_h = h\n",
    "    if w<min_w:\n",
    "        min_w = w\n",
    "    if h<min_h:\n",
    "        min_h = h\n",
    "    \n",
    "    index = w//100\n",
    "    \n",
    "#     if not index in counts:\n",
    "#         counts[index]=0\n",
    "    counts[index]+=1\n",
    "    \n",
    "#     if not index in label_counts[label]:\n",
    "#         label_counts[label][index]=0\n",
    "    label_counts[label][index]+=1\n",
    "    \n",
    "    transformed_sample = scale(sample)\n",
    "    image = transformed_sample['image']\n",
    "#     print(image.shape)\n",
    "#   print(image.shape)\n",
    "#     plt.figure()\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()\n",
    "    count+=1\n",
    "    if count%100==0:\n",
    "        gc.collect()\n",
    "        print(count)\n",
    "        print((time.time()-t1))\n",
    "    \n",
    "print((time.time()-t1))\n",
    "print(max_w, max_h, min_w, min_h)\n",
    "print(counts)\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = ProjectDataset(csv_file='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/comp-6721-project/label_info.csv'\n",
    "                                     ,root_dir='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/1/dataset/images/'\n",
    "                                     ,transform=transforms.Compose([\n",
    "                                         Rescale(512)\n",
    "                                         ,ToTensor()\n",
    "                                     ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(transformed_dataset, batch_size=16,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
