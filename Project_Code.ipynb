{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>\n",
    "COMP-6721 | 2021-Winter\n",
    "Project | Part-1\n",
    "\n",
    "Pravesh Gupta | 40152506\n",
    "Vikramjeet Singh | \n",
    "Manjot Kaur Dherdi | \n",
    "</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Installing required python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torch) (1.19.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: torch==1.8.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torchvision) (1.8.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torch==1.8.0->torchvision) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vkrmj\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: torch==1.8.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torchvision) (1.8.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from torch==1.8.0->torchvision) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.15.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (1.5.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (3.3.2)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (8.0.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (2020.10.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2020.6.20)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vkrmj\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (1.19.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1321 sha256=8791b43b8cde719410e725d1359a1a716b735865b6ba038e74ce9f9986d149e0\n",
      "  Stored in directory: c:\\users\\vkrmj\\appdata\\local\\pip\\cache\\wheels\\22\\0b\\40\\fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\vkrmj\\anaconda3\\lib\\site-packages (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Required Dataset Folder Heirarchy:\n",
    "<pre>\n",
    "{dataset_folder}\n",
    "--images\n",
    "----mask\n",
    "-------{mask images}\n",
    "----no_mask\n",
    "-------{no mask images}\n",
    "----not_person\n",
    "-------{not person images}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Defining Pytorch dataset Representation and data transaformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VisionDataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io as sk_io, transform as sk_transform\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "    \n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size, debug=False, export_path=None):\n",
    "        assert isinstance(output_size, (int))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, img_data):\n",
    "        img_arr = np.array(img_data)\n",
    "        scale_factor = float(self.output_size)/img_arr.shape[0]\n",
    "        img_arr = (sk_transform.rescale(img_arr, (scale_factor, scale_factor, 1))*255).astype(np.uint8)\n",
    "        \n",
    "        new_w = img_arr.shape[1]\n",
    "        \n",
    "        # Clipping or filling\n",
    "        if new_w>self.output_size:\n",
    "            mid = new_w//2\n",
    "            new_w_start = mid-self.output_size//2\n",
    "            new_w_end = mid+self.output_size//2\n",
    "            \n",
    "            if (new_w_end-new_w_start)<self.output_size:\n",
    "                new_w_end += (self.output_size-(new_w_end-new_w_start))\n",
    "            elif (new_w_end-new_w_start)>self.output_size:\n",
    "                new_w_end -= ((new_w_end-new_w_start)-self.output_size)\n",
    "            img_arr = img_arr[:, new_w_start:new_w_end]\n",
    "        elif new_w<self.output_size:\n",
    "            mid = new_w//2\n",
    "            new_w_start = self.output_size//2-mid\n",
    "            new_w_end = new_w_start+new_w\n",
    "            filled_img_arr = np.zeros((self.output_size, self.output_size, img_arr.shape[2]), dtype=np.uint8)\n",
    "            filled_img_arr[:, new_w_start:new_w_end] = img_arr[:, :]\n",
    "            img_arr = filled_img_arr\n",
    "        return Image.fromarray(img_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Creating dataset and data loaders for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_indices(dataset_targets):\n",
    "    test_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        test_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    train_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        train_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    targets = np.array(dataset.targets, dtype=np.int32)\n",
    "    target_indices = np.where(targets!=None)[0]\n",
    "    np.random.shuffle(target_indices)\n",
    "\n",
    "    for i in target_indices:\n",
    "        label = dataset.targets[i]\n",
    "        if test_indices_map[label]['count']<100:\n",
    "            test_indices_map[label]['indices'] = np.append(test_indices_map[label]['indices'], i)\n",
    "            test_indices_map[label]['count']+=1\n",
    "        elif train_indices_map[label]['count']<350:\n",
    "            train_indices_map[label]['indices'] = np.append(train_indices_map[label]['indices'], i)\n",
    "            train_indices_map[label]['count']+=1\n",
    "\n",
    "    test_indices = np.array([], dtype=np.int32)\n",
    "    train_indices = np.array([], dtype=np.int32)\n",
    "\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        label_test_indices = test_indices_map[label]['indices']\n",
    "        test_indices = np.append(test_indices, label_test_indices)\n",
    "\n",
    "        label_train_indices = train_indices_map[label]['indices']\n",
    "        train_indices = np.append(train_indices, label_train_indices)\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: size: 3091, class labels: {'mask': 0, 'no_mask': 1, 'not_person': 2}\n",
      "Train dataset: size: 1050\n",
      "Train X | y batch shapes : (torch.Size([10, 3, 512, 512]), torch.Size([10]))\n",
      "Test dataset: size: 300\n",
      "Test X | y batch shapes : (torch.Size([10, 3, 512, 512]), torch.Size([10]))\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "data_transform = Compose([\n",
    "    Rescale(512)\n",
    "    ,ToTensor()\n",
    "#     ,Normalize(mean=torch.zeros((3)),std=torch.ones((3)))\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    root='D:/Courses/COMP 6721 Applied AI/Project/Iteration1/Dataset/images/'\n",
    "    ,transform=data_transform\n",
    ")\n",
    "print(f'Dataset: size: {len(dataset)}, class labels: {dataset.class_to_idx}')\n",
    "\n",
    "train_indices, test_indices = get_train_test_indices(dataset.targets)\n",
    "    \n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "print(f'Train dataset: size: {len(train_dataset)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "for data, labels in train_dataloader:\n",
    "    print(f'Train X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break\n",
    "\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "print(f'Test dataset: size: {len(test_dataset)}')\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n",
    "for data, labels in test_dataloader:\n",
    "    print(f'Test X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Conv2d, MaxPool2d, Linear, ReLU\n",
    "\n",
    "class ProjectModel(Module):\n",
    "    def __init__(self):\n",
    "        super(ProjectModel, self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=2)\n",
    "        self.pool1 = MaxPool2d(2)\n",
    "        self.conv2 = Conv2d(in_channels=16, out_channels = 32, kernel_size=3)\n",
    "        self.linear = Linear(in_features = 32*125*125, out_features=3)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        relu = ReLU(inplace=False)\n",
    "        X = self.conv1(X)\n",
    "        X = relu(X)\n",
    "        X = self.pool1(X)\n",
    "        X = self.conv2(X)\n",
    "        X = relu(X)\n",
    "        X = torch.flatten(X, 1)\n",
    "        X = self.linear(X)\n",
    "        return X\n",
    "\n",
    "net = ProjectModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Integrity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0044, -0.0378, -0.0162],\n",
      "        [ 0.0201, -0.0536,  0.0202],\n",
      "        [ 0.0127, -0.0462,  0.0125],\n",
      "        [ 0.0087, -0.0673,  0.0153],\n",
      "        [ 0.0023, -0.0628,  0.0035],\n",
      "        [-0.0025, -0.0476, -0.0018],\n",
      "        [ 0.0090, -0.0878,  0.0113],\n",
      "        [-0.0106, -0.0555,  0.0276],\n",
      "        [ 0.0034, -0.0724,  0.0143],\n",
      "        [-0.0046, -0.0490,  0.0060]], grad_fn=<AddmmBackward>)\n",
      "tensor([0, 2, 0, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([[0.3384, 0.3272, 0.3344],\n",
      "        [0.3414, 0.3172, 0.3414],\n",
      "        [0.3398, 0.3204, 0.3398],\n",
      "        [0.3409, 0.3160, 0.3431],\n",
      "        [0.3404, 0.3189, 0.3408],\n",
      "        [0.3382, 0.3233, 0.3385],\n",
      "        [0.3436, 0.3119, 0.3444],\n",
      "        [0.3339, 0.3192, 0.3469],\n",
      "        [0.3404, 0.3155, 0.3441],\n",
      "        [0.3370, 0.3224, 0.3406]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([0, 2, 0, 2, 2, 2, 2, 2, 2, 2])\n",
      "Model test passed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Model Unit test\n",
    "for data, labels in train_dataloader:\n",
    "    outputs = net(data)\n",
    "    print(outputs)\n",
    "    _, y_pred = torch.max(outputs.data, 1)\n",
    "    print(y_pred)\n",
    "    prob = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    print(prob)\n",
    "    label_pred = torch.argmax(prob, dim=1)\n",
    "    print(label_pred)\n",
    "    acc = metrics.accuracy_score(labels, y_pred, normalize=True)\n",
    "    break\n",
    "print('Model test passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: [time:0.0m 2.8794808387756348s, Accuracy: 30.0]\n",
      "Training time: 0.0m 2.8794808387756348s\n",
      "=============================================\n",
      "Training accuracy: 33.33333333333332\n",
      "Trainig evaluation time: 4.0m 53.35770297050476s\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import time\n",
    "\n",
    "num_epoch = 5\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "loss_evaluater = CrossEntropyLoss()\n",
    "optimizer = SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "t = time.time()\n",
    "for i in range(num_epoch):\n",
    "    train_acc_sum = 0.0\n",
    "    batch_count = 0\n",
    "    t_epoch = time.time()\n",
    "    for data, labels in train_dataloader:\n",
    "        X, y = data, labels\n",
    "        optimizer.zero_grad()\n",
    "        output = net(X)\n",
    "        loss = loss_evaluater(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, y_pred = torch.max(output.data, 1)\n",
    "        acc = metrics.accuracy_score(y, y_pred)\n",
    "        batch_count+=1\n",
    "        train_acc_sum+=acc\n",
    "    epoch_acc = (train_acc_sum/batch_count)\n",
    "    seconds_passed = time.time()-t_epoch\n",
    "    print(f'Epoch {i+1}: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {epoch_acc*100}]')\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Training time: {seconds_passed//60}m {seconds_passed%60}s')\n",
    "print('=============================================')\n",
    "\n",
    "t = time.time()\n",
    "with torch.no_grad():\n",
    "    acc_sum = 0.0\n",
    "    batch_count = 0\n",
    "    for data, labels in train_dataloader:\n",
    "        X, y = data, labels\n",
    "        output = net(X)\n",
    "        _, y_pred = torch.max(output.data, 1)\n",
    "        acc = metrics.accuracy_score(y, y_pred)\n",
    "        acc_sum+=acc\n",
    "        batch_count+=1\n",
    "    train_acc = acc_sum/batch_count\n",
    "    print(f'Training accuracy: {train_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Trainig evaluation time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "acc_sum = 0.0\n",
    "precision_sum = 0.0\n",
    "recall_sum = 0.0\n",
    "f1_sum = 0.0\n",
    "batch_count = 0\n",
    "for data, labels in test_dataloader:\n",
    "    X, y = data, labels\n",
    "    output = net(X)\n",
    "    _, y_pred = torch.max(output.data, 1)\n",
    "    acc = metrics.accuracy_score(y, y_pred)\n",
    "    acc_sum+=acc\n",
    "    precision=metrics.precision_score(y, y_pred, average='weighted')\n",
    "    precision_sum+=precision\n",
    "    recall=metrics.recall_score(y, y_pred, average='weighted')\n",
    "    recall_sum+=recall\n",
    "    f1=metrics.f1_score(y, y_pred, average='weighted')\n",
    "    f1_sum+=f1\n",
    "    batch_count+=1\n",
    "test_acc = acc_sum/batch_count\n",
    "print(f'Test accuracy: {test_acc*100}')\n",
    "test_precision = precision_sum/batch_count\n",
    "print(f'Test precision: {test_precision*100}')\n",
    "test_recall = recall_sum/batch_count\n",
    "print(f'Test recall: {test_recall*100}')\n",
    "test_f1 = f1_sum/batch_count\n",
    "print(f'Test f1 score: {test_f1*100}')\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Test time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the model is 50.0 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for the model is {test_acc*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for the model is 4.0 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision for the model is {test_precision*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for the model is 20.0 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Recall for the model is {test_recall*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for the model is 6.666666666666668 %\n"
     ]
    }
   ],
   "source": [
    "print(f'F1 score for the model is {test_f1*100} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
