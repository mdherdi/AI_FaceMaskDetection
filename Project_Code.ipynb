{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>\n",
    "COMP-6721 | 2021-Winter\n",
    "Project | Part-1\n",
    "\n",
    "Pravesh Gupta | 40152506\n",
    "Vikramjeet Singh | \n",
    "Manjot Kaur Dherdi | \n",
    "</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Installing required python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\installations\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: future in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (0.6)\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in d:\\installations\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.18.5)\n",
      "Requirement already satisfied: torch==1.7.0 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.7.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (7.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: future in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.6)\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\installations\\anaconda3\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\installations\\anaconda3\\lib\\site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in d:\\installations\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\installations\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\installations\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in d:\\installations\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.18.5)\n",
      "Requirement already satisfied: torch==1.7.0 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.7.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (7.2.0)\n",
      "Requirement already satisfied: future in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in d:\\installations\\anaconda3\\lib\\site-packages (0.16.2)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (7.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (3.2.2)\n",
      "Requirement already satisfied: scipy>=0.19.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (1.5.0)\n",
      "Requirement already satisfied: networkx>=2.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\installations\\anaconda3\\lib\\site-packages (from PyWavelets>=0.4.0->scikit-image) (1.18.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\installations\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: six in d:\\installations\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in d:\\installations\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\installations\\anaconda3\\lib\\site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in d:\\installations\\anaconda3\\lib\\site-packages (7.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Required Dataset Folder Heirarchy:\n",
    "<pre>\n",
    "{dataset_folder}\n",
    "--images\n",
    "----mask\n",
    "-------{mask images}\n",
    "----no_mask\n",
    "-------{no mask images}\n",
    "----not_person\n",
    "-------{not person images}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Defining Pytorch dataset Representation and data transaformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VisionDataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io as sk_io, transform as sk_transform\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "    \n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size, debug=False, export_path=None):\n",
    "        assert isinstance(output_size, (int))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, img_data):\n",
    "        img_arr = np.array(img_data)\n",
    "        h, w, c = img_arr.shape\n",
    "        isAlreadyScaled = (h==self.output_size and w==self.output_size)\n",
    "        \n",
    "        if not isAlreadyScaled:\n",
    "            scale_factor = float(self.output_size)/img_arr.shape[0]\n",
    "            img_arr = (sk_transform.rescale(img_arr, (scale_factor, scale_factor, 1))*255).astype(np.uint8)\n",
    "\n",
    "            new_w = img_arr.shape[1]\n",
    "\n",
    "            # Clipping or filling\n",
    "            if new_w>self.output_size:\n",
    "                mid = new_w//2\n",
    "                new_w_start = mid-self.output_size//2\n",
    "                new_w_end = mid+self.output_size//2\n",
    "\n",
    "                if (new_w_end-new_w_start)<self.output_size:\n",
    "                    new_w_end += (self.output_size-(new_w_end-new_w_start))\n",
    "                elif (new_w_end-new_w_start)>self.output_size:\n",
    "                    new_w_end -= ((new_w_end-new_w_start)-self.output_size)\n",
    "                img_arr = img_arr[:, new_w_start:new_w_end]\n",
    "            elif new_w<self.output_size:\n",
    "                mid = new_w//2\n",
    "                new_w_start = self.output_size//2-mid\n",
    "                new_w_end = new_w_start+new_w\n",
    "                filled_img_arr = np.zeros((self.output_size, self.output_size, img_arr.shape[2]), dtype=np.uint8)\n",
    "                filled_img_arr[:, new_w_start:new_w_end] = img_arr[:, :]\n",
    "                img_arr = filled_img_arr\n",
    "        return Image.fromarray(img_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Creating dataset and data loaders for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_indices(dataset_targets):\n",
    "    test_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        test_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    train_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        train_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    targets = np.array(dataset.targets, dtype=np.int32)\n",
    "    target_indices = np.where(targets!=None)[0]\n",
    "    np.random.shuffle(target_indices)\n",
    "\n",
    "    for i in target_indices:\n",
    "        label = dataset.targets[i]\n",
    "        if test_indices_map[label]['count']<100:\n",
    "            test_indices_map[label]['indices'] = np.append(test_indices_map[label]['indices'], i)\n",
    "            test_indices_map[label]['count']+=1\n",
    "        elif train_indices_map[label]['count']<350:\n",
    "            train_indices_map[label]['indices'] = np.append(train_indices_map[label]['indices'], i)\n",
    "            train_indices_map[label]['count']+=1\n",
    "\n",
    "    test_indices = np.array([], dtype=np.int32)\n",
    "    train_indices = np.array([], dtype=np.int32)\n",
    "\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        label_test_indices = test_indices_map[label]['indices']\n",
    "        test_indices = np.append(test_indices, label_test_indices)\n",
    "\n",
    "        label_train_indices = train_indices_map[label]['indices']\n",
    "        train_indices = np.append(train_indices, label_train_indices)\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: size: 1344, class labels: {'mask': 0, 'no_mask': 1, 'not_person': 2}\n",
      "Selected dataset: size: 1344\n",
      "Mean: tensor([0.4322, 0.4013, 0.3816])\n",
      "Std: tensor([0.2814, 0.2715, 0.2818])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import gc\n",
    "\n",
    "torch.manual_seed(6721)\n",
    "\n",
    "rescaled_size=512\n",
    "\n",
    "data_dir = './data/'\n",
    "\n",
    "data_transform = Compose([\n",
    "    Rescale(rescaled_size)\n",
    "    , ToTensor()\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    root=data_dir\n",
    "    ,transform=data_transform\n",
    ")\n",
    "print(f'Dataset: size: {len(dataset)}, class labels: {dataset.class_to_idx}')\n",
    "\n",
    "train_indices, test_indices = get_train_test_indices(dataset.targets)\n",
    "selected_indices = np.concatenate((train_indices, test_indices))\n",
    "\n",
    "selected_dataset = Subset(dataset, selected_indices)\n",
    "print(f'Selected dataset: size: {len(selected_dataset)}')\n",
    "selected_dataloader = DataLoader(selected_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "means = torch.tensor([])\n",
    "stds = torch.tensor([])\n",
    "for i, (data, labels) in enumerate(selected_dataloader):\n",
    "    gc.collect()\n",
    "    batch_mean = torch.mean(data, axis=(0, 2, 3))\n",
    "    batch_std = torch.std(data, axis=(0, 2, 3))\n",
    "    means = torch.cat((means, batch_mean.unsqueeze(0)))\n",
    "    stds = torch.cat((stds, batch_std.unsqueeze(0)))\n",
    "mean = torch.mean(means, axis=0)\n",
    "std = torch.mean(stds, axis=0)\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: size: 1044\n",
      "Train X | y batch shapes : (torch.Size([8, 3, 512, 512]), torch.Size([8]))\n",
      "Test dataset: size: 300\n",
      "Test X | y batch shapes : (torch.Size([8, 3, 512, 512]), torch.Size([8]))\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "data_transform = Compose([\n",
    "    Rescale(rescaled_size)\n",
    "    , ToTensor()\n",
    "    , Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    root=data_dir\n",
    "    ,transform=data_transform\n",
    ")\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "print(f'Train dataset: size: {len(train_dataset)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "for data, labels in train_dataloader:\n",
    "    print(f'Train X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break\n",
    "\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "print(f'Test dataset: size: {len(test_dataset)}')\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "for data, labels in test_dataloader:\n",
    "    print(f'Test X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Conv2d, MaxPool2d, Linear, ReLU\n",
    "\n",
    "class ProjectModel(Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(ProjectModel, self).__init__()\n",
    "        self.module = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=2)\n",
    "            , torch.nn.BatchNorm2d(32)\n",
    "            , torch.nn.LeakyReLU(inplace=True)\n",
    "            \n",
    "            , torch.nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0)\n",
    "            , torch.nn.BatchNorm2d(32)\n",
    "            , torch.nn.LeakyReLU(inplace=True)\n",
    "            \n",
    "            , torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "            , torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "            , torch.nn.BatchNorm2d(64)\n",
    "            , torch.nn.LeakyReLU(inplace=True)\n",
    "            \n",
    "            , torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "            , torch.nn.BatchNorm2d(64)\n",
    "            , torch.nn.LeakyReLU(inplace=True)\n",
    "            \n",
    "            , torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "            , torch.nn.Flatten()\n",
    "            , torch.nn.Linear(64*126*126, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.module(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Integrity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8427,  0.9975,  0.7415],\n",
      "        [ 2.3258,  0.4306,  0.6336],\n",
      "        [ 0.9899,  0.0332,  0.4025],\n",
      "        [ 0.1196,  1.0243, -0.4477],\n",
      "        [ 0.5997,  0.5001,  0.4291],\n",
      "        [ 1.0980,  0.6828,  0.0372],\n",
      "        [ 1.3799,  1.5422, -0.3335],\n",
      "        [ 0.9429,  0.4780,  0.2456]], grad_fn=<AddmmBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 0])\n",
      "Accuracy: 50.0\n",
      "Model test passed.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = ProjectModel()\n",
    "\n",
    "# net = net.to(device)\n",
    "\n",
    "# Model Unit test\n",
    "total_labels = 0\n",
    "correct_labels = 0\n",
    "for data, labels in train_dataloader:\n",
    "#     torch.cuda.empty_cache()\n",
    "#     data, labels = data.to(device), labels.to(device)\n",
    "    outputs = net(data)\n",
    "    print(outputs)\n",
    "    y_pred = torch.argmax(outputs, dim=1)\n",
    "    print(y_pred)\n",
    "    total_labels+=labels.size(0)\n",
    "    correct_labels += (y_pred==labels).sum().item()\n",
    "    break\n",
    "\n",
    "print(f'Accuracy: {(correct_labels/total_labels)*100}')\n",
    "print('Model test passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "After 0 batches: [time:0.0m 7.9788360595703125s, Accuracy: 50.0]\n",
      "After 5 batches: [time:0.0m 37.384806632995605s, Accuracy: 37.5]\n",
      "After 10 batches: [time:1.0m 5.338175296783447s, Accuracy: 36.36363636363637]\n",
      "After 15 batches: [time:1.0m 33.06679153442383s, Accuracy: 36.71875]\n",
      "After 20 batches: [time:2.0m 0.7114949226379395s, Accuracy: 39.285714285714285]\n",
      "After 25 batches: [time:2.0m 28.31422758102417s, Accuracy: 40.86538461538461]\n",
      "After 30 batches: [time:2.0m 58.5833740234375s, Accuracy: 39.516129032258064]\n",
      "After 35 batches: [time:3.0m 26.927509546279907s, Accuracy: 39.58333333333333]\n",
      "After 40 batches: [time:3.0m 56.62056827545166s, Accuracy: 39.02439024390244]\n",
      "After 45 batches: [time:4.0m 25.321579933166504s, Accuracy: 40.21739130434783]\n",
      "After 50 batches: [time:4.0m 53.31445503234863s, Accuracy: 41.17647058823529]\n",
      "After 55 batches: [time:5.0m 21.514552116394043s, Accuracy: 41.294642857142854]\n",
      "After 60 batches: [time:5.0m 49.809208393096924s, Accuracy: 40.16393442622951]\n",
      "After 65 batches: [time:6.0m 18.718305349349976s, Accuracy: 39.96212121212121]\n",
      "After 70 batches: [time:6.0m 48.46769332885742s, Accuracy: 39.7887323943662]\n",
      "After 75 batches: [time:7.0m 16.78307795524597s, Accuracy: 40.46052631578947]\n",
      "After 80 batches: [time:7.0m 46.5604133605957s, Accuracy: 41.9753086419753]\n",
      "After 85 batches: [time:8.0m 15.331015586853027s, Accuracy: 42.73255813953488]\n",
      "After 90 batches: [time:8.0m 44.28586459159851s, Accuracy: 43.543956043956044]\n",
      "After 95 batches: [time:9.0m 12.993597269058228s, Accuracy: 43.88020833333333]\n",
      "After 100 batches: [time:9.0m 41.637163162231445s, Accuracy: 44.554455445544555]\n",
      "After 105 batches: [time:10.0m 10.924785614013672s, Accuracy: 45.04716981132076]\n",
      "After 110 batches: [time:10.0m 38.847259759902954s, Accuracy: 45.15765765765766]\n",
      "After 115 batches: [time:11.0m 6.689841270446777s, Accuracy: 45.258620689655174]\n",
      "After 120 batches: [time:11.0m 34.711276054382324s, Accuracy: 45.14462809917356]\n",
      "After 125 batches: [time:12.0m 5.411188840866089s, Accuracy: 45.03968253968254]\n",
      "After 130 batches: [time:12.0m 33.157283306121826s, Accuracy: 45.593869731800766]\n",
      "Epoch 1: [time:12.0m 33.157283306121826s, Accuracy: 45.593869731800766]\n",
      "\n",
      "Epoch: 2\n",
      "After 0 batches: [time:0.0m 5.378883361816406s, Accuracy: 50.0]\n",
      "After 5 batches: [time:0.0m 32.83266758918762s, Accuracy: 62.5]\n",
      "After 10 batches: [time:1.0m 0.24231553077697754s, Accuracy: 63.63636363636363]\n",
      "After 15 batches: [time:1.0m 27.884612321853638s, Accuracy: 64.84375]\n",
      "After 20 batches: [time:1.0m 54.79017782211304s, Accuracy: 61.904761904761905]\n",
      "After 25 batches: [time:2.0m 21.935604333877563s, Accuracy: 60.09615384615385]\n",
      "After 30 batches: [time:2.0m 49.3152277469635s, Accuracy: 58.46774193548387]\n",
      "After 35 batches: [time:3.0m 16.538288593292236s, Accuracy: 57.638888888888886]\n",
      "After 40 batches: [time:3.0m 43.91001105308533s, Accuracy: 58.536585365853654]\n",
      "After 45 batches: [time:7.0m 21.915177822113037s, Accuracy: 58.69565217391305]\n",
      "After 50 batches: [time:7.0m 55.78156232833862s, Accuracy: 59.068627450980394]\n",
      "After 55 batches: [time:8.0m 25.62941861152649s, Accuracy: 59.375]\n",
      "After 60 batches: [time:9.0m 3.759885549545288s, Accuracy: 60.45081967213115]\n",
      "After 65 batches: [time:9.0m 35.96171545982361s, Accuracy: 60.22727272727273]\n",
      "After 70 batches: [time:10.0m 6.164594411849976s, Accuracy: 61.267605633802816]\n",
      "After 75 batches: [time:10.0m 39.85802125930786s, Accuracy: 61.18421052631579]\n",
      "After 80 batches: [time:11.0m 9.046142816543579s, Accuracy: 60.18518518518518]\n",
      "After 85 batches: [time:11.0m 35.334758281707764s, Accuracy: 59.883720930232556]\n",
      "After 90 batches: [time:12.0m 4.2471678256988525s, Accuracy: 59.34065934065934]\n",
      "After 95 batches: [time:12.0m 35.76820611953735s, Accuracy: 60.026041666666664]\n",
      "After 100 batches: [time:13.0m 6.098367929458618s, Accuracy: 60.27227722772277]\n",
      "After 105 batches: [time:13.0m 32.07094383239746s, Accuracy: 59.43396226415094]\n",
      "After 110 batches: [time:14.0m 0.6456863880157471s, Accuracy: 59.12162162162162]\n",
      "After 115 batches: [time:14.0m 28.61453938484192s, Accuracy: 59.59051724137932]\n",
      "After 120 batches: [time:14.0m 58.053465843200684s, Accuracy: 59.607438016528924]\n",
      "After 125 batches: [time:15.0m 26.94093132019043s, Accuracy: 59.82142857142857]\n",
      "After 130 batches: [time:15.0m 51.189475536346436s, Accuracy: 59.48275862068966]\n",
      "Epoch 2: [time:15.0m 51.189475536346436s, Accuracy: 59.48275862068966]\n",
      "\n",
      "Epoch: 3\n",
      "After 0 batches: [time:0.0m 5.292974472045898s, Accuracy: 75.0]\n",
      "After 5 batches: [time:0.0m 33.31516098976135s, Accuracy: 45.83333333333333]\n",
      "After 10 batches: [time:1.0m 0.5509138107299805s, Accuracy: 53.40909090909091]\n",
      "After 15 batches: [time:1.0m 28.1987726688385s, Accuracy: 60.9375]\n",
      "After 20 batches: [time:1.0m 55.11853361129761s, Accuracy: 64.28571428571429]\n",
      "After 25 batches: [time:2.0m 22.634020805358887s, Accuracy: 62.980769230769226]\n",
      "After 30 batches: [time:2.0m 52.55472183227539s, Accuracy: 64.91935483870968]\n",
      "After 35 batches: [time:3.0m 20.993136882781982s, Accuracy: 65.27777777777779]\n",
      "After 40 batches: [time:3.0m 49.549073696136475s, Accuracy: 65.2439024390244]\n",
      "After 45 batches: [time:4.0m 16.922235250473022s, Accuracy: 65.48913043478261]\n",
      "After 50 batches: [time:4.0m 44.30492615699768s, Accuracy: 65.44117647058823]\n",
      "After 55 batches: [time:5.0m 15.399681329727173s, Accuracy: 66.51785714285714]\n",
      "After 60 batches: [time:5.0m 46.865036725997925s, Accuracy: 65.3688524590164]\n",
      "After 65 batches: [time:6.0m 16.316447496414185s, Accuracy: 65.3409090909091]\n",
      "After 70 batches: [time:6.0m 45.462870359420776s, Accuracy: 65.84507042253522]\n",
      "After 75 batches: [time:7.0m 15.06784987449646s, Accuracy: 66.94078947368422]\n",
      "After 80 batches: [time:7.0m 44.56881642341614s, Accuracy: 67.43827160493827]\n",
      "After 85 batches: [time:8.0m 13.649721622467041s, Accuracy: 68.02325581395348]\n",
      "After 90 batches: [time:8.0m 51.84139966964722s, Accuracy: 68.4065934065934]\n",
      "After 95 batches: [time:9.0m 24.526318073272705s, Accuracy: 67.70833333333334]\n",
      "After 100 batches: [time:9.0m 54.80579876899719s, Accuracy: 67.57425742574257]\n",
      "After 105 batches: [time:10.0m 23.93443250656128s, Accuracy: 68.04245283018868]\n",
      "After 110 batches: [time:10.0m 52.798656940460205s, Accuracy: 67.9054054054054]\n",
      "After 115 batches: [time:11.0m 21.46292018890381s, Accuracy: 68.64224137931035]\n",
      "After 120 batches: [time:11.0m 50.09316682815552s, Accuracy: 68.28512396694215]\n",
      "After 125 batches: [time:12.0m 18.686344146728516s, Accuracy: 68.15476190476191]\n",
      "After 130 batches: [time:12.0m 44.06558084487915s, Accuracy: 68.00766283524904]\n",
      "Epoch 3: [time:12.0m 44.06657862663269s, Accuracy: 68.00766283524904]\n",
      "\n",
      "Epoch: 4\n",
      "After 0 batches: [time:0.0m 5.710983753204346s, Accuracy: 75.0]\n",
      "After 5 batches: [time:0.0m 34.28153324127197s, Accuracy: 79.16666666666666]\n",
      "After 10 batches: [time:1.0m 3.067932605743408s, Accuracy: 78.4090909090909]\n",
      "After 15 batches: [time:1.0m 34.502336502075195s, Accuracy: 79.6875]\n",
      "After 20 batches: [time:2.0m 4.732884168624878s, Accuracy: 77.97619047619048]\n",
      "After 25 batches: [time:2.0m 39.51211094856262s, Accuracy: 77.88461538461539]\n",
      "After 30 batches: [time:3.0m 10.302167892456055s, Accuracy: 78.2258064516129]\n",
      "After 35 batches: [time:3.0m 41.87376952171326s, Accuracy: 78.125]\n",
      "After 40 batches: [time:4.0m 12.178361892700195s, Accuracy: 77.4390243902439]\n",
      "After 45 batches: [time:4.0m 41.23552417755127s, Accuracy: 76.63043478260869]\n",
      "After 50 batches: [time:5.0m 11.232254981994629s, Accuracy: 77.20588235294117]\n",
      "After 55 batches: [time:5.0m 40.12869358062744s, Accuracy: 76.5625]\n",
      "After 60 batches: [time:6.0m 9.929332256317139s, Accuracy: 77.25409836065575]\n",
      "After 65 batches: [time:6.0m 40.68388652801514s, Accuracy: 76.89393939393939]\n",
      "After 70 batches: [time:7.0m 13.220149278640747s, Accuracy: 77.64084507042254]\n",
      "After 75 batches: [time:7.0m 41.83806800842285s, Accuracy: 77.96052631578947]\n",
      "After 80 batches: [time:8.0m 11.434795141220093s, Accuracy: 77.9320987654321]\n",
      "After 85 batches: [time:8.0m 39.04702281951904s, Accuracy: 78.05232558139535]\n",
      "After 90 batches: [time:9.0m 8.087748050689697s, Accuracy: 78.02197802197803]\n",
      "After 95 batches: [time:9.0m 37.13242793083191s, Accuracy: 77.86458333333334]\n",
      "After 100 batches: [time:10.0m 6.943242311477661s, Accuracy: 77.5990099009901]\n",
      "After 105 batches: [time:10.0m 34.37228775024414s, Accuracy: 77.7122641509434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 110 batches: [time:11.0m 1.7149364948272705s, Accuracy: 77.92792792792793]\n",
      "After 115 batches: [time:11.0m 30.767980098724365s, Accuracy: 77.69396551724138]\n",
      "After 120 batches: [time:11.0m 59.5701322555542s, Accuracy: 78.099173553719]\n",
      "After 125 batches: [time:12.0m 30.950241804122925s, Accuracy: 77.97619047619048]\n",
      "After 130 batches: [time:12.0m 57.68120050430298s, Accuracy: 78.06513409961686]\n",
      "Epoch 4: [time:12.0m 57.68120050430298s, Accuracy: 78.06513409961686]\n",
      "\n",
      "Epoch: 5\n",
      "After 0 batches: [time:0.0m 5.480627775192261s, Accuracy: 87.5]\n",
      "After 5 batches: [time:0.0m 34.84145927429199s, Accuracy: 83.33333333333334]\n",
      "After 10 batches: [time:1.0m 5.627687692642212s, Accuracy: 86.36363636363636]\n",
      "After 15 batches: [time:1.0m 37.69657325744629s, Accuracy: 85.15625]\n",
      "After 20 batches: [time:2.0m 7.762336015701294s, Accuracy: 86.30952380952381]\n",
      "After 25 batches: [time:2.0m 37.75038409233093s, Accuracy: 86.53846153846155]\n",
      "After 30 batches: [time:3.0m 6.924262285232544s, Accuracy: 86.69354838709677]\n",
      "After 35 batches: [time:3.0m 36.45701289176941s, Accuracy: 86.45833333333334]\n",
      "After 40 batches: [time:4.0m 7.348037242889404s, Accuracy: 86.28048780487805]\n",
      "After 45 batches: [time:4.0m 37.16814422607422s, Accuracy: 86.68478260869566]\n",
      "After 50 batches: [time:5.0m 6.015273809432983s, Accuracy: 86.02941176470588]\n",
      "After 55 batches: [time:5.0m 34.67080593109131s, Accuracy: 85.9375]\n",
      "After 60 batches: [time:6.0m 5.610816478729248s, Accuracy: 86.0655737704918]\n",
      "After 65 batches: [time:6.0m 36.15982937812805s, Accuracy: 85.41666666666666]\n",
      "After 70 batches: [time:7.0m 6.250000953674316s, Accuracy: 84.85915492957746]\n",
      "After 75 batches: [time:7.0m 35.0191969871521s, Accuracy: 85.19736842105263]\n",
      "After 80 batches: [time:8.0m 5.505528926849365s, Accuracy: 85.3395061728395]\n",
      "After 85 batches: [time:8.0m 36.56029462814331s, Accuracy: 85.31976744186046]\n",
      "After 90 batches: [time:9.0m 4.805999517440796s, Accuracy: 85.3021978021978]\n",
      "After 95 batches: [time:9.0m 33.04563546180725s, Accuracy: 85.02604166666666]\n",
      "After 100 batches: [time:10.0m 0.3346874713897705s, Accuracy: 84.77722772277228]\n",
      "After 105 batches: [time:10.0m 28.987739324569702s, Accuracy: 84.90566037735849]\n",
      "After 110 batches: [time:10.0m 57.46175265312195s, Accuracy: 84.34684684684684]\n",
      "After 115 batches: [time:11.0m 28.64411950111389s, Accuracy: 83.72844827586206]\n",
      "After 120 batches: [time:11.0m 58.434221267700195s, Accuracy: 83.47107438016529]\n",
      "After 125 batches: [time:12.0m 28.199748277664185s, Accuracy: 83.13492063492063]\n",
      "After 130 batches: [time:12.0m 53.45657730102539s, Accuracy: 83.5249042145594]\n",
      "Epoch 5: [time:12.0m 53.45757603645325s, Accuracy: 83.5249042145594]\n",
      "\n",
      "Training time: 66.0m 59.55610227584839s\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import time\n",
    "\n",
    "num_epoch = 5\n",
    "lr = 0.001\n",
    "momentum = 0.5\n",
    "net = ProjectModel()\n",
    "\n",
    "loss_evaluater = CrossEntropyLoss()\n",
    "optimizer = SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "# net = net.to(device)\n",
    "\n",
    "net.train()\n",
    "\n",
    "t = time.time()\n",
    "for i in range(num_epoch):\n",
    "    print(f'Epoch: {i+1}')\n",
    "    t_epoch = time.time()\n",
    "    total_labels = 0\n",
    "    correctly_pred = 0\n",
    "    t_batch = time.time()\n",
    "    for j, (data, labels) in enumerate(train_dataloader):\n",
    "#         torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "#         data, labels = data.to(device), labels.to(device)\n",
    "        X, y = data, labels\n",
    "        optimizer.zero_grad()\n",
    "        output = net(X)\n",
    "        loss = loss_evaluater(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred = torch.argmax(output, dim=1)\n",
    "        total_labels += y.size(0)\n",
    "        correctly_pred += (y_pred==y).sum().item()\n",
    "        current_acc = (correctly_pred/total_labels)\n",
    "        if j%5==0:\n",
    "            seconds_passed = time.time()-t_batch\n",
    "            print(f'After {j} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "    epoch_acc = (correctly_pred/total_labels)\n",
    "    seconds_passed = time.time()-t_epoch\n",
    "    print(f'Epoch {i+1}: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {epoch_acc*100}]')\n",
    "    print()\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Training time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 batches: [time:0.0m 2.034867286682129s, Accuracy: 100.0]\n",
      "After 5 batches: [time:0.0m 12.793136358261108s, Accuracy: 97.91666666666666]\n",
      "After 10 batches: [time:0.0m 23.726908206939697s, Accuracy: 94.31818181818183]\n",
      "After 15 batches: [time:0.0m 34.384806871414185s, Accuracy: 90.625]\n",
      "After 20 batches: [time:0.0m 44.63647174835205s, Accuracy: 91.07142857142857]\n",
      "After 25 batches: [time:0.0m 54.9376962184906s, Accuracy: 92.3076923076923]\n",
      "After 30 batches: [time:1.0m 5.849656581878662s, Accuracy: 91.53225806451613]\n",
      "After 35 batches: [time:1.0m 16.235935926437378s, Accuracy: 91.31944444444444]\n",
      "After 40 batches: [time:1.0m 27.290453910827637s, Accuracy: 91.46341463414635]\n",
      "After 45 batches: [time:1.0m 38.015302896499634s, Accuracy: 91.30434782608695]\n",
      "After 50 batches: [time:1.0m 49.54110860824585s, Accuracy: 90.93137254901961]\n",
      "After 55 batches: [time:2.0m 0.4509751796722412s, Accuracy: 91.29464285714286]\n",
      "After 60 batches: [time:2.0m 11.839511156082153s, Accuracy: 90.98360655737704]\n",
      "After 65 batches: [time:2.0m 23.560807943344116s, Accuracy: 91.09848484848484]\n",
      "After 70 batches: [time:2.0m 33.98947548866272s, Accuracy: 90.84507042253522]\n",
      "After 75 batches: [time:2.0m 44.41179418563843s, Accuracy: 90.625]\n",
      "After 80 batches: [time:2.0m 55.81581211090088s, Accuracy: 89.96913580246914]\n",
      "After 85 batches: [time:3.0m 7.5350611209869385s, Accuracy: 89.82558139534885]\n",
      "After 90 batches: [time:3.0m 18.8159818649292s, Accuracy: 89.97252747252747]\n",
      "After 95 batches: [time:3.0m 30.317257404327393s, Accuracy: 89.97395833333334]\n",
      "After 100 batches: [time:3.0m 42.08064603805542s, Accuracy: 89.85148514851485]\n",
      "After 105 batches: [time:3.0m 54.19700050354004s, Accuracy: 89.97641509433963]\n",
      "After 110 batches: [time:4.0m 4.303918838500977s, Accuracy: 89.41441441441441]\n",
      "After 115 batches: [time:4.0m 14.261861085891724s, Accuracy: 89.4396551724138]\n",
      "After 120 batches: [time:4.0m 24.47836470603943s, Accuracy: 89.6694214876033]\n",
      "After 125 batches: [time:4.0m 34.55595517158508s, Accuracy: 89.88095238095238]\n",
      "After 130 batches: [time:4.0m 45.12348222732544s, Accuracy: 89.9425287356322]\n",
      "Training accuracy: 89.9425287356322\n",
      "Trainig evaluation time: 4.0m 45.124478816986084s\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "t = time.time()\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_labels = 0\n",
    "    correctly_pred = 0\n",
    "    t_batch = time.time()\n",
    "    for i, (data, labels) in enumerate(train_dataloader):\n",
    "#         data,labels = data.to(device), labels.to(device)\n",
    "        gc.collect()\n",
    "        X, y = data, labels\n",
    "        output = net(X)\n",
    "        y_pred = torch.argmax(output, dim=1)\n",
    "        total_labels += y.size(0)\n",
    "        correctly_pred += (y_pred==y).sum().item()\n",
    "        current_acc = (correctly_pred/total_labels)\n",
    "        if i%5==0:\n",
    "            seconds_passed = time.time()-t_batch\n",
    "            print(f'After {i} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "    train_acc = (correctly_pred/total_labels)\n",
    "    print(f'Training accuracy: {train_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "\n",
    "print(f'Trainig evaluation time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 batches: [time:0.0m 1.9298062324523926s, Accuracy: 50.0]\n",
      "After 5 batches: [time:0.0m 17.20026469230652s, Accuracy: 72.91666666666666]\n",
      "After 10 batches: [time:0.0m 28.88688635826111s, Accuracy: 75.0]\n",
      "After 15 batches: [time:0.0m 40.97071886062622s, Accuracy: 75.0]\n",
      "After 20 batches: [time:0.0m 52.90430927276611s, Accuracy: 72.61904761904762]\n",
      "After 25 batches: [time:1.0m 4.585077285766602s, Accuracy: 69.71153846153845]\n",
      "After 30 batches: [time:1.0m 16.374597549438477s, Accuracy: 68.95161290322581]\n",
      "After 35 batches: [time:1.0m 28.56737470626831s, Accuracy: 68.40277777777779]\n",
      "Test accuracy: 67.66666666666666\n",
      "Test time: 1.0m 32.29839634895325s\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "net.eval()\n",
    "\n",
    "t = time.time()\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "total_labels = 0\n",
    "correctly_pred = 0\n",
    "t_batch = time.time()\n",
    "for i, (data, labels) in enumerate(test_dataloader):\n",
    "#     torch.cuda.empty_cache()\n",
    "#     data, labels = data.to(device), labels.to(device)\n",
    "    gc.collect()\n",
    "    X, y = data, labels\n",
    "    output = net(X)\n",
    "    y_pred = torch.argmax(output, dim=1)\n",
    "    total_labels += y.size(0)\n",
    "    correctly_pred += (y_pred==y).sum().item()\n",
    "    current_acc = (correctly_pred/total_labels)\n",
    "    if i%5==0:\n",
    "        seconds_passed = time.time()-t_batch\n",
    "        print(f'After {i} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "\n",
    "test_acc = (correctly_pred/total_labels)\n",
    "print(f'Test accuracy: {test_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Test time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Saving pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "file_path = './net.pt'\n",
    "\n",
    "state = {\n",
    "    'epoch': num_epoch,\n",
    "    'state_dict': net.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'lr': lr,\n",
    "    'momentum': momentum\n",
    "}\n",
    "\n",
    "torch.save(state, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Loading Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "state = torch.load(file_path)\n",
    "\n",
    "loaded_net = ProjectModel()\n",
    "loaded_loss_evaluater = CrossEntropyLoss()\n",
    "loaded_optimizer = SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "loaded_num_epoch = state['epoch']\n",
    "loaded_lr = state['lr']\n",
    "loaded_momentum = state['momentum']\n",
    "loaded_net.load_state_dict(state['state_dict'])\n",
    "loaded_optimizer.load_state_dict(state['optimizer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing loaded pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 batches: [time:0.0m 2.1682002544403076s, Accuracy: 50.0]\n",
      "After 5 batches: [time:0.0m 13.696052074432373s, Accuracy: 72.91666666666666]\n",
      "After 10 batches: [time:0.0m 25.893124103546143s, Accuracy: 75.0]\n",
      "After 15 batches: [time:0.0m 37.31352925300598s, Accuracy: 75.0]\n",
      "After 20 batches: [time:0.0m 48.05142378807068s, Accuracy: 72.61904761904762]\n",
      "After 25 batches: [time:0.0m 59.50429081916809s, Accuracy: 69.71153846153845]\n",
      "After 30 batches: [time:1.0m 11.316333770751953s, Accuracy: 68.95161290322581]\n",
      "After 35 batches: [time:1.0m 22.33365750312805s, Accuracy: 68.40277777777779]\n",
      "Test accuracy: 67.66666666666666\n",
      "Test time: 1.0m 25.707111358642578s\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6721)\n",
    "\n",
    "loaded_net.eval()\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "total_labels = 0\n",
    "correctly_pred = 0\n",
    "t_batch = time.time()\n",
    "for i, (data, labels) in enumerate(test_dataloader):\n",
    "#     torch.cuda.empty_cache()\n",
    "#     data, labels = data.to(device), labels.to(device)\n",
    "    gc.collect()\n",
    "    X, y = data, labels\n",
    "    output = loaded_net(X)\n",
    "    y_pred = torch.argmax(output, dim=1)\n",
    "    total_labels += y.size(0)\n",
    "    correctly_pred += (y_pred==y).sum().item()\n",
    "    current_acc = (correctly_pred/total_labels)\n",
    "    if i%5==0:\n",
    "        seconds_passed = time.time()-t_batch\n",
    "        print(f'After {i} batches: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {current_acc*100}]')\n",
    "\n",
    "test_acc = (correctly_pred/total_labels)\n",
    "print(f'Test accuracy: {test_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Test time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy for the model is {test_acc*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision for the model is {test_precision*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Recall for the model is {test_recall*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'F1 score for the model is {test_f1*100} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
