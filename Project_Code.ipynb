{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>\n",
    "COMP-6721 | 2021-Winter\n",
    "Project | Part-1\n",
    "\n",
    "Pravesh Gupta | 40152506\n",
    "Vikramjeet Singh | \n",
    "Manjot Kaur Dherdi | \n",
    "</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Installing required python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\installations\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: future in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (0.6)\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (from torch) (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in d:\\installations\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.18.5)\n",
      "Requirement already satisfied: torch==1.7.0 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.7.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (7.2.0)\n",
      "Requirement already satisfied: future in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\installations\\anaconda3\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in d:\\installations\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\installations\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\installations\\anaconda3\\lib\\site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in d:\\installations\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in d:\\installations\\anaconda3\\lib\\site-packages (0.8.1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.18.5)\n",
      "Requirement already satisfied: torch==1.7.0 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (1.7.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in d:\\installations\\anaconda3\\lib\\site-packages (from torchvision) (7.2.0)\n",
      "\n",
      "Requirement already satisfied: future in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\lib\\site-packages (from torch==1.7.0->torchvision) (0.6)\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in d:\\installations\\anaconda3\\lib\\site-packages (0.16.2)\n",
      "Requirement already satisfied: networkx>=2.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: scipy>=0.19.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (1.5.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: pillow>=4.3.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (7.2.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-image) (3.2.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\installations\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in d:\\installations\\anaconda3\\lib\\site-packages (from scipy>=0.19.0->scikit-image) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\installations\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in d:\\installations\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\lib\\site-packages (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in d:\\installations\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\installations\\anaconda3\\lib\\site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\installations\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in d:\\installations\\anaconda3\\lib\\site-packages (7.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Required Dataset Folder Heirarchy:\n",
    "<pre>\n",
    "{dataset_folder}\n",
    "--images\n",
    "----mask\n",
    "-------{mask images}\n",
    "----no_mask\n",
    "-------{no mask images}\n",
    "----not_person\n",
    "-------{not person images}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Defining Pytorch dataset Representation and data transaformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VisionDataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io as sk_io, transform as sk_transform\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "    \n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size, debug=False, export_path=None):\n",
    "        assert isinstance(output_size, (int))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, img_data):\n",
    "        img_arr = np.array(img_data)\n",
    "        scale_factor = float(self.output_size)/img_arr.shape[0]\n",
    "        img_arr = (sk_transform.rescale(img_arr, (scale_factor, scale_factor, 1))*255).astype(np.uint8)\n",
    "        \n",
    "        new_w = img_arr.shape[1]\n",
    "        \n",
    "        # Clipping or filling\n",
    "        if new_w>self.output_size:\n",
    "            mid = new_w//2\n",
    "            new_w_start = mid-self.output_size//2\n",
    "            new_w_end = mid+self.output_size//2\n",
    "            \n",
    "            if (new_w_end-new_w_start)<self.output_size:\n",
    "                new_w_end += (self.output_size-(new_w_end-new_w_start))\n",
    "            elif (new_w_end-new_w_start)>self.output_size:\n",
    "                new_w_end -= ((new_w_end-new_w_start)-self.output_size)\n",
    "            img_arr = img_arr[:, new_w_start:new_w_end]\n",
    "        elif new_w<self.output_size:\n",
    "            mid = new_w//2\n",
    "            new_w_start = self.output_size//2-mid\n",
    "            new_w_end = new_w_start+new_w\n",
    "            filled_img_arr = np.zeros((self.output_size, self.output_size, img_arr.shape[2]), dtype=np.uint8)\n",
    "            filled_img_arr[:, new_w_start:new_w_end] = img_arr[:, :]\n",
    "            img_arr = filled_img_arr\n",
    "        return Image.fromarray(img_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Creating dataset and data loaders for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_indices(dataset_targets):\n",
    "    test_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        test_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    train_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        train_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    targets = np.array(dataset.targets, dtype=np.int32)\n",
    "    target_indices = np.where(targets!=None)[0]\n",
    "    np.random.shuffle(target_indices)\n",
    "\n",
    "    for i in target_indices:\n",
    "        label = dataset.targets[i]\n",
    "        if test_indices_map[label]['count']<100:\n",
    "            test_indices_map[label]['indices'] = np.append(test_indices_map[label]['indices'], i)\n",
    "            test_indices_map[label]['count']+=1\n",
    "        elif train_indices_map[label]['count']<350:\n",
    "            train_indices_map[label]['indices'] = np.append(train_indices_map[label]['indices'], i)\n",
    "            train_indices_map[label]['count']+=1\n",
    "\n",
    "    test_indices = np.array([], dtype=np.int32)\n",
    "    train_indices = np.array([], dtype=np.int32)\n",
    "\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        label_test_indices = test_indices_map[label]['indices']\n",
    "        test_indices = np.append(test_indices, label_test_indices)\n",
    "\n",
    "        label_train_indices = train_indices_map[label]['indices']\n",
    "        train_indices = np.append(train_indices, label_train_indices)\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: size: 3091, class labels: {'mask': 0, 'no_mask': 1, 'not_person': 2}\n",
      "Train dataset: size: 1050\n",
      "Train X | y batch shapes : (torch.Size([10, 3, 512, 512]), torch.Size([10]))\n",
      "Test dataset: size: 300\n",
      "Test X | y batch shapes : (torch.Size([10, 3, 512, 512]), torch.Size([10]))\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "data_transform = Compose([\n",
    "    Rescale(512)\n",
    "    ,ToTensor()\n",
    "#     ,Normalize(mean=torch.zeros((3)),std=torch.ones((3)))\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    root='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/1/dataset/images/'\n",
    "    ,transform=data_transform\n",
    ")\n",
    "print(f'Dataset: size: {len(dataset)}, class labels: {dataset.class_to_idx}')\n",
    "\n",
    "train_indices, test_indices = get_train_test_indices(dataset.targets)\n",
    "    \n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "print(f'Train dataset: size: {len(train_dataset)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "for data, labels in train_dataloader:\n",
    "    print(f'Train X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break\n",
    "\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "print(f'Test dataset: size: {len(test_dataset)}')\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n",
    "for data, labels in test_dataloader:\n",
    "    print(f'Test X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Conv2d, MaxPool2d, Linear, ReLU\n",
    "\n",
    "class ProjectModel(Module):\n",
    "    def __init__(self):\n",
    "        super(ProjectModel, self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=2)\n",
    "        self.pool1 = MaxPool2d(2)\n",
    "        self.conv2 = Conv2d(in_channels=16, out_channels = 32, kernel_size=3)\n",
    "        self.linear = Linear(in_features = 32*125*125, out_features=3)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        relu = ReLU(inplace=False)\n",
    "        X = self.conv1(X)\n",
    "        X = relu(X)\n",
    "        X = self.pool1(X)\n",
    "        X = self.conv2(X)\n",
    "        X = relu(X)\n",
    "        X = torch.flatten(X, 1)\n",
    "        X = self.linear(X)\n",
    "        return X\n",
    "\n",
    "net = ProjectModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Integrity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0851,  0.0331, -0.0427],\n",
      "        [-0.0199,  0.1084, -0.0564],\n",
      "        [-0.0572,  0.0911, -0.0624],\n",
      "        [-0.0855,  0.0687, -0.0684],\n",
      "        [-0.0678,  0.0941, -0.0451],\n",
      "        [-0.0743,  0.0642, -0.0293],\n",
      "        [-0.0006,  0.0391, -0.0654],\n",
      "        [-0.0617,  0.0815, -0.0622],\n",
      "        [-0.0528,  0.0639, -0.0591],\n",
      "        [-0.0269,  0.0515, -0.0250]], grad_fn=<AddmmBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([[0.3156, 0.3552, 0.3292],\n",
      "        [0.3225, 0.3666, 0.3109],\n",
      "        [0.3170, 0.3677, 0.3153],\n",
      "        [0.3141, 0.3665, 0.3195],\n",
      "        [0.3126, 0.3676, 0.3198],\n",
      "        [0.3130, 0.3595, 0.3274],\n",
      "        [0.3358, 0.3494, 0.3148],\n",
      "        [0.3171, 0.3659, 0.3170],\n",
      "        [0.3208, 0.3605, 0.3188],\n",
      "        [0.3243, 0.3508, 0.3249]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Model test passed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Model Unit test\n",
    "for data, labels in train_dataloader:\n",
    "    outputs = net(data)\n",
    "    print(outputs)\n",
    "    _, y_pred = torch.max(outputs.data, 1)\n",
    "    print(y_pred)\n",
    "    prob = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    print(prob)\n",
    "    label_pred = torch.argmax(prob, dim=1)\n",
    "    print(label_pred)\n",
    "    acc = metrics.accuracy_score(labels, y_pred, normalize=True)\n",
    "    break\n",
    "print('Model test passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: [time:15.0m 43.64962816238403s, Accuracy: 34.952380952380935]\n",
      "Epoch 2: [time:12.0m 5.149068355560303s, Accuracy: 32.38095238095238]\n",
      "Epoch 3: [time:12.0m 37.05988788604736s, Accuracy: 32.76190476190476]\n",
      "Epoch 4: [time:11.0m 54.265122175216675s, Accuracy: 32.1904761904762]\n",
      "Epoch 5: [time:11.0m 51.710593938827515s, Accuracy: 30.95238095238095]\n",
      "Training time: 64.0m 11.848260879516602s\n",
      "=============================================\n",
      "Training accuracy: 33.33333333333333\n",
      "Trainig evaluation time: 11.0m 44.382646322250366s\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import time\n",
    "\n",
    "num_epoch = 5\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "loss_evaluater = CrossEntropyLoss()\n",
    "optimizer = SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "t = time.time()\n",
    "for i in range(num_epoch):\n",
    "    train_acc_sum = 0.0\n",
    "    batch_count = 0\n",
    "    t_epoch = time.time()\n",
    "    for data, labels in train_dataloader:\n",
    "        X, y = data, labels\n",
    "        optimizer.zero_grad()\n",
    "        output = net(X)\n",
    "        loss = loss_evaluater(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, y_pred = torch.max(output.data, 1)\n",
    "        acc = metrics.accuracy_score(y, y_pred)\n",
    "        batch_count+=1\n",
    "        train_acc_sum+=acc\n",
    "    epoch_acc = (train_acc_sum/batch_count)\n",
    "    seconds_passed = time.time()-t_epoch\n",
    "    print(f'Epoch {i+1}: [time:{seconds_passed//60}m {seconds_passed%60}s, Accuracy: {epoch_acc*100}]')\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Training time: {seconds_passed//60}m {seconds_passed%60}s')\n",
    "print('=============================================')\n",
    "\n",
    "t = time.time()\n",
    "with torch.no_grad():\n",
    "    acc_sum = 0.0\n",
    "    batch_count = 0\n",
    "    for data, labels in train_dataloader:\n",
    "        X, y = data, labels\n",
    "        output = net(X)\n",
    "        _, y_pred = torch.max(output.data, 1)\n",
    "        acc = metrics.accuracy_score(y, y_pred)\n",
    "        acc_sum+=acc\n",
    "        batch_count+=1\n",
    "    train_acc = acc_sum/batch_count\n",
    "    print(f'Training accuracy: {train_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Trainig evaluation time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 33.33333333333333\n",
      "Test time: 3.0m 14.451367855072021s\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "acc_sum = 0.0\n",
    "batch_count = 0\n",
    "for data, labels in test_dataloader:\n",
    "    X, y = data, labels\n",
    "    output = net(X)\n",
    "    _, y_pred = torch.max(output.data, 1)\n",
    "    acc = metrics.accuracy_score(y, y_pred)\n",
    "    acc_sum+=acc\n",
    "    batch_count+=1\n",
    "test_acc = acc_sum/batch_count\n",
    "print(f'Test accuracy: {test_acc*100}')\n",
    "seconds_passed = time.time()-t\n",
    "print(f'Test time: {seconds_passed//60}m {seconds_passed%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
