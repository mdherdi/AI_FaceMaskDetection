{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>\n",
    "COMP-6721 | 2021-Winter\n",
    "Project | Part-1\n",
    "\n",
    "Pravesh Gupta | 40152506\n",
    "Vikramjeet Singh | \n",
    "Manjot Kaur Dherdi | \n",
    "</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Installing required python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from torch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from torch) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from torchvision) (8.1.2)\n",
      "Requirement already satisfied: torch==1.8.0 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from torchvision) (1.8.0)\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from torch==1.8.0->torchvision) (0.8)\n",
      "Requirement already satisfied: typing-extensions in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from torch==1.8.0->torchvision) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (1.1.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: torch==1.8.0 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from torchvision) (1.8.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from torchvision) (8.1.2)\n",
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: dataclasses in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from torch==1.8.0->torchvision) (0.8)\n",
      "Requirement already satisfied: typing-extensions in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from torch==1.8.0->torchvision) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: networkx>=2.0 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from scikit-image) (2.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from scikit-image) (2020.9.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from scikit-image) (3.3.4)\n",
      "Requirement already satisfied: scipy>=1.0.1 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from scikit-image) (1.5.4)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from scikit-image) (8.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.1 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from scikit-image) (1.19.5)\n",
      "Requirement already satisfied: imageio>=2.3.0 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied: six in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from scikit-learn->sklearn) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\installations\\anaconda3\\envs\\comp6721\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Required Dataset Folder Heirarchy:\n",
    "<pre>\n",
    "{dataset_folder}\n",
    "--images\n",
    "----mask\n",
    "-------{mask images}\n",
    "----no_mask\n",
    "-------{no mask images}\n",
    "----not_person\n",
    "-------{not person images}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Defining Pytorch dataset Representation and data transaformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VisionDataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io as sk_io, transform as sk_transform\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "    \n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size, debug=False, export_path=None):\n",
    "        assert isinstance(output_size, (int))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, img_data):\n",
    "        img_arr = np.array(img_data)\n",
    "        scale_factor = float(self.output_size)/img_arr.shape[0]\n",
    "        img_arr = (sk_transform.rescale(img_arr, (scale_factor, scale_factor, 1))*255).astype(np.uint8)\n",
    "        \n",
    "        new_w = img_arr.shape[1]\n",
    "        \n",
    "        # Clipping or filling\n",
    "        if new_w>self.output_size:\n",
    "            mid = new_w//2\n",
    "            new_w_start = mid-self.output_size//2\n",
    "            new_w_end = mid+self.output_size//2\n",
    "            \n",
    "            if (new_w_end-new_w_start)<self.output_size:\n",
    "                new_w_end += (self.output_size-(new_w_end-new_w_start))\n",
    "            elif (new_w_end-new_w_start)>self.output_size:\n",
    "                new_w_end -= ((new_w_end-new_w_start)-self.output_size)\n",
    "            img_arr = img_arr[:, new_w_start:new_w_end]\n",
    "        elif new_w<self.output_size:\n",
    "            mid = new_w//2\n",
    "            new_w_start = self.output_size//2-mid\n",
    "            new_w_end = new_w_start+new_w\n",
    "            filled_img_arr = np.zeros((self.output_size, self.output_size, img_arr.shape[2]), dtype=np.uint8)\n",
    "            filled_img_arr[:, new_w_start:new_w_end] = img_arr[:, :]\n",
    "            img_arr = filled_img_arr\n",
    "        return Image.fromarray(img_arr)\n",
    "    \n",
    "class ConvertToType(object):\n",
    "    def __init__(self, conversion_type, debug=False):\n",
    "        self.conversion_type = conversion_type\n",
    "        self.debug = debug\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return img.type(self.conversion_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Creating dataset and data loaders for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_indices(dataset_targets):\n",
    "    test_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        test_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    train_indices_map = {}\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        train_indices_map[label] = {'indices': np.array([], dtype=np.int32), 'count': 0}\n",
    "\n",
    "    targets = np.array(dataset.targets, dtype=np.int32)\n",
    "    target_indices = np.where(targets!=None)[0]\n",
    "    np.random.shuffle(target_indices)\n",
    "\n",
    "    for i in target_indices:\n",
    "        label = dataset.targets[i]\n",
    "        if test_indices_map[label]['count']<100:\n",
    "            test_indices_map[label]['indices'] = np.append(test_indices_map[label]['indices'], i)\n",
    "            test_indices_map[label]['count']+=1\n",
    "        elif train_indices_map[label]['count']<350:\n",
    "            train_indices_map[label]['indices'] = np.append(train_indices_map[label]['indices'], i)\n",
    "            train_indices_map[label]['count']+=1\n",
    "\n",
    "    test_indices = np.array([], dtype=np.int32)\n",
    "    train_indices = np.array([], dtype=np.int32)\n",
    "\n",
    "    for class_name in dataset.class_to_idx:\n",
    "        label = dataset.class_to_idx[class_name]\n",
    "        label_test_indices = test_indices_map[label]['indices']\n",
    "        test_indices = np.append(test_indices, label_test_indices)\n",
    "\n",
    "        label_train_indices = train_indices_map[label]['indices']\n",
    "        train_indices = np.append(train_indices, label_train_indices)\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: size: 3091, class labels: {'mask': 0, 'no_mask': 1, 'not_person': 2}\n",
      "Train dataset: size: 1050\n",
      "Train X | y batch shapes : (torch.Size([10, 3, 512, 512]), torch.Size([10]))\n",
      "Test dataset: size: 300\n",
      "Test X | y batch shapes : (torch.Size([10, 3, 512, 512]), torch.Size([10]))\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "data_transform = Compose([\n",
    "    Rescale(512)\n",
    "    ,ToTensor()\n",
    "    ,Normalize(mean=torch.zeros((3)),std=torch.ones((1)))\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    root='D:/pravesh/Concordia/2021-Winter/COMP-6721-Intro_To_AI/project/1/dataset/images/'\n",
    "    ,transform=data_transform\n",
    ")\n",
    "print(f'Dataset: size: {len(dataset)}, class labels: {dataset.class_to_idx}')\n",
    "\n",
    "train_indices, test_indices = get_train_test_indices(dataset.targets)\n",
    "    \n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "print(f'Train dataset: size: {len(train_dataset)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "for data, labels in train_dataloader:\n",
    "    print(f'Train X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break\n",
    "\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "print(f'Test dataset: size: {len(test_dataset)}')\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n",
    "for data, labels in test_dataloader:\n",
    "    print(f'Test X | y batch shapes : {data.shape, labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Conv2d, MaxPool2d, Linear, ReLU\n",
    "\n",
    "class ProjectModel(Module):\n",
    "    def __init__(self):\n",
    "        super(ProjectModel, self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=2)\n",
    "        self.pool1 = MaxPool2d(2)\n",
    "        self.conv2 = Conv2d(in_channels=16, out_channels = 32, kernel_size=3)\n",
    "        self.linear = Linear(in_features = 32*125*125, out_features=3)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        relu = ReLU(inplace=False)\n",
    "        X = self.conv1(X)\n",
    "        X = relu(X)\n",
    "        X = self.pool1(X)\n",
    "        X = self.conv2(X)\n",
    "        X = relu(X)\n",
    "        X = torch.flatten(X, 1)\n",
    "        X = self.linear(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Integrity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test passed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Model Unit test\n",
    "\n",
    "for data, labels in train_dataloader:\n",
    "    net = ProjectModel()\n",
    "    outputs = net(data)\n",
    "    _, y_pred = torch.max(outputs.data, 1)\n",
    "    acc = metrics.accuracy_score(labels, y_pred, normalize=True)\n",
    "    break\n",
    "print('Model test passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: [time:826.873375415802 seconds, Accuracy: 31.714285714285722\n",
      "Epoch 2: [time:697.1080617904663 seconds, Accuracy: 46.19047619047618\n",
      "Epoch 3: [time:683.4369280338287 seconds, Accuracy: 56.5714285714286\n",
      "Epoch 4: [time:679.9524466991425 seconds, Accuracy: 75.52380952380953\n",
      "Epoch 5: [time:686.3944699764252 seconds, Accuracy: 79.14285714285715\n",
      "Training time: 3573.7712635993958\n",
      "Training accuracy: 89.80952380952384\n",
      "Trainig evaluation time: 674.6690237522125\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import time\n",
    "\n",
    "num_epoch = 5\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "net = ProjectModel()\n",
    "loss_evaluater = CrossEntropyLoss()\n",
    "optimizer = SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "t = time.time()\n",
    "for i in range(num_epoch):\n",
    "    train_acc_sum = 0.0\n",
    "    batch_count = 0\n",
    "    t_epoch = time.time()\n",
    "    for data, labels in train_dataloader:\n",
    "        X, y = data, labels\n",
    "        optimizer.zero_grad()\n",
    "        output = net(X)\n",
    "        loss = loss_evaluater(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, y_pred = torch.max(output.data, 1)\n",
    "        acc = metrics.accuracy_score(y, y_pred)\n",
    "        batch_count+=1\n",
    "        train_acc_sum+=acc\n",
    "    epoch_acc = (train_acc_sum/batch_count)\n",
    "    print(f'Epoch {i+1}: [time:{time.time()-t_epoch} seconds, Accuracy: {epoch_acc*100}]')\n",
    "print(f'Training time: {time.time()-t} seconds')\n",
    "print('=============================================')\n",
    "\n",
    "t = time.time()\n",
    "with torch.no_grad():\n",
    "    acc_sum = 0.0\n",
    "    batch_count = 0\n",
    "    for data, labels in train_dataloader:\n",
    "        X, y = data, labels\n",
    "        output = net(X)\n",
    "        _, y_pred = torch.max(output.data, 1)\n",
    "        acc = metrics.accuracy_score(y, y_pred)\n",
    "        acc_sum+=acc\n",
    "        batch_count+=1\n",
    "    train_acc = acc_sum/batch_count\n",
    "    print(f'Training accuracy: {train_acc*100}')\n",
    "\n",
    "print(f'Trainig evaluation time: {time.time()-t} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 45.0\n"
     ]
    }
   ],
   "source": [
    "acc_sum = 0.0\n",
    "batch_count = 0\n",
    "for data, labels in test_dataloader:\n",
    "    X, y = data, labels\n",
    "    output = net(X)\n",
    "    _, y_pred = torch.max(output.data, 1)\n",
    "    acc = metrics.accuracy_score(y, y_pred)\n",
    "    acc_sum+=acc\n",
    "    batch_count+=1\n",
    "test_acc = acc_sum/batch_count\n",
    "print(f'Test accuracy: {test_acc*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:comp6721]",
   "language": "python",
   "name": "conda-env-comp6721-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
