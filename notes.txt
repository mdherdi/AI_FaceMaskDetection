No mask:
	eyeglasses
	face_no_mask
	face_other_covering
	hat
	sunglasses
	turban
	
Mask:
	face_with_mask
	face_with_mask_incorrect
	mask_colorful
	mask_surgical
	
https://pytorch.org/tutorials/beginner/data_loading_tutorial.html
https://www.hdrplusdata.org/dataset.html

6-9 ~600 to 1000

	
6720 8192 352 320
[  0.   0.   0.   8. 158. 338. 596. 463. 202. 162. 322.  41. 115.  10.
  30.  15.  18.   4.   9.  29.  21.   6.   2.   2.  11.   8.   1.   0.
   4.   4.  15.  31.  38.   2.   2.   2.   0.   2.   3.   1.  87.   1.
 300.   1.   0.   1.   1.   1.   0.   2.   1.   0.   1.   2.   2.   0.
   1.   2.   0.   2.   7.   1.   1.   0.   0.   0.   0.   2.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.]
{0: array([  0.,   0.,   0.,   3.,  96., 276., 392., 351., 132.,  97., 178.,
        30.,  71.,   6.,  19.,   9.,  12.,   1.,   6.,   7.,   9.,   5.,
         1.,   1.,   1.,   3.,   1.,   0.,   3.,   1.,   3.,   2.,   0.,
         0.,   0.,   2.,   0.,   2.,   1.,   0.,   6.,   1.,   2.,   1.,
         0.,   1.,   0.,   1.,   0.,   1.,   1.,   0.,   0.,   1.,   1.,
         0.,   1.,   0.,   0.,   2.,   6.,   1.,   1.,   0.,   0.,   0.,
         0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
         0.]), 1: array([  0.,   0.,   0.,   5.,  62.,  62., 204., 112.,  70.,  65., 144.,
        11.,  44.,   4.,  11.,   6.,   6.,   3.,   3.,  22.,  12.,   1.,
         1.,   1.,   7.,   5.,   0.,   0.,   1.,   3.,   5.,   1.,   2.,
         2.,   2.,   0.,   0.,   0.,   2.,   1.,   3.,   0.,   1.,   0.,
         0.,   0.,   1.,   0.,   0.,   1.,   0.,   0.,   1.,   0.,   1.,
         0.,   0.,   2.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,
         0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
         0.]), 2: array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
         0.,   0.,   3.,   0.,   0.,   0.,   0.,   0.,   7.,  28.,  36.,
         0.,   0.,   0.,   0.,   0.,   0.,   0.,  78.,   0., 297.,   0.,
         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,
         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
         0.])}
		 
1000
300

1300

450*3
1350
		 

6-8

1)
Implementation: Initial

Changes done:
1. Normalize(mean=[0.485, 0.456, 0.406], std=[0.225, 0.225, 0.225])
2. lr = 0.001
3. momentum = 0.5

Training accuracy: 96.38095238095238
Test accuracy: 67.0

############################

2)
Implementation: Lab-7

Changes:
1. changes from above
2. optimizer = sgd, lr=0.001
3. 

Training accuracy: 87.52380952380953
Test accuracy: 63.33333333333333

#################

3)
Impl: lab-7
changes:
1. changes from above
2. adam 0.001

Training accuracy: 84.38095238095238
Test accuracy: 61.66666666666667

#################

4)
Impl: lab-7

changes:
1. above changes
2. Norm calculated using data first and then used for normalization in transformation

Training accuracy: 89.9425287356322
Test accuracy: 67.66666666666666

####################


5)
impl: lab-7

1. above changes
2. xavier initialization
3. dropout layer
4. more linear layers
5. adaptiveavgpool
6. adam

ProjectModel(
  (module): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01, inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.01, inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): LeakyReLU(negative_slope=0.01, inplace=True)
    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): LeakyReLU(negative_slope=0.01, inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): AdaptiveAvgPool2d(output_size=(12, 12))
    (15): Flatten(start_dim=1, end_dim=-1)
    (16): Dropout(p=0.2, inplace=False)
    (17): Linear(in_features=9216, out_features=4096, bias=True)
    (18): Dropout(p=0.2, inplace=False)
    (19): Linear(in_features=4096, out_features=512, bias=True)
    (20): Dropout(p=0.2, inplace=False)
    (21): Linear(in_features=512, out_features=3, bias=True)
  )
  
Training accuracy: 65.13409961685824
Test accuracy: 61.33333333333333

############################################

6)

changes:
epoch = 10
dataset = 700*3=2100

Training accuracy: 79.16129032258064
Test accuracy: 71.33333333333334

#############

7)

above 
epoch=15
Training accuracy: 80.06451612903226
Test accuracy: 73.33333333333333